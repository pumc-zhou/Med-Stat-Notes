[
  {
    "objectID": "Quarto/quarto-LaTeX.html",
    "href": "Quarto/quarto-LaTeX.html",
    "title": "Quarto与LaTeX的记录",
    "section": "",
    "text": "在2025-02-23迁移博客到本网站时遇到一些问题，主要是因为在相关与回归部分使用plotly包制作了一个三维图形，在以前的Rmarkdown博客中，因为未知原因导致从2024年中的一次更新开始就无法在生成PDF文件，所以这个问题没有被发现。\n简而言之就是使用plotly绘制如图所示的双元正态分布图形后，如果Quarto被指定要生成PDF文件，需要载入更多的R包且更新TeXLive的宏包来提供支持。\n## 安装和加载所需的包\n# install.packages(\"plotly\")\n# install.packages(\"mvtnorm\")\nlibrary(plotly)\nlibrary(mvtnorm)\nlibrary(webshot2)\n\n# 创建网格数据\nx &lt;- seq(150, 190, length.out = 100)\n#身高150-190，等距的100个值\ny &lt;- seq(50, 80, length.out = 100)\n#体重50-80，等距的100个值\ngrid &lt;- expand.grid(X = x, Y = y)\n#生成 x 和 y 的所有组合，用于构建一个网格数据框，以便计算多元正态分布的概率密度。\n\n# 设置均值和协方差矩阵\nmu &lt;- c(170, 65)\n#设置双元正态分布的均值向量，表示均值分别为身高 170 cm 和体重 65 kg\n\nsigma &lt;- matrix(c(100, 20, 20, 25), nrow = 2)\n#设置协方差矩阵，表示身高的方差为 100，体重的方差为 25，身高和体重之间的协方差为 20\n\n# 计算概率密度\nz &lt;- dmvnorm(as.matrix(grid), mean = mu, sigma = sigma)\n#计算每个网格点上双元正态分布的概率密度。\n\n# 将概率密度矩阵转换为适合绘图的形状\nz_matrix &lt;- matrix(z, nrow = 100, ncol = 100)\n\n# 绘制三维表面图\nplot_ly(x = x, y = y, z = z_matrix, type = \"surface\") %&gt;%\n  layout(title = list(text = \"双元正态分布的三维概率密度图\", y=0.95),\n         scene = list(xaxis = list(title = \"身高 (cm)\"),\n                      yaxis = list(title = \"体重 (kg)\"),\n                      zaxis = list(title = \"概率密度\")))\n\n\n双元正态分布示例\n上述图像在被转换为PDF文件时，会发生报错：Quarto 文档中包含了一些生成 HTML 输出的函数（比如交互式图表或其他 HTML 小部件），但你当前的目标输出格式是 PDF。由于 PDF 是静态格式，无法直接渲染 HTML 内容，Quarto 会报错并停止执行。",
    "crumbs": [
      "Home",
      "Quarto introduction",
      "Quarto与LaTeX的记录"
    ]
  },
  {
    "objectID": "Quarto/quarto-LaTeX.html#解决方案1",
    "href": "Quarto/quarto-LaTeX.html#解决方案1",
    "title": "Quarto与LaTeX的记录",
    "section": "\n1 解决方案1",
    "text": "1 解决方案1\n此章节不转换为PDF格式。",
    "crumbs": [
      "Home",
      "Quarto introduction",
      "Quarto与LaTeX的记录"
    ]
  },
  {
    "objectID": "Quarto/quarto-LaTeX.html#解决方案2",
    "href": "Quarto/quarto-LaTeX.html#解决方案2",
    "title": "Quarto与LaTeX的记录",
    "section": "\n2 解决方案2",
    "text": "2 解决方案2\n增加支持：如果你仍想输出 PDF，但希望将 HTML 小部件作为静态截图嵌入，可以安装 R 的 webshot 或 webshot2 包。Quarto 会利用它们将 HTML 内容转换为图片。\n需要安装：\n\ninstall.packages(\"webshot2\")\n\n然后在这段程序的前部导入该包：library(webshot2)。\n也可以使用\n\ninstall.packages(\"webshot\")\n\n但是使用 webshot 还需要安装 PhantomJS\n\nwebshot::install_phantomjs()",
    "crumbs": [
      "Home",
      "Quarto introduction",
      "Quarto与LaTeX的记录"
    ]
  },
  {
    "objectID": "Quarto/quarto-LaTeX.html#解决方案3启用-prefer-html-true-选项",
    "href": "Quarto/quarto-LaTeX.html#解决方案3启用-prefer-html-true-选项",
    "title": "Quarto与LaTeX的记录",
    "section": "\n3 解决方案3：启用 prefer-html: true 选项\n",
    "text": "3 解决方案3：启用 prefer-html: true 选项\n\n如果你不在乎 HTML 内容在 PDF 中不可见，可以通过添加 prefer-html: true 来跳过这个错误。这种方法会忽略 HTML 输出，PDF 中不会显示相关内容。\n\n\n在 .qmd 文件的 YAML 前置元数据中添加：\n\nformat: pdf: toc: true # 可选{yaml}",
    "crumbs": [
      "Home",
      "Quarto introduction",
      "Quarto与LaTeX的记录"
    ]
  },
  {
    "objectID": "Quarto/quarto-LaTeX.html#解决方法-4检查并移除-html-输出代码",
    "href": "Quarto/quarto-LaTeX.html#解决方法-4检查并移除-html-输出代码",
    "title": "Quarto与LaTeX的记录",
    "section": "\n4 解决方法 4：检查并移除 HTML 输出代码\n",
    "text": "4 解决方法 4：检查并移除 HTML 输出代码\n\n如果你的目标是纯 PDF 输出，且不需要 HTML 小部件，可以检查文档中的代码块，移除或调整生成 HTML 的部分。例如：\n\n如果使用了 R 的 plotly 或 htmlwidgets，将其替换为静态图形库（如 ggplot2）。\n检查是否有 {r, results='asis'} 或其他生成 HTML 的设置，改为适合 PDF 的输出。\n\n示例：\n将交互式图表改为静态图表：\n\n# 原代码（生成 HTML）\nlibrary(plotly)\nplot_ly(data, x = ~x, y = ~y, type = \"scatter\")\n\n# 修改后（适合 PDF）\nlibrary(ggplot2)\nggplot(data, aes(x = x, y = y)) + geom_point()",
    "crumbs": [
      "Home",
      "Quarto introduction",
      "Quarto与LaTeX的记录"
    ]
  },
  {
    "objectID": "Quarto/quarto-LaTeX.html#quarto调用texlive报错",
    "href": "Quarto/quarto-LaTeX.html#quarto调用texlive报错",
    "title": "Quarto与LaTeX的记录",
    "section": "\n5 Quarto调用TeXLive报错",
    "text": "5 Quarto调用TeXLive报错\n在使用方法一进行完善的过程中，terminal输出了一些关于TeX Live的信息：\n\nTeX Live infrastructure update in progress ... \nTeX Live infrastructure update in progress ... \nDetailed command logging to \"C:\\texlive\\2024\\temp\\update-self.log\" \nself update: texlive.infra (70084 -&gt; 73495) \ntexlive.infra.windows (69813 -&gt; 71447) \ntlperl.windows (69939 -&gt; 71515) \nInfrastructure update finished successfully. \nYou may now close this window.\n\n这是因为Quarto的预览过程中触发了TeX Live的更新，这里的输出显示已完成更新，但是preview .qmd文档仍然不顺利，怀疑没有正确更新，且因为太晚关闭了电脑，导致更新中断。\n试着从terminal对TeX Live进行更新，在cmd中使用如下命令\n\ntlmgr update --self --all\n\n你的Windows电脑可能会和我一样报错：\n\nC:\\Users\\asus&gt;tlmgr update --self --all\nLocale 'English_United States.936' is unsupported, and may crash the interpreter.\n\n这是因为：\n当你运行 tlmgr update --self --all 来更新 TeX Live 时，出现了 Locale 'English_United States.936' is unsupported, and may crash the interpreter 的警告。这表明 TeX Live 的包管理器（tlmgr）在你的系统区域设置（locale）下遇到了兼容性问题，可能是因为你的 Windows 系统使用了中文（代码页 936，简体中文 GBK）作为默认区域设置，而 tlmgr 默认期望一个支持的区域设置（如 UTF-8 或英语）。\n以下是解决这个问题的步骤：\n\n\n5.1 方案 1：检查系统区域设置\n\n\n查看当前区域设置：\n\n按 Win + R，输入 intl.cpl，回车，打开“区域”设置。\n在“格式”选项卡中，查看当前格式（可能是“中文（简体，中国）”）。\n点击“管理”选项卡 -&gt; “更改系统区域设置”，查看“当前系统区域设置”（可能是“中文（简体，中国）”）。\n\n\n\n问题原因：\n\n代码页 936（中文 GBK）不是 TeX Live 的 tlmgr 完全支持的区域设置，可能导致编码或解释器错误。\n\n\n\n\n5.2 方案 2：临时更改区域设置运行 tlmgr\n\n为了让 tlmgr 正常工作，可以临时将区域设置为英语（美国），运行更新后再改回。\n操作步骤：\n\n\n更改系统区域设置：\n\n按 Win + R，输入 intl.cpl。\n点击“管理”选项卡 -&gt; “更改系统区域设置”。\n在下拉菜单中选择“英语（美国）”（English (United States)）。\n勾选“Beta: 使用 UTF-8 提供全球语言支持”（推荐），然后点击“确定”。\n系统会提示重启，点击“立即重启”。\n\n\n\n运行更新：\n\n重启后，打开命令行（cmd）。\n\n输入：\n\ntlmgr update --self --all\n\n\n观察是否还有错误，等待更新完成。\n\n\n\n恢复区域设置（可选）：\n\n更新完成后，重复上述步骤，将区域设置改回“中文（简体，中国）”，再次重启。\n\n\n\n\n5.3 方案 3：使用环境变量绕过区域问题\n如果你不想更改系统区域设置，可以通过设置环境变量临时调整 tlmgr 的运行环境。\n操作步骤：\n\n打开命令行（cmd）。\n\n输入以下命令设置临时环境变量：\n\nset LC_ALL=en_US.UTF-8\n\n\n\n紧接着运行更新：\n\ntlmgr update --self --all\n\n\n\n检查是否成功执行。如果仍然报错，尝试：\n\nset LANG=en_US.UTF-8\ntlmgr update --self --all\n\n\n说明：\n\n\nLC_ALL 或 LANG 是控制区域设置的环境变量，设置为 en_US.UTF-8 可以让 tlmgr 在英语环境下运行，避免中文编码问题。\n这种方法无需重启，适合临时解决。\n\n\n5.4 方案 4：验证更新结果\n更新完成后，检查 TeX Live 是否正常工作： 1. 运行： tlmgr info --list installed 查看已安装的包列表，确保更新生效。 2. 返回 Quarto 项目，运行： quarto preview 确认是否还有 TeX 相关的问题。\n\n5.5 额外建议\n\n\n检查 TeX Live 安装： 如果问题持续存在，可能是 TeX Live 安装不完整。可以尝试重新安装：\n\n下载最新版 TeX Live（tug.org/texlive）。\n安装时选择“完整安装”以确保所有组件齐全。\n\n\n\n使用 PowerShell 或 WSL： 如果 cmd 仍然有问题，可以尝试在 PowerShell 或 Windows Subsystem for Linux (WSL) 中运行 tlmgr，这些环境可能更好地处理区域设置。\n\n\n5.6 推荐方案\n\n\n快速解决：用 Step 3 设置 LC_ALL=en_US.UTF-8，无需重启，最简单。\n\n彻底解决：用 Step 2 临时改为英语区域设置，更新后再改回。\n\n我采用了方案 1，在cmd中输入命令后，出现如下：\n\nC:\\Users\\asus&gt;tlmgr update --self --all\ntlmgr.pl: package repository https://mirrors.hust.edu.cn/CTAN/systems/texlive/tlnet (not verified: gpg unavailable)\ntlmgr.pl: saving backups to C:/texlive/2024/tlpkg/backups\ntlmgr.pl: no self-updates for tlmgr available\ntlmgr.pl: skipping forcibly removed package: extractbb\ntlmgr.pl: skipping forcibly removed package: extractbb.windows\n[  1/764, ??:??/??:??] update: ebgaramond [8780k] (66604 -&gt; 71069) ... done\n[  2/764, 00:16/42:39] update: ebgaramond-maths [567k] (52168 -&gt; 74174) ... done\n\n表示在更新中，这个过程大概需要45分钟左右。",
    "crumbs": [
      "Home",
      "Quarto introduction",
      "Quarto与LaTeX的记录"
    ]
  },
  {
    "objectID": "Quarto/config-giscus-github.html",
    "href": "Quarto/config-giscus-github.html",
    "title": "Qmd config giscus",
    "section": "",
    "text": "[giscus](https://giscus.app/zh-CN)\n\n\n\nGiscus是一个基于Github Discussion的评论插件，可以为无服务器端的博客运营者提供简易的部署和拓展。根据官网，其存在以下特性：\n开源！\n无跟踪，无广告，永久免费；\n无需数据库。全部数据均储存在 GitHub Discussions 中；\n支持自定义主题、多种语言、高度可配置；\n自动从 GitHub 拉取新评论与编辑；\n可自建服务！\n工作原理:\n  Giscus在加载时，会使用 GitHub Discussions 搜索 API 根据选定的映射方式（如 URL、pathname等）来查找与当前页面关联的discussion。如果找不到匹配的discussion，giscus bot就会在第一次有人留下评论或回应时自动创建一个discussion。\n\n  在评论时，访客必须按 GitHub OAuth 流程授权 giscus app 代表他发帖。或者访客也可以直接在 GitHub Discussion 里评论。你可以在 GitHub 上管理评论。\n\n\n\n\n首先要在GitHub建一个开放、可以使用Discussion的仓库，命名可以根据自己需要来，不能同网站仓库一致，因为独立存放评论内容。\n\n创建仓库完成后，请点击仓库最后一个选项setting，往下滑，找到Features功能区中的Discussion，点击勾选，开启仓库的Discussion功能，并安装giscus app ，点击连接并且install到对应新建的仓库就可以了。\n\n\n\n\n\n\nhttps://github.com/apps/giscus\n\nGiscus 应用库可以帮助你更方便地管理设置。通过上述链接进入网页进行安装：\n\n安装完成后转到如下页面，选择已创建好的comments仓库作为评论仓库。\n\n\n\n\n进入&lt;https://giscus.app/zh-CN&gt;配置页面，在该页面中根据自己的需求，选择配置。\n\n仓库选项是必须的，你需要把你创建好的comments仓库输入其中。\n选择合适的分类：\n\n嵌入到网站，在上述配置完成后，会生成一段script，将其放置在你想要展示评论的位置即可。\n\nend.",
    "crumbs": [
      "Home",
      "Quarto introduction",
      "Qmd config giscus"
    ]
  },
  {
    "objectID": "Quarto/config-giscus-github.html#什么是giscus",
    "href": "Quarto/config-giscus-github.html#什么是giscus",
    "title": "Qmd config giscus",
    "section": "",
    "text": "Giscus是一个基于Github Discussion的评论插件，可以为无服务器端的博客运营者提供简易的部署和拓展。根据官网，其存在以下特性：\n开源！\n无跟踪，无广告，永久免费；\n无需数据库。全部数据均储存在 GitHub Discussions 中；\n支持自定义主题、多种语言、高度可配置；\n自动从 GitHub 拉取新评论与编辑；\n可自建服务！\n工作原理:\n  Giscus在加载时，会使用 GitHub Discussions 搜索 API 根据选定的映射方式（如 URL、pathname等）来查找与当前页面关联的discussion。如果找不到匹配的discussion，giscus bot就会在第一次有人留下评论或回应时自动创建一个discussion。\n\n  在评论时，访客必须按 GitHub OAuth 流程授权 giscus app 代表他发帖。或者访客也可以直接在 GitHub Discussion 里评论。你可以在 GitHub 上管理评论。",
    "crumbs": [
      "Home",
      "Quarto introduction",
      "Qmd config giscus"
    ]
  },
  {
    "objectID": "Quarto/config-giscus-github.html#如何使用giscus",
    "href": "Quarto/config-giscus-github.html#如何使用giscus",
    "title": "Qmd config giscus",
    "section": "",
    "text": "首先要在GitHub建一个开放、可以使用Discussion的仓库，命名可以根据自己需要来，不能同网站仓库一致，因为独立存放评论内容。\n\n创建仓库完成后，请点击仓库最后一个选项setting，往下滑，找到Features功能区中的Discussion，点击勾选，开启仓库的Discussion功能，并安装giscus app ，点击连接并且install到对应新建的仓库就可以了。",
    "crumbs": [
      "Home",
      "Quarto introduction",
      "Qmd config giscus"
    ]
  },
  {
    "objectID": "Quarto/config-giscus-github.html#安装giscus-app",
    "href": "Quarto/config-giscus-github.html#安装giscus-app",
    "title": "Qmd config giscus",
    "section": "",
    "text": "https://github.com/apps/giscus\n\nGiscus 应用库可以帮助你更方便地管理设置。通过上述链接进入网页进行安装：\n\n安装完成后转到如下页面，选择已创建好的comments仓库作为评论仓库。",
    "crumbs": [
      "Home",
      "Quarto introduction",
      "Qmd config giscus"
    ]
  },
  {
    "objectID": "Quarto/config-giscus-github.html#配置giscus",
    "href": "Quarto/config-giscus-github.html#配置giscus",
    "title": "Qmd config giscus",
    "section": "",
    "text": "进入&lt;https://giscus.app/zh-CN&gt;配置页面，在该页面中根据自己的需求，选择配置。\n\n仓库选项是必须的，你需要把你创建好的comments仓库输入其中。\n选择合适的分类：\n\n嵌入到网站，在上述配置完成后，会生成一段script，将其放置在你想要展示评论的位置即可。\n\nend.",
    "crumbs": [
      "Home",
      "Quarto introduction",
      "Qmd config giscus"
    ]
  },
  {
    "objectID": "Learn/Bayes/01-Bayes-PGM.html",
    "href": "Learn/Bayes/01-Bayes-PGM.html",
    "title": "贝叶斯与概率图模型（PGM）",
    "section": "",
    "text": "概率图模型是一种结合概率论与图论的理论框架，用于表示和分析复杂系统中的不确定性及概率关系。\n\n\n贝叶斯网络\n马尔科夫随机场（MRF)\n隐马尔科夫模型（HMM)\n\n\n安装：\n\ninstall.packages(\"gRain\")\n\n加载：\n\nlibrary(\"gRbase\")\n\n首先定义一个带有变量的A、B、C、D、E的简单无向图\n\ngraph &lt;- ug(\"A:B:E + C:E:D\")\nclass(graph)\n\n[1] \"igraph\"\n\n\n安装可视化程序包，使用流行的Rgraphviz\nRgraphviz是 Bioconductor 生态系统的一部分，所以可以通过 Bioconductor 来安装它。首先要确保已经安装了BiocManager，若未安装，可使用以下代码进行安装：\n\nif (!require(\"BiocManager\", quietly = TRUE))\n    install.packages(\"BiocManager\")\n\n安装好BiocManager之后，使用它来安装Rgraphviz：\n\nBiocManager::install(\"Rgraphviz\")\n\n载入并使用：\n\nlibrary(\"Rgraphviz\")\nplot(graph)\n\n\n\n\n\n\n\n定义有向图：\n\ndag &lt;- dag(\"A + B:A + C:B + D:B + E:C:D\")\ndag\n\nIGRAPH 28898ca DN-- 1 0 -- \n+ attr: name (v/c)\n+ edges from 28898ca (vertex names):\n\nplot(dag)\n\n\n\n\n\n\n\n\n报错：无法正确显示图形\n原因：Rgraphviz 没有被正确的安装。\n需要从 bioconductor 中安装：\n\n&gt; install.packages(\"Rgraphviz\")\nInstalling package into 'C:/Users/asus/AppData/Local/R/win-library/4.4'\n(as 'lib' is unspecified)\nWarning message:\npackage 'Rgraphviz' is not available for this version of R\n\nA version of this package for your version of R might be available elsewhere,\nsee the ideas at\nhttps://cran.r-project.org/doc/manuals/r-patched/R-admin.html#Installing-packages\n\n当使用 bidconductor 源来安装 Rgraphviz ，首先安装 BiocManager ：\n\n&gt; if (!require(\"BiocManager\", quietly = TRUE))\n+     install.packages(\"BiocManager\")\nInstalling package into 'C:/Users/asus/AppData/Local/R/win-library/4.4'\n(as 'lib' is unspecified)\ntrying URL 'https://mirrors.sustech.edu.cn/CRAN/bin/windows/contrib/4.4/BiocManager_1.30.25.zip'\nContent type 'application/zip' length 506482 bytes (494 KB)\ndownloaded 494 KB\n\npackage 'BiocManager' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n        C:\\Users\\asus\\AppData\\Local\\Temp\\RtmpSCcZNG\\downloaded_packages\n\n然后使用 BiocManager 安装 Rgraphviz ，需要安装的配套程序包很多，需要几分钟，但是这里出现了报错。\n\n&gt; BiocManager::install(\"Rgraphviz\")\n'getOption(\"repos\")' replaces Bioconductor standard repositories, see\n'help(\"repositories\", package = \"BiocManager\")' for details.\nReplacement repositories:\n    CRAN: https://mirrors.sustech.edu.cn/CRAN\nBioconductor version 3.20 (BiocManager 1.30.25), R 4.4.2 (2024-10-31 ucrt)\nInstalling package(s) 'BiocVersion', 'Rgraphviz'\nalso installing the dependencies 'BiocGenerics', 'graph'\n\ntrying URL 'https://bioconductor.org/packages/3.20/bioc/bin/windows/contrib/4.4/BiocGenerics_0.52.0.zip'\nlibpng warning: iCCP: known incorrect sRGB profile\nlibpng warning: iCCP: known incorrect sRGB profile\nContent type 'application/zip' length 639558 bytes (624 KB)\ndownloaded 624 KB\n\ntrying URL 'https://bioconductor.org/packages/3.20/bioc/bin/windows/contrib/4.4/graph_1.84.1.zip'\nContent type 'application/zip' length 2173761 bytes (2.1 MB)\ndownloaded 2.1 MB\n\ntrying URL 'https://bioconductor.org/packages/3.20/bioc/bin/windows/contrib/4.4/BiocVersion_3.20.0.zip'\nContent type 'application/zip' length 8386 bytes\ndownloaded 8386 bytes\n\ntrying URL 'https://bioconductor.org/packages/3.20/bioc/bin/windows/contrib/4.4/Rgraphviz_2.50.0.zip'\nContent type 'application/zip' length 1457153 bytes (1.4 MB)\ndownloaded 1.4 MB\n\npackage 'BiocGenerics' successfully unpacked and MD5 sums checked\npackage 'graph' successfully unpacked and MD5 sums checked\npackage 'BiocVersion' successfully unpacked and MD5 sums checked\npackage 'Rgraphviz' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n        C:\\Users\\asus\\AppData\\Local\\Temp\\RtmpSCcZNG\\downloaded_packages\nInstallation paths not writeable, unable to update packages\n  path: C:/Program Files/R/R-4.4.2/library\n  packages:\n    class, cli, cluster, curl, data.table, foreign, glue, jsonlite, KernSmooth,\n    lintr, MASS, Matrix, nlme, nnet, processx, ps, purrr, R.utils, R6, renv,\n    reticulate, rlang, rpart, sessioninfo, spatial, survival, tinytex, xfun,\n    xml2, zoo\nOld packages: 'httpgd', 'readxl', 'unigd'\napdate all/some/none? [a/s/n]:\ntrying URL 'https://mirrors.sustech.edu.cn/CRAN/bin/windows/contrib/4.4/httpgd_2.0.3.zip'\nContent type 'application/zip' length 874316 bytes (853 KB)\ndownloaded 853 KB\n\ntrying URL 'https://mirrors.sustech.edu.cn/CRAN/bin/windows/contrib/4.4/readxl_1.4.4.zip' \nContent type 'application/zip' length 750422 bytes (732 KB)\ndownloaded 732 KB\n\ntrying URL 'https://mirrors.sustech.edu.cn/CRAN/bin/windows/contrib/4.4/unigd_0.1.3.zip'\nContent type 'application/zip' length 5591347 bytes (5.3 MB)\ndownloaded 5.3 MB\n\npackage 'httpgd' successfully unpacked and MD5 sums checked\npackage 'readxl' successfully unpacked and MD5 sums checked\nWarning: cannot remove prior installation of package 'readxl'\nWarning: restored 'readxl'\npackage 'unigd' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n        C:\\Users\\asus\\AppData\\Local\\Temp\\RtmpSCcZNG\\downloaded_packages\nWarning message:\nIn file.copy(savedcopy, lib, recursive = TRUE) :\n  problem copying C:\\Users\\asus\\AppData\\Local\\R\\win-library\\4.4\\00LOCK\\readxl\\libs\\x64\\readxl.dll to C:\\Users\\asus\\AppData\\Local\\R\\win-library\\4.4\\readxl\\libs\\x64\\readxl.dll: Permission denied\n\n主要问题是没有写入权限，这可能和在 vscode 中安装有关，因此，换到 R 的终端中进行安装（注意，可能需要使用管理员权限），但是仍然免不了一系列的包冲突问题，需要根据提示选择操作：\n\n使用管理员身份运行 R 。\n选择合适的源来下载。\n\n处理有冲突的包（卸载），或者重新创建一个 env 。\n\n # 删除 readxl 包\n readxl_path &lt;- system.file(package = \"readxl\")\n if (!is.na(readxl_path)) {\n unlink(readxl_path, recursive = TRUE)\n }\n # 删除 cli 包\n cli_path &lt;- system.file(package = \"cli\")\n if (!is.na(cli_path)) {\n unlink(cli_path, recursive = TRUE)\n }\n # 再次尝试安装 Rgraphviz\n BiocManager::install(\"Rgraphviz\")\n\n\n强制更新，忽略冲突\n\n有些包的版本已经是最新的，但安装过程仍然提示需要更新，你可以使用 force = TRUE 参数强制重新安装。\n\nBiocManager::install(\"Rgraphviz\", force = TRUE)\n\n\n\n具体信息如下：\n\n&gt; BiocManager::install(\"Rgraphviz\")\n'getOption(\"repos\")' replaces Bioconductor standard repositories, see\n'help(\"repositories\", package = \"BiocManager\")' for details.\nReplacement repositories:\n    CRAN: https://mirrors.nju.edu.cn/CRAN\nBioconductor version 3.20 (BiocManager 1.30.25), R 4.4.2 (2024-10-31 ucrt)\nWarning message:\npackage(s) not installed when version(s) same as or greater than current; use\n  `force = TRUE` to re-install: 'Rgraphviz' \n&gt; BiocManager::install(\"Rgraphviz\", force = TRUE)\n'getOption(\"repos\")' replaces Bioconductor standard repositories, see\n'help(\"repositories\", package = \"BiocManager\")' for details.\nReplacement repositories:\n    CRAN: https://mirrors.nju.edu.cn/CRAN\nBioconductor version 3.20 (BiocManager 1.30.25), R 4.4.2 (2024-10-31 ucrt)\nInstalling package(s) 'Rgraphviz'\ntrying URL 'https://bioconductor.org/packages/3.20/bioc/bin/windows/contrib/4.4/Rgraphviz_2.50.0.zip'\nContent type 'application/zip' length 1457153 bytes (1.4 MB)\ndownloaded 1.4 MB\n\npackage ‘Rgraphviz’ successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n        C:\\Users\\asus\\AppData\\Local\\Temp\\Rtmp2j7SlA\\downloaded_packages\n\n\n\n首先，为每一个节点定义取值：\n\nmachine_val &lt;- c(\"working\", \"broken\")\nlight_bulb_val &lt;- c(\"good\", \"bad\")\n\n为两个随机变量定义百分比数值：\n\nmachine_val &lt;- c(99,1)\nlight_bulb_val &lt;- c(99,1,60,40)\n\n使用 gRain 定义随机变量：\n\nlibrary(gRain)\nM &lt;- cptable(~machine, values = machine_prob,\n            levels = machine_val)\nL &lt;- cptable(~light_bulb | machine,\n            values = light_bulb_prob,\n            levels = light_bulb_val)\n\n这里的 cptable 表示条件概率表1：它是离散型随机变量概率分布的内存表示2。\n\n\nplist &lt;- compileCPT(list(M,L))\nplist\n\n输出结果如上，这里可以清楚地看到之前定义的概率分布\n2025.04.05 再次尝试复现程序，失败，暂时停止概率图R程序的复现工作。\nend.",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "贝叶斯与概率推理",
      "贝叶斯与概率图模型（PGM）"
    ]
  },
  {
    "objectID": "Learn/Bayes/01-Bayes-PGM.html#常见类型",
    "href": "Learn/Bayes/01-Bayes-PGM.html#常见类型",
    "title": "贝叶斯与概率图模型（PGM）",
    "section": "",
    "text": "贝叶斯网络\n马尔科夫随机场（MRF)\n隐马尔科夫模型（HMM)",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "贝叶斯与概率推理",
      "贝叶斯与概率图模型（PGM）"
    ]
  },
  {
    "objectID": "Learn/Bayes/01-Bayes-PGM.html#用r来展示概率图模型",
    "href": "Learn/Bayes/01-Bayes-PGM.html#用r来展示概率图模型",
    "title": "贝叶斯与概率图模型（PGM）",
    "section": "",
    "text": "安装：\n\ninstall.packages(\"gRain\")\n\n加载：\n\nlibrary(\"gRbase\")\n\n首先定义一个带有变量的A、B、C、D、E的简单无向图\n\ngraph &lt;- ug(\"A:B:E + C:E:D\")\nclass(graph)\n\n[1] \"igraph\"\n\n\n安装可视化程序包，使用流行的Rgraphviz\nRgraphviz是 Bioconductor 生态系统的一部分，所以可以通过 Bioconductor 来安装它。首先要确保已经安装了BiocManager，若未安装，可使用以下代码进行安装：\n\nif (!require(\"BiocManager\", quietly = TRUE))\n    install.packages(\"BiocManager\")\n\n安装好BiocManager之后，使用它来安装Rgraphviz：\n\nBiocManager::install(\"Rgraphviz\")\n\n载入并使用：\n\nlibrary(\"Rgraphviz\")\nplot(graph)\n\n\n\n\n\n\n\n定义有向图：\n\ndag &lt;- dag(\"A + B:A + C:B + D:B + E:C:D\")\ndag\n\nIGRAPH 28898ca DN-- 1 0 -- \n+ attr: name (v/c)\n+ edges from 28898ca (vertex names):\n\nplot(dag)",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "贝叶斯与概率推理",
      "贝叶斯与概率图模型（PGM）"
    ]
  },
  {
    "objectID": "Learn/Bayes/01-Bayes-PGM.html#报错",
    "href": "Learn/Bayes/01-Bayes-PGM.html#报错",
    "title": "贝叶斯与概率图模型（PGM）",
    "section": "",
    "text": "报错：无法正确显示图形\n原因：Rgraphviz 没有被正确的安装。\n需要从 bioconductor 中安装：\n\n&gt; install.packages(\"Rgraphviz\")\nInstalling package into 'C:/Users/asus/AppData/Local/R/win-library/4.4'\n(as 'lib' is unspecified)\nWarning message:\npackage 'Rgraphviz' is not available for this version of R\n\nA version of this package for your version of R might be available elsewhere,\nsee the ideas at\nhttps://cran.r-project.org/doc/manuals/r-patched/R-admin.html#Installing-packages\n\n当使用 bidconductor 源来安装 Rgraphviz ，首先安装 BiocManager ：\n\n&gt; if (!require(\"BiocManager\", quietly = TRUE))\n+     install.packages(\"BiocManager\")\nInstalling package into 'C:/Users/asus/AppData/Local/R/win-library/4.4'\n(as 'lib' is unspecified)\ntrying URL 'https://mirrors.sustech.edu.cn/CRAN/bin/windows/contrib/4.4/BiocManager_1.30.25.zip'\nContent type 'application/zip' length 506482 bytes (494 KB)\ndownloaded 494 KB\n\npackage 'BiocManager' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n        C:\\Users\\asus\\AppData\\Local\\Temp\\RtmpSCcZNG\\downloaded_packages\n\n然后使用 BiocManager 安装 Rgraphviz ，需要安装的配套程序包很多，需要几分钟，但是这里出现了报错。\n\n&gt; BiocManager::install(\"Rgraphviz\")\n'getOption(\"repos\")' replaces Bioconductor standard repositories, see\n'help(\"repositories\", package = \"BiocManager\")' for details.\nReplacement repositories:\n    CRAN: https://mirrors.sustech.edu.cn/CRAN\nBioconductor version 3.20 (BiocManager 1.30.25), R 4.4.2 (2024-10-31 ucrt)\nInstalling package(s) 'BiocVersion', 'Rgraphviz'\nalso installing the dependencies 'BiocGenerics', 'graph'\n\ntrying URL 'https://bioconductor.org/packages/3.20/bioc/bin/windows/contrib/4.4/BiocGenerics_0.52.0.zip'\nlibpng warning: iCCP: known incorrect sRGB profile\nlibpng warning: iCCP: known incorrect sRGB profile\nContent type 'application/zip' length 639558 bytes (624 KB)\ndownloaded 624 KB\n\ntrying URL 'https://bioconductor.org/packages/3.20/bioc/bin/windows/contrib/4.4/graph_1.84.1.zip'\nContent type 'application/zip' length 2173761 bytes (2.1 MB)\ndownloaded 2.1 MB\n\ntrying URL 'https://bioconductor.org/packages/3.20/bioc/bin/windows/contrib/4.4/BiocVersion_3.20.0.zip'\nContent type 'application/zip' length 8386 bytes\ndownloaded 8386 bytes\n\ntrying URL 'https://bioconductor.org/packages/3.20/bioc/bin/windows/contrib/4.4/Rgraphviz_2.50.0.zip'\nContent type 'application/zip' length 1457153 bytes (1.4 MB)\ndownloaded 1.4 MB\n\npackage 'BiocGenerics' successfully unpacked and MD5 sums checked\npackage 'graph' successfully unpacked and MD5 sums checked\npackage 'BiocVersion' successfully unpacked and MD5 sums checked\npackage 'Rgraphviz' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n        C:\\Users\\asus\\AppData\\Local\\Temp\\RtmpSCcZNG\\downloaded_packages\nInstallation paths not writeable, unable to update packages\n  path: C:/Program Files/R/R-4.4.2/library\n  packages:\n    class, cli, cluster, curl, data.table, foreign, glue, jsonlite, KernSmooth,\n    lintr, MASS, Matrix, nlme, nnet, processx, ps, purrr, R.utils, R6, renv,\n    reticulate, rlang, rpart, sessioninfo, spatial, survival, tinytex, xfun,\n    xml2, zoo\nOld packages: 'httpgd', 'readxl', 'unigd'\napdate all/some/none? [a/s/n]:\ntrying URL 'https://mirrors.sustech.edu.cn/CRAN/bin/windows/contrib/4.4/httpgd_2.0.3.zip'\nContent type 'application/zip' length 874316 bytes (853 KB)\ndownloaded 853 KB\n\ntrying URL 'https://mirrors.sustech.edu.cn/CRAN/bin/windows/contrib/4.4/readxl_1.4.4.zip' \nContent type 'application/zip' length 750422 bytes (732 KB)\ndownloaded 732 KB\n\ntrying URL 'https://mirrors.sustech.edu.cn/CRAN/bin/windows/contrib/4.4/unigd_0.1.3.zip'\nContent type 'application/zip' length 5591347 bytes (5.3 MB)\ndownloaded 5.3 MB\n\npackage 'httpgd' successfully unpacked and MD5 sums checked\npackage 'readxl' successfully unpacked and MD5 sums checked\nWarning: cannot remove prior installation of package 'readxl'\nWarning: restored 'readxl'\npackage 'unigd' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n        C:\\Users\\asus\\AppData\\Local\\Temp\\RtmpSCcZNG\\downloaded_packages\nWarning message:\nIn file.copy(savedcopy, lib, recursive = TRUE) :\n  problem copying C:\\Users\\asus\\AppData\\Local\\R\\win-library\\4.4\\00LOCK\\readxl\\libs\\x64\\readxl.dll to C:\\Users\\asus\\AppData\\Local\\R\\win-library\\4.4\\readxl\\libs\\x64\\readxl.dll: Permission denied\n\n主要问题是没有写入权限，这可能和在 vscode 中安装有关，因此，换到 R 的终端中进行安装（注意，可能需要使用管理员权限），但是仍然免不了一系列的包冲突问题，需要根据提示选择操作：\n\n使用管理员身份运行 R 。\n选择合适的源来下载。\n\n处理有冲突的包（卸载），或者重新创建一个 env 。\n\n # 删除 readxl 包\n readxl_path &lt;- system.file(package = \"readxl\")\n if (!is.na(readxl_path)) {\n unlink(readxl_path, recursive = TRUE)\n }\n # 删除 cli 包\n cli_path &lt;- system.file(package = \"cli\")\n if (!is.na(cli_path)) {\n unlink(cli_path, recursive = TRUE)\n }\n # 再次尝试安装 Rgraphviz\n BiocManager::install(\"Rgraphviz\")\n\n\n强制更新，忽略冲突\n\n有些包的版本已经是最新的，但安装过程仍然提示需要更新，你可以使用 force = TRUE 参数强制重新安装。\n\nBiocManager::install(\"Rgraphviz\", force = TRUE)\n\n\n\n具体信息如下：\n\n&gt; BiocManager::install(\"Rgraphviz\")\n'getOption(\"repos\")' replaces Bioconductor standard repositories, see\n'help(\"repositories\", package = \"BiocManager\")' for details.\nReplacement repositories:\n    CRAN: https://mirrors.nju.edu.cn/CRAN\nBioconductor version 3.20 (BiocManager 1.30.25), R 4.4.2 (2024-10-31 ucrt)\nWarning message:\npackage(s) not installed when version(s) same as or greater than current; use\n  `force = TRUE` to re-install: 'Rgraphviz' \n&gt; BiocManager::install(\"Rgraphviz\", force = TRUE)\n'getOption(\"repos\")' replaces Bioconductor standard repositories, see\n'help(\"repositories\", package = \"BiocManager\")' for details.\nReplacement repositories:\n    CRAN: https://mirrors.nju.edu.cn/CRAN\nBioconductor version 3.20 (BiocManager 1.30.25), R 4.4.2 (2024-10-31 ucrt)\nInstalling package(s) 'Rgraphviz'\ntrying URL 'https://bioconductor.org/packages/3.20/bioc/bin/windows/contrib/4.4/Rgraphviz_2.50.0.zip'\nContent type 'application/zip' length 1457153 bytes (1.4 MB)\ndownloaded 1.4 MB\n\npackage ‘Rgraphviz’ successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n        C:\\Users\\asus\\AppData\\Local\\Temp\\Rtmp2j7SlA\\downloaded_packages",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "贝叶斯与概率推理",
      "贝叶斯与概率图模型（PGM）"
    ]
  },
  {
    "objectID": "Learn/Basic/10-regression-correlation.html",
    "href": "Learn/Basic/10-regression-correlation.html",
    "title": "简单线性相关和回归",
    "section": "",
    "text": "two variables relationship\n\n\n\n\n\nThe basic process of straight-line regression analysis\n\n\n\n\n\n\n\n\n名称\n适用条件\n\n\n\nPearson直线相关系数\n双变量正态分布的资料\\(\\rightarrow\\)定量\\(\\rightarrow\\)类比t检验、方差分析\n\n\n列联系数\n非等级资料\\(\\rightarrow\\)分类\\(\\rightarrow\\)类比卡方检验\n\n\nSpearman秩相关系数\n不满足双变量正态分布、分布未知、等级资料\\(\\rightarrow\\)定量+分类\\(\\rightarrow\\)类比秩和检验",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "简单线性相关和回归"
    ]
  },
  {
    "objectID": "Learn/Basic/10-regression-correlation.html#两变量关系分析",
    "href": "Learn/Basic/10-regression-correlation.html#两变量关系分析",
    "title": "简单线性相关和回归",
    "section": "",
    "text": "two variables relationship",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "简单线性相关和回归"
    ]
  },
  {
    "objectID": "Learn/Basic/10-regression-correlation.html#常见相关系数",
    "href": "Learn/Basic/10-regression-correlation.html#常见相关系数",
    "title": "简单线性相关和回归",
    "section": "",
    "text": "The basic process of straight-line regression analysis\n\n\n\n\n\n\n\n\n名称\n适用条件\n\n\n\nPearson直线相关系数\n双变量正态分布的资料\\(\\rightarrow\\)定量\\(\\rightarrow\\)类比t检验、方差分析\n\n\n列联系数\n非等级资料\\(\\rightarrow\\)分类\\(\\rightarrow\\)类比卡方检验\n\n\nSpearman秩相关系数\n不满足双变量正态分布、分布未知、等级资料\\(\\rightarrow\\)定量+分类\\(\\rightarrow\\)类比秩和检验",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "简单线性相关和回归"
    ]
  },
  {
    "objectID": "Learn/Basic/10-regression-correlation.html#简单直线回归",
    "href": "Learn/Basic/10-regression-correlation.html#简单直线回归",
    "title": "简单线性相关和回归",
    "section": "",
    "text": "Draw a scatterplot\n\n\n选择一组数据集的“最佳拟合直线”，需要设法通过观测数据确定参数\\(\\alpha\\)与\\(\\beta\\)的估计值a和b，使得直线\n\\[\\hat y=a+bx\\]\n能最佳地反映\\((x_i,y_i)\\)之间的变化关系，该直线称为一元回归直线。\n常用最小二乘估计法（least squares estimation）来最佳直线，其基本原理是通过最小化残差平方和，使得各观测点到回归直线的纵向距离的平方和最小。\n\\[\n\\begin{cases}\na=\\bar y-b \\bar x\\\\\nb=\\frac{\\sum\\limits_{i=1}^n x_i y_i - \\frac{1}{n}(\\sum\\limits_{i=1}^n x_i)(\\sum\\limits_{i=1}^n y_i)}{\\sum\\limits_{i=1}^n x_i^2 - \\frac{1}{n}(\\sum\\limits_{i=1}^n x_i)^2}\n\\end{cases}\n\\] 为方便，引入以下记号： \\[\nSS_{xx}=\\sum_{i}(x_i-\\bar x)^2=\\sum_{i}x_i^2-\\frac{1}{n}(\\sum_{i}x_i)^2\\\\\nSS_{yy}=\\sum_{i}(y_i-\\bar y)^2=\\sum_{i}y_i^2-\\frac{1}{n}(\\sum_{i}y_i)^2\\\\\nSS_{xy}=\\sum_{i}(x_i-\\bar x)(y_i-\\bar y)=\\sum_{i}x_i y_i-\\frac{1}{n}(\\sum_{i}x_i)(\\sum_{i}y_i)\n\\] 其中，\\(SS_{xx}\\)和\\(SS_{yy}\\)是离均差平方和，\\(SS_{xy}\\)称为离均差积和。\n这样可以简化为： \\[\n\\begin{cases}\na=\\bar y-b \\bar x\\\\\nb=\\frac{SS_{xy}}{SS_{xx}}\n\\end{cases}\n\\]\n\n\nF检验\n\n\\(y_i\\)的总离均差平方和为：\n\\[SS_{yy}=\\sum_{i}(y_i-\\bar y)^2\\] 对其做分解，得到等式：\n\\[SS_{yy}=\\sum_{i}^{n}(\\hat y_i-\\bar y)^2+\\sum_{i}^{n}(y_i-\\hat y_i)^2\\] \\(\\sum_{i}^{n}(\\hat y_i-\\bar y)^2\\)为回归平方和（regression sum of squares），记为\\(SS_R\\)，表示回归估计值\\(\\hat y_i\\)与均数\\(\\bar y\\)的离差平方和，其公式为：\n\\[\n\\begin{align}\nSS_{yy} &= \\sum_{i=1}^{n}(\\hat y_i - \\bar y)^2 \\\\\n        &= \\sum_{i=1}^{n}[a + bx_i - (a + b\\bar x)]^2 \\\\\n        &= SS_{xx}b^2 \\\\\n        &= SS_{xy}b\n\\end{align}\n\\] 显然，回归平方和\\(SS_{R}\\)反映的是在y的总变异中由x与y的直线回归关系解释的那部分变异。\\(SS_R\\)值越大，说明回归直线的拟合效果就越好。\n\\(\\sum_{i}^{n}(y_i-\\hat y_i)^2\\)为残差平方和（residual sum of squares），记为\\(SS_E\\)，表示观测值\\(y_i\\)与回归估计值\\(\\hat y_i\\)的离差平方和，其公式为： \\[SS_E=\\sum_{i=1}^{n}(y_i-\\hat y_i)^2\\] \\(SS_E\\)反映了在总变异中扣除自变量x对因变量y的线性影响以后的其他因素（包括x对y的非线性影响和随机误差等）对y变异的影响，也就是在总平方和中无法用y和x线性回归关系解释的部分。\\(SS_E\\)值越小，说明回归直线的拟合效果就越好。\n对公式进行简化： \\[\\begin{align}\nSS_{yy}=&\\sum_{i}^{n}(\\hat y_i-\\bar y)^2+\\sum_{i}^{n}(y_i-\\hat y_i)^2\\\\\n=&SS_R+SS_E\n\\end{align}\\] 上述三个平方和，各有其相应的自由度\\(v\\)，并有如下关系： \\[v_{yy}=v_R+v_E\\\\\nv_{yy}=n-1,v_R=1,v_E=n-2\\]\n在\\(H_0\\)成立的条件下，有： \\[\\frac{SS_R}{\\sigma^2}\\sim \\chi^2(v_R),\\frac{SS_E}{\\sigma^2}\\sim \\chi^2(v_E)\\] 且\\(SS_R\\)和\\(SS_E\\)相互独立。\n检验统计量：\n\\[F=\\frac{SS_R/v_R}{SS_E/v_E}\\] 服从自由度\\(v_R=1,v_E=n-2\\)的F分布。如果y和x确实存在直线回归关系，那么回归所解释的变异\\(SS_R\\)应大于其他因素所解释的变异\\(SS_E\\)。由此可见，F检验正是建立在这个基础上的。\n对于给定的检验水准\\(\\alpha\\)， 如果\\(F&gt;F_{(v_R,v_E),1-\\alpha}\\)，则拒绝\\(H_0\\)，认为直线回归方程有统计学显著性；\n如果\\(F\\leq F_{(v_R,v_E),1-\\alpha}\\)，则不拒绝\\(H_0\\)，尚不能认为直线回归方程有统计学显著性。\n\nt检验法",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "简单线性相关和回归"
    ]
  },
  {
    "objectID": "Learn/Basic/10-regression-correlation.html#直线相关与直线回归的比较",
    "href": "Learn/Basic/10-regression-correlation.html#直线相关与直线回归的比较",
    "title": "简单线性相关和回归",
    "section": "\n2.3 直线相关与直线回归的比较",
    "text": "2.3 直线相关与直线回归的比较\n\n\n\n\n\n\n\n区别与联系\n类目\n内容\n\n\n\n区别\n资料要求\n1. 线性相关要求X,Y服从双变量正态分布，对这种资料进行回归分析称为\\(\\textrm{II}\\)型回归，即可以把X当自变量，也可以当因变量，反之亦然。2. 线性回归要求Y在给定X值时服从正态分布，X可以是精确测量和严格控制的变量，这时的回归称为型回归，即不可以把X当因变量，Y当自变量进行回归分析。\n\n\n\n\n应用\n1. 线性相关用来表达两个变量间的互依关系，两个变量的研究地位是相等的，谁做X，谁做Y都可以；2. 线性回归用来表达两个变量间的依存变化的数量关系，即一个变量（为因变量Y）如何依存于另一个变量（为自变量X）而变化，两个变量的研究地位是不相等的。\n\n\n\n意义\n1. 相关系数r说明具有线性关系的两个变量之间的密切程度和相关方向；2. 回归系数b表示X每变化一个单位所导致的Y的平均变化量。\n\n\n\nr和b的取值范围\nr没有单位，而b有单位（其单位是：Y的单位/X的单位），所以导致两者的取值范围不同；\\(-1 \\le r \\le 1\\),\\(-\\infty&lt;b&lt;+\\infty\\)\n\n\n\n\nr和b的计算公式不同\n\n\\(r=\\frac{l_{xy}}{\\sqrt{l_{xx}l_{yy}}}\\),\\(b=\\frac{SS_{xy}}{SS_{xx}}\\)\n\n\n\n联系\n符号\n对于既可以做相关又可作回归的同一组资料，计算出r与b的正负号相同\n\n\n\n假设检验\n对于同一组资料，相关系数和回归系数的假设检验等价。即有：\\(t_b=t_r\\)\n\n\n\n\n相互换算\n对于同一组资料，相关系数和回归系数可通过下式换算：\\(b=r\\frac{S_Y}{S_X}\\)，式中的\\(S_X,S_Y\\)分别是\\(X,Y\\)的标准差\n\n\n\n用回归解释相关\n又决定系数\\(R^2=\\frac{SS_{回}}{SS_{总}}\\in [0,1]\\)当总平方和的大小决定了相关的密切程度，回归平方和越接近总平方和，则\\(R^2\\)越接近1，相关的效果越好，说明回归效果越好，相关的密切程度也越高。",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "简单线性相关和回归"
    ]
  },
  {
    "objectID": "Learn/Basic/08-anova-test.html",
    "href": "Learn/Basic/08-anova-test.html",
    "title": "方差分析",
    "section": "",
    "text": "类目\n完全随机设计的方差分析\n\n\n\n数据要求\n独立性、正态性、方差齐性\n\n\n检验目的\n推断多个样本所代表的总体均数是否不等\n\n\n\n\\(H_0\\)与\\(H_1\\)\n\n\n\\(H_0\\):\\(\\mu_1=\\mu_2=\\dots =\\mu_a\\)，各组所代表的总体均数相等。\\(H_1\\):\\(\\mu_1,\\mu_2,\\dots,\\mu_a\\)各组总体均数不全相等（至少有一个不等式成立）\n\n\n检验统计量\n\\(F=\\frac{MS_{组间}}{MS_{组内}}\\sim(v_{组间}=k-1，v_{组内}=n-k）\\)\n\n\n关键要点\n总变异分解为组间变异和组内变异\n\n\n\n\n\n\n\n\n\n类目\n随机区组设计的方差分析\n\n\n\n数据要求\n处理组间、区组间数据满足独立、正态性和方差齐性\n\n\n处理组假设\n\n\\(H_0\\)：不同处理组水平的均数相同；\\(H_1\\)：不同处理组水平的均属不全相同\n\n\n区组假设\n\n\\(H_0\\)：不同区组对观测指标的影响很大；\\(H_1\\)：不同区组对观测指标的影响不全相同\n\n\n检验统计量\n\n\\(F=\\frac{MS_{处理}}{MS_{误差}}\\sim(v_{处理}=k-1,v_{误差}=(b-1)×(k-1))\\)\\(F=\\frac{MS_{区组}}{MS_{误差}}\\sim(v_{区组}=k-1,v_{误差}=(b-1)×(k-1))\\)\n\n\n\n关键要点\n总变异分解为处理组变异、区组变异和随机误差变异\n\n\n\n\n\n\n\n\n\n\n类目\n析因设计的方差分析\n\n\n\n数据要求\n因素之间的数据独立，样本数据满足正态性和方差齐性假设\n\n\n检验目的\n推断多个因素及其交互作用是否对观测指标存在显著影响\n\n\n主效应假设\n\n\\(H_0\\): 各因素的水平对观测指标的均数无显著影响；\\(H_1\\): 各因素的水平对观测指标的均数存在显著影响\n\n\n交互作用假设\n\n\\(H_0\\): 不同因素水平的交互作用对观测指标的均数无显著影响；\\(H_1\\): 不同因素水平的交互作用对观测指标的均数存在显著影响\n\n\n检验统计量\n\\(F=\\frac{MS_{主效应或交互作用}}{MS_{误差}}\\sim F(v_{效应},v_{误差})\\)\n\n\n关键要点\n- 总变异分解为主效应变异、交互作用变异和随机误差变异- 各因素主效应和交互作用的显著性需要单独检验- 每个因素包含多个水平，可能是固定效应或随机效应",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "方差分析"
    ]
  },
  {
    "objectID": "Learn/Basic/08-anova-test.html#完全随机设计的方差分析",
    "href": "Learn/Basic/08-anova-test.html#完全随机设计的方差分析",
    "title": "方差分析",
    "section": "",
    "text": "类目\n完全随机设计的方差分析\n\n\n\n数据要求\n独立性、正态性、方差齐性\n\n\n检验目的\n推断多个样本所代表的总体均数是否不等\n\n\n\n\\(H_0\\)与\\(H_1\\)\n\n\n\\(H_0\\):\\(\\mu_1=\\mu_2=\\dots =\\mu_a\\)，各组所代表的总体均数相等。\\(H_1\\):\\(\\mu_1,\\mu_2,\\dots,\\mu_a\\)各组总体均数不全相等（至少有一个不等式成立）\n\n\n检验统计量\n\\(F=\\frac{MS_{组间}}{MS_{组内}}\\sim(v_{组间}=k-1，v_{组内}=n-k）\\)\n\n\n关键要点\n总变异分解为组间变异和组内变异",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "方差分析"
    ]
  },
  {
    "objectID": "Learn/Basic/08-anova-test.html#随机区组设计的方差分析",
    "href": "Learn/Basic/08-anova-test.html#随机区组设计的方差分析",
    "title": "方差分析",
    "section": "",
    "text": "类目\n随机区组设计的方差分析\n\n\n\n数据要求\n处理组间、区组间数据满足独立、正态性和方差齐性\n\n\n处理组假设\n\n\\(H_0\\)：不同处理组水平的均数相同；\\(H_1\\)：不同处理组水平的均属不全相同\n\n\n区组假设\n\n\\(H_0\\)：不同区组对观测指标的影响很大；\\(H_1\\)：不同区组对观测指标的影响不全相同\n\n\n检验统计量\n\n\\(F=\\frac{MS_{处理}}{MS_{误差}}\\sim(v_{处理}=k-1,v_{误差}=(b-1)×(k-1))\\)\\(F=\\frac{MS_{区组}}{MS_{误差}}\\sim(v_{区组}=k-1,v_{误差}=(b-1)×(k-1))\\)\n\n\n\n关键要点\n总变异分解为处理组变异、区组变异和随机误差变异",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "方差分析"
    ]
  },
  {
    "objectID": "Learn/Basic/08-anova-test.html#析因设计的总结",
    "href": "Learn/Basic/08-anova-test.html#析因设计的总结",
    "title": "方差分析",
    "section": "",
    "text": "类目\n析因设计的方差分析\n\n\n\n数据要求\n因素之间的数据独立，样本数据满足正态性和方差齐性假设\n\n\n检验目的\n推断多个因素及其交互作用是否对观测指标存在显著影响\n\n\n主效应假设\n\n\\(H_0\\): 各因素的水平对观测指标的均数无显著影响；\\(H_1\\): 各因素的水平对观测指标的均数存在显著影响\n\n\n交互作用假设\n\n\\(H_0\\): 不同因素水平的交互作用对观测指标的均数无显著影响；\\(H_1\\): 不同因素水平的交互作用对观测指标的均数存在显著影响\n\n\n检验统计量\n\\(F=\\frac{MS_{主效应或交互作用}}{MS_{误差}}\\sim F(v_{效应},v_{误差})\\)\n\n\n关键要点\n- 总变异分解为主效应变异、交互作用变异和随机误差变异- 各因素主效应和交互作用的显著性需要单独检验- 每个因素包含多个水平，可能是固定效应或随机效应",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "方差分析"
    ]
  },
  {
    "objectID": "Learn/Basic/06-parameter-estimation.html",
    "href": "Learn/Basic/06-parameter-estimation.html",
    "title": "参数估计",
    "section": "",
    "text": "统计量实际上是一种对样本数据信息的压缩。一个好的统计量，应该能把样本中包含总体的信息全部提炼出来，而不损失任何信息，这样的统计量称为充分统计量（sufficient statistic）。\n\n\n抽样误差是抽样研究固有的属性，不可避免，它是由个体变异和抽样共同引起的。\n\n总体方差已知，或总体方差未知但样本量足够大时\n\n\\[\\bar X \\sim N(\\mu,\\sigma_{\\bar X}^2)\\] 将\\(\\bar X\\)标准化，有： \\[U=\\frac{\\bar X-\\mu}{\\sigma_{\\bar X}}=\\frac{\\bar X-\\mu}{\\sigma_ X/\\sqrt{n}}\\] U为标准化随机变量，\\(U\\sim N(0,1)\\)。\n若从一个非正态总体中随机抽样，且样本量足够大\\((n\\geq30)\\)，样本均数\\(\\bar X\\)的抽样分布又该如何？\n中心极限定理(Central limit theorems):中心极限定理指的是给定一个任意分布的总体\\(X\\)，只要存在有限的方差\\(\\sigma^2(\\sigma^2\\neq0)\\)，则当样本量n足够大时，样本均数\\(\\bar X\\)的抽样分布将近似的服从均数为\\(\\mu\\)和方差为\\(\\sigma_{\\bar X}^2\\)的正态分布。 \\[\\bar X\\simeq N(\\mu,\\frac{\\sigma^2}{n})\\] 在大样本量条件下，由于样本方差\\(S^2\\)对总体方差\\(\\sigma^2\\)的估计误差非常小，实践中我们可以直接用\\(S^2\\)替代\\(\\sigma^2\\)进行计算。\n每次从这些总体中随机抽取\\(n\\)个抽样，一共抽\\(m\\)次。然后把这\\(m\\)组抽样分别求出平均值。这些平均值的分布接近正态分布。\n\n\\[\\frac{(n-1)S^2}{\\sigma^2}\\sim \\chi^2(v)\\] \\(\\chi^2\\)分布式赫尔默特（F.R. Helmert）于1875年研究来自正态总体的样本方差的抽样分布时得出的，其密度函数为： \\[f_v(x)=\\begin{cases} \\frac{1}{2^{\\frac{v}{2}}\\Gamma\\left(\\frac{v}{2}\\right)}y^{\\frac{v}{2}-1}\\mathrm{e}^{-\\frac{\\chi^2}{2}},&\\chi^2&gt;0\\\\ 0,&\\chi^2\\leq0\\end{cases}\\] \\(\\chi^2\\)分布和\\(t\\)分布一样，是依赖于参数（自由度）的一簇分布。随着自由度的增加，其分布曲线由正偏态分布趋近于正态分布。\n\n\n\n\n\n\n\n率的统计指标\n计算公式\n\n\n\n样本率\\(p\\)的总体均数\n\\(\\mu_{p}=\\pi\\)\n\n\n样本量\\(p\\)的方差\n\n\\(\\sigma_p^2=\\frac{\\pi(1-\\pi)}{n}\\)(理论值);\\(S_p^2=\\frac{p(1-p)}{n}\\)(估计值)\n\n\n样本率\\(p\\)的标准差\n\n\\(\\sigma_p=\\sqrt{\\frac{\\pi(1-\\pi)}{n}}\\)(理论值);\\(S_p=\\sqrt{\\frac{p(1-p)}{n}}\\)(估计值)\n\n\n率的标准误\n\n\\(\\sigma_p=\\sqrt{\\frac{\\pi(1-\\pi)}{n}}\\)(理论值);\\(S_p=\\sqrt{\\frac{p(1-p)}{n}}\\)(估计值)\n\n\n\n\n\n\n\n\n\n均数的统计指标\n计算公式\n\n\n\n样本均数\n\\(\\bar X=\\frac{\\sum_\\limits{i=1}^{n}X_i}{n}\\)\n\n\n样本方差\n\n\\(\\sigma^2=\\frac{\\sum_\\limits{i=1}^{n}(\\mu-\\bar \\mu)^2}{n}\\)(理论值);\\(S^2=\\frac{\\sum_\\limits{i=1}^{n}(X_i-\\bar X)^2}{n-1}\\)(估计值) 1\n\n\n\n样本均数标准误(SE)\n\n\\(\\sigma_{\\bar X}=\\frac{\\sigma}{\\sqrt{n}}\\)(理论值);\\(S_{\\bar X}=\\frac{S}{\\sqrt{n}}\\)(估计值)\n\n\n\n大数定律(Law of large Numbers):当随机事件发生的次数足够多时，随机事件发生的频率趋近于预期的概率。可以简单理解为样本数量越多，其平概率越接近于期望值。大数定律的条件：\n\n独立重复事件；\n重复次数足够多。\n\n\n\n\n\n\n\n\n\n\n\n\n\n类目\n标准差\n均数的标准误\n\n\n\n定义\n描述一组变量的离散程度，并可以作为总体标准差的点估计\n描述多个样本均数的离散程度，并且是样本均数的标准差估计值\n\n\n应用\n1. 标准差越小，个体资料的离散程度就越小，说明变量值围绕均数分布越紧密，均数的代表性越好  2.估计医学参考值范围，计算变异系数和标准误\n1. 标准误越小，统计量的平均抽样误差就越小，说明样本均数和总体均数的平均差异越小，用样本均数估计总体均数的可靠性越大；2. 计算置信区间、进行假设检验\n\n\n与n的关系\nn越大，样本标准差随机波动的幅度越来越小，并且稳定在总体标准差附近\nn越大，样本均数的标准误越小，并且趋向于0\n\n\n控制方法\n个体差异，不能通过统计方法控制\n增加n，可以减小标准误\n\n\n二者联系\n1. 两者都是变异指标  2. 在n相同的情况下，标准差越大，标准误相对越大；标准差越小，标准误也相对越小。正比关系  3. \\(\\sigma_{\\bar x}=\\frac{\\sigma}{\\sqrt{n}}\\),\\(\\sigma_{\\bar x}\\)与\\(\\sigma\\)成正比，与\\(\\sqrt{n}\\)成反比。\n\n\n\n\n\n\n\n\n\n\n\n类目\n总体均数的置信区间\n医学参考值范围\n\n\n\n含义\n按照预先给定的概率，确定的包含未知总体参数\\(\\mu\\)（总体均数）的可能范围\n指特定的“正常”人群（排除了对所研究指标有影响的疾病和有关因素的人群）的生理生化指标中大多数个体的取值所在的范围\n\n\n举例\n若某一样本的均值为10，其95%可信区间为（9.5,10.5），这就表示总体均数介于（9.5,10.5）之间的可信度为95%\n假设空腹血糖95%正常值范围为（3.6,6.1），这就是指95%正常人的空腹血糖值介于（3.6,6.1）之间\n\n\n计算\n1. 总体标准差位置，且样本量n不大，根据t分布计算；2. 总体标准差未知，n足够大，正态近似法；3. 总体标准差已知，根据Z分布计算\n1. 正态分布法； 2. 偏态分布法\n\n\n用途\n总体均数的区间估计（估计未知的总体均数所在范围\n1. 个体值的波动范围；  2. 绝大多数观察对象某指标分布范围； 3. 医学判断个体某指标是否正常\n\n\n95%理解的常见误区\n\n\n\n\n区别\n\n\n\n\n\n\n在95%置信区间内有95%的总体参数在该区间？×\n在95%置信区间内，该区间包含了95%的总体参数？×\n以\\(1-\\alpha=95\\%\\)算得的100个可信区间中，平均有95个可信区间包含了总体均数，而另外5个未包含总体均数。√\n在95%置信区间，该区间有95%的可能包含总体参数？×\n该区间包含总体参数，可信度在95%。√\n总体参数有95%的可能落在该区间。×\n\n\n\n置信水平（Confidence Level）\n置信水平是指在多次重复抽样时，置信区间覆盖总体参数的比例。常见的置信水平有95%、99%等。置信水平越高，表示对总体参数的估计越保守，但置信区间也会变得更宽。\n置信区间的宽度（Width of Confidence Interval）\n置信区间的宽度是指上下限之间的距离，反映了估计的精确程度。置信区间越窄，说明估计的精度越高，越宽则精度越低。\n\n\n样本大小（Sample Size）\n样本大小是置信区间宽度的一个关键决定因素。样本量越大，标准误差越小，置信区间越窄，从而提高估计的精确度。\n样本标准差（Sample Standard Deviation）\n样本标准差反映数据的离散程度。样本的波动越大，置信区间越宽；样本的波动越小，置信区间越窄。\n置信水平\n提高置信水平（例如从95%提高到99%）会导致置信区间变宽，因为要包含更多可能的参数值范围。\n总体分布的形状\n如果数据服从正态分布且样本量较大，置信区间估计会更精确；对于非正态分布，特别是在样本量较小时，置信区间的估计可能不够准确。\n估计方法（Point Estimate and Statistical Technique）\n使用不同的统计方法（如t分布、z分布）会对置信区间的范围造成影响。通常情况下，样本量较小时采用t分布，样本量较大时可以近似采用z分布。",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "参数估计"
    ]
  },
  {
    "objectID": "Learn/Basic/06-parameter-estimation.html#统计量",
    "href": "Learn/Basic/06-parameter-estimation.html#统计量",
    "title": "参数估计",
    "section": "",
    "text": "统计量实际上是一种对样本数据信息的压缩。一个好的统计量，应该能把样本中包含总体的信息全部提炼出来，而不损失任何信息，这样的统计量称为充分统计量（sufficient statistic）。",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "参数估计"
    ]
  },
  {
    "objectID": "Learn/Basic/06-parameter-estimation.html#抽样分布",
    "href": "Learn/Basic/06-parameter-estimation.html#抽样分布",
    "title": "参数估计",
    "section": "",
    "text": "抽样误差是抽样研究固有的属性，不可避免，它是由个体变异和抽样共同引起的。\n\n总体方差已知，或总体方差未知但样本量足够大时\n\n\\[\\bar X \\sim N(\\mu,\\sigma_{\\bar X}^2)\\] 将\\(\\bar X\\)标准化，有： \\[U=\\frac{\\bar X-\\mu}{\\sigma_{\\bar X}}=\\frac{\\bar X-\\mu}{\\sigma_ X/\\sqrt{n}}\\] U为标准化随机变量，\\(U\\sim N(0,1)\\)。\n若从一个非正态总体中随机抽样，且样本量足够大\\((n\\geq30)\\)，样本均数\\(\\bar X\\)的抽样分布又该如何？\n中心极限定理(Central limit theorems):中心极限定理指的是给定一个任意分布的总体\\(X\\)，只要存在有限的方差\\(\\sigma^2(\\sigma^2\\neq0)\\)，则当样本量n足够大时，样本均数\\(\\bar X\\)的抽样分布将近似的服从均数为\\(\\mu\\)和方差为\\(\\sigma_{\\bar X}^2\\)的正态分布。 \\[\\bar X\\simeq N(\\mu,\\frac{\\sigma^2}{n})\\] 在大样本量条件下，由于样本方差\\(S^2\\)对总体方差\\(\\sigma^2\\)的估计误差非常小，实践中我们可以直接用\\(S^2\\)替代\\(\\sigma^2\\)进行计算。\n每次从这些总体中随机抽取\\(n\\)个抽样，一共抽\\(m\\)次。然后把这\\(m\\)组抽样分别求出平均值。这些平均值的分布接近正态分布。\n\n\\[\\frac{(n-1)S^2}{\\sigma^2}\\sim \\chi^2(v)\\] \\(\\chi^2\\)分布式赫尔默特（F.R. Helmert）于1875年研究来自正态总体的样本方差的抽样分布时得出的，其密度函数为： \\[f_v(x)=\\begin{cases} \\frac{1}{2^{\\frac{v}{2}}\\Gamma\\left(\\frac{v}{2}\\right)}y^{\\frac{v}{2}-1}\\mathrm{e}^{-\\frac{\\chi^2}{2}},&\\chi^2&gt;0\\\\ 0,&\\chi^2\\leq0\\end{cases}\\] \\(\\chi^2\\)分布和\\(t\\)分布一样，是依赖于参数（自由度）的一簇分布。随着自由度的增加，其分布曲线由正偏态分布趋近于正态分布。\n\n\n\n\n\n\n\n率的统计指标\n计算公式\n\n\n\n样本率\\(p\\)的总体均数\n\\(\\mu_{p}=\\pi\\)\n\n\n样本量\\(p\\)的方差\n\n\\(\\sigma_p^2=\\frac{\\pi(1-\\pi)}{n}\\)(理论值);\\(S_p^2=\\frac{p(1-p)}{n}\\)(估计值)\n\n\n样本率\\(p\\)的标准差\n\n\\(\\sigma_p=\\sqrt{\\frac{\\pi(1-\\pi)}{n}}\\)(理论值);\\(S_p=\\sqrt{\\frac{p(1-p)}{n}}\\)(估计值)\n\n\n率的标准误\n\n\\(\\sigma_p=\\sqrt{\\frac{\\pi(1-\\pi)}{n}}\\)(理论值);\\(S_p=\\sqrt{\\frac{p(1-p)}{n}}\\)(估计值)\n\n\n\n\n\n\n\n\n\n均数的统计指标\n计算公式\n\n\n\n样本均数\n\\(\\bar X=\\frac{\\sum_\\limits{i=1}^{n}X_i}{n}\\)\n\n\n样本方差\n\n\\(\\sigma^2=\\frac{\\sum_\\limits{i=1}^{n}(\\mu-\\bar \\mu)^2}{n}\\)(理论值);\\(S^2=\\frac{\\sum_\\limits{i=1}^{n}(X_i-\\bar X)^2}{n-1}\\)(估计值) 1\n\n\n\n样本均数标准误(SE)\n\n\\(\\sigma_{\\bar X}=\\frac{\\sigma}{\\sqrt{n}}\\)(理论值);\\(S_{\\bar X}=\\frac{S}{\\sqrt{n}}\\)(估计值)\n\n\n\n大数定律(Law of large Numbers):当随机事件发生的次数足够多时，随机事件发生的频率趋近于预期的概率。可以简单理解为样本数量越多，其平概率越接近于期望值。大数定律的条件：\n\n独立重复事件；\n重复次数足够多。\n\n\n\n\n\n\n\n\n\n\n\n\n\n类目\n标准差\n均数的标准误\n\n\n\n定义\n描述一组变量的离散程度，并可以作为总体标准差的点估计\n描述多个样本均数的离散程度，并且是样本均数的标准差估计值\n\n\n应用\n1. 标准差越小，个体资料的离散程度就越小，说明变量值围绕均数分布越紧密，均数的代表性越好  2.估计医学参考值范围，计算变异系数和标准误\n1. 标准误越小，统计量的平均抽样误差就越小，说明样本均数和总体均数的平均差异越小，用样本均数估计总体均数的可靠性越大；2. 计算置信区间、进行假设检验\n\n\n与n的关系\nn越大，样本标准差随机波动的幅度越来越小，并且稳定在总体标准差附近\nn越大，样本均数的标准误越小，并且趋向于0\n\n\n控制方法\n个体差异，不能通过统计方法控制\n增加n，可以减小标准误\n\n\n二者联系\n1. 两者都是变异指标  2. 在n相同的情况下，标准差越大，标准误相对越大；标准差越小，标准误也相对越小。正比关系  3. \\(\\sigma_{\\bar x}=\\frac{\\sigma}{\\sqrt{n}}\\),\\(\\sigma_{\\bar x}\\)与\\(\\sigma\\)成正比，与\\(\\sqrt{n}\\)成反比。\n\n\n\n\n\n\n\n\n\n\n\n类目\n总体均数的置信区间\n医学参考值范围\n\n\n\n含义\n按照预先给定的概率，确定的包含未知总体参数\\(\\mu\\)（总体均数）的可能范围\n指特定的“正常”人群（排除了对所研究指标有影响的疾病和有关因素的人群）的生理生化指标中大多数个体的取值所在的范围\n\n\n举例\n若某一样本的均值为10，其95%可信区间为（9.5,10.5），这就表示总体均数介于（9.5,10.5）之间的可信度为95%\n假设空腹血糖95%正常值范围为（3.6,6.1），这就是指95%正常人的空腹血糖值介于（3.6,6.1）之间\n\n\n计算\n1. 总体标准差位置，且样本量n不大，根据t分布计算；2. 总体标准差未知，n足够大，正态近似法；3. 总体标准差已知，根据Z分布计算\n1. 正态分布法； 2. 偏态分布法\n\n\n用途\n总体均数的区间估计（估计未知的总体均数所在范围\n1. 个体值的波动范围；  2. 绝大多数观察对象某指标分布范围； 3. 医学判断个体某指标是否正常\n\n\n95%理解的常见误区\n\n\n\n\n区别",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "参数估计"
    ]
  },
  {
    "objectID": "Learn/Basic/06-parameter-estimation.html#置信区间的含义与常见说法辨析",
    "href": "Learn/Basic/06-parameter-estimation.html#置信区间的含义与常见说法辨析",
    "title": "参数估计",
    "section": "",
    "text": "在95%置信区间内有95%的总体参数在该区间？×\n在95%置信区间内，该区间包含了95%的总体参数？×\n以\\(1-\\alpha=95\\%\\)算得的100个可信区间中，平均有95个可信区间包含了总体均数，而另外5个未包含总体均数。√\n在95%置信区间，该区间有95%的可能包含总体参数？×\n该区间包含总体参数，可信度在95%。√\n总体参数有95%的可能落在该区间。×",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "参数估计"
    ]
  },
  {
    "objectID": "Learn/Basic/06-parameter-estimation.html#置信区间的两要素及影响因素",
    "href": "Learn/Basic/06-parameter-estimation.html#置信区间的两要素及影响因素",
    "title": "参数估计",
    "section": "",
    "text": "置信水平（Confidence Level）\n置信水平是指在多次重复抽样时，置信区间覆盖总体参数的比例。常见的置信水平有95%、99%等。置信水平越高，表示对总体参数的估计越保守，但置信区间也会变得更宽。\n置信区间的宽度（Width of Confidence Interval）\n置信区间的宽度是指上下限之间的距离，反映了估计的精确程度。置信区间越窄，说明估计的精度越高，越宽则精度越低。\n\n\n样本大小（Sample Size）\n样本大小是置信区间宽度的一个关键决定因素。样本量越大，标准误差越小，置信区间越窄，从而提高估计的精确度。\n样本标准差（Sample Standard Deviation）\n样本标准差反映数据的离散程度。样本的波动越大，置信区间越宽；样本的波动越小，置信区间越窄。\n置信水平\n提高置信水平（例如从95%提高到99%）会导致置信区间变宽，因为要包含更多可能的参数值范围。\n总体分布的形状\n如果数据服从正态分布且样本量较大，置信区间估计会更精确；对于非正态分布，特别是在样本量较小时，置信区间的估计可能不够准确。\n估计方法（Point Estimate and Statistical Technique）\n使用不同的统计方法（如t分布、z分布）会对置信区间的范围造成影响。通常情况下，样本量较小时采用t分布，样本量较大时可以近似采用z分布。",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "参数估计"
    ]
  },
  {
    "objectID": "Learn/Basic/06-parameter-estimation.html#假设检验的基本步骤",
    "href": "Learn/Basic/06-parameter-estimation.html#假设检验的基本步骤",
    "title": "参数估计",
    "section": "\n3.1 假设检验的基本步骤",
    "text": "3.1 假设检验的基本步骤\n\n\n\n\n\n\n步骤\n内容\n\n\n\n建立假设检验，确定检验水准\n1. 双侧检验：\\(H_{0}:\\mu_{d}=0;H_{1}:\\mu_{d}\\neq 0,\\alpha=0.05\\)  2. 单侧检验：\\(H_{0}:\\mu_{d}=0;H_{1}:\\mu_{d}&lt;0或\\mu_{d}&gt;0,\\alpha=0.05\\)\n\n\n\n\n1. 假设检验是针对总体的，而非样本；2. 单双侧检验主要根据专业知识预先确定，并且还需要考虑差异的方向； 3. 单侧检验的检验效能更高。\n\n\n计算并选择检验统计量\n1. 根据研究设计方案、资料类型、样本含量大小及分析目的选用适当的检验方法，并根据样本资料计算相应的检验统计量；2. 不同的检验方法要用不同的公式计算现有样本的检验统计量（\\(t\\)检验、\\(\\chi^2\\)检验、\\(F\\)检验）；3. 检验统计量是在\\(H_{0}\\)成立的前提下计算的。\n\n\n确定P值，做出推断\n假设检验的统计学结论：1. 若\\(P\\le \\alpha\\)，按所取\\(\\alpha\\)检验水准，拒绝\\(H_{0}\\)，接受\\(H_{1}\\)，可以认为…有差异；2. 若\\(P&gt;\\alpha\\)时，现有样本信息还不足以拒绝H0，尚不能认为…有差异\n\n\n\n假设检验所做出的的结论是具有概率性质的，不是绝对的肯定或否定。不论拒绝或不拒绝\\(H_{0}\\)都可能发生错误。下结论时，只能两种：1. 两总体有无差异；2. 两样本差异有无统计学意义。",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "参数估计"
    ]
  },
  {
    "objectID": "Learn/Basic/06-parameter-estimation.html#假设检验的两型错误检验效能",
    "href": "Learn/Basic/06-parameter-estimation.html#假设检验的两型错误检验效能",
    "title": "参数估计",
    "section": "\n3.2 假设检验的两型错误、检验效能",
    "text": "3.2 假设检验的两型错误、检验效能\n\n\n\n\n\n\n\n客观实际\n拒绝\\(H_{0}\\)，接受\\(H_{1}\\)\n\n不拒绝\\(H_{0}\\)\n\n\n\n\n\n\\(H_{0}\\)成立\n\n\\(\\textrm{I}\\)型错误(\\(\\alpha\\))(假阳性) 错误拒绝实际成立的\\(H_{0}\\)\n\n正确推断(\\(1-\\alpha\\))\n\n\n\n\\(H_{0}\\)不成立\n正确推断(\\(1-\\beta\\))\\(H_{1}\\)为真，能够拒绝\\(H_{0}\\)的概率称为发现该\\(H_{1}\\)的检验效能，用\\(1-\\beta\\)表示\n\n\\(\\textrm{II}\\)型错误(\\(\\beta\\))(假阴性)不拒绝实际不成立的\\(H_{0}\\)\n\n\n\n\n\n3.2.1 \\(1-\\beta\\)的影响因素：\n\n检验水准\\(\\alpha\\)（正向）——检验水准\\(\\alpha\\)越大，检验效能越大\n\n\\(H_{0}\\)与\\(H_{1}\\)的差异大小（正向）——差异越大，检验效能越大\n样本量（正向）——样本量越大，检验效能越大\n标准差越大（反向）——个体差异（标准差）越小，检验效能越大\n单双侧检验：单侧检验效能高于双侧检验效能\n\n3.2.2 \\(\\alpha 、\\beta 、1-\\beta\\)关系：\n\n当样本量确定时，\\(\\alpha\\)与\\(\\beta\\)呈反向变化关系，与\\(1-\\beta\\)呈正向变化关系。如果把\\(\\alpha\\)设置得很小，势必增加犯\\(\\textrm{II}\\)型错误的概率，从而降低检验效能；反之，如果把重点放在减少\\(\\beta\\)上，势必增加犯\\(\\textrm{I}\\)型错误的概率，从而降低了置信度。\n要同时减小\\(\\alpha\\)和\\(\\beta\\)，只有通过增加样本含量来计算。",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "参数估计"
    ]
  },
  {
    "objectID": "Learn/Basic/06-parameter-estimation.html#假设检验与置信区间的关系",
    "href": "Learn/Basic/06-parameter-estimation.html#假设检验与置信区间的关系",
    "title": "参数估计",
    "section": "\n3.3 假设检验与置信区间的关系",
    "text": "3.3 假设检验与置信区间的关系\n\n\n\n\n\n\n\n基本思想\n假设检验\n置信区间\n\n\n\n基本思想\n假设检验的假设是指我们对总体特征（如参数、分布）的某种推测，从而用概率来判断样本数据所提供的的信息和我们对总体特征猜想的一致性，进而结合专业知识判断这一猜想的正确性\n置信区间是指有样本统计量所构造的总体参数的估计区间，区间估计是按照一定的概率和可信度\\((1-\\alpha)\\)用一个区间估计总体参数所在的范围，这个范围称作可信度为\\((1-\\alpha)\\)的可信区间\n\n\n区别\n1. 假设检验用于推断总体参数之间是否不同\n1. 置信区间用于推断总体参数所在范围； 2.置信区间比假设检验提供更多的信息，置信区间能够回答假设检验的问题； 3. 置信区间在回答差别有无统计学意义时，还可以提示差别是否具有实际意义。\n\n\n联系\n1. 假设检验与置信区间都属于统计推断方法；2. 置信区间估计总体参数所采用的的统计量与假设检验的检验统计量相同；\n3.置信区间能够回答假设检验的问题。根据置信度\\(1-\\alpha\\)构造置信区间，如果统计量在置信区间内，那么不拒绝原假设；如果不在置信区间中，那么拒绝原假设；4. 双侧检验时，置信区间确定的\\(z'\\)与检验水准\\(\\alpha\\)确定的检验统计量的分布界值相同，因此，在双侧检验时\\(C=1-\\alpha\\)。根据显著水平\\(\\alpha\\)，可以构造置信度为\\(1-\\alpha\\)的置信区间",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "参数估计"
    ]
  },
  {
    "objectID": "Learn/Basic/06-parameter-estimation.html#footnotes",
    "href": "Learn/Basic/06-parameter-estimation.html#footnotes",
    "title": "参数估计",
    "section": "脚注",
    "text": "脚注\n\n无偏方差:\\(S^2\\)作为样本方差，称之为无偏方差。样本方差是度量样本离散程度的统计量，其中n为样本量， \\(\\sum_{i=1}^{n}(x_i-\\bar x)^2\\)为偏差平方和，\\(n-1\\)称为偏差平方和的自由度，因为在\\(\\bar x\\)确定后，\\(x_i(i=1,2,\\dots,n)\\)中只有\\(n-1\\)个可以自由变动。↩︎",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "参数估计"
    ]
  },
  {
    "objectID": "Learn/Basic/04-discrete-type-random-variable.html",
    "href": "Learn/Basic/04-discrete-type-random-variable.html",
    "title": "离散型随机变量的概率分布",
    "section": "",
    "text": "type of data\n\n\n定义：\\(n\\)次伯努利试验，成功的次数为\\(X\\)的离散概率分布，其中每次试验的成功概率为\\(\\pi\\)，失败的概率为\\(1-\\pi\\)。\n\n\n\\(X\\)的总体均数\\(\\mu_{x}=n\\pi\\)\n\n总体方差\\(\\sigma_{x}=n\\pi(1-\\pi)\\)\n\n\nnotice：\n\n实际上，当\\(n=1\\)时，二项分布就是伯努利试验。\n伯努利试验要求：互斥、独立、重复\n\n\n\n\n\n\nBinomial Distribution with Different n/π\n\n\n\n\n定义：描述在单位面积、单位时间或单位空间中罕见事件发生次数的概率分布为泊松分布，记作\\(P(\\mu)\\)。泊松分布是二项分布的极限形式，当一个二项分布的\\(n\\)很大，\\(\\pi\\)很小时，此时，这个二项分布近似于泊松分布。\n\n其总体均数与总体方差相等，记为\\(\\mu\\)\n\n可加性：\\(X\\sim P(\\mu_{1})\\)，\\(Y\\sim P(\\mu_{2})\\)，若\\(X\\)与\\(Y\\) 独立，则\\(X+Y \\sim P(\\mu_{1}+\\mu_{1})\\)\n\n泊松分布只有一个参数\\(\\lambda(\\mu)\\)\n\n服从泊松分布的随机变量，其取值为\\(0\\)到\\(+\\infty\\)的概率之和为1\n一般来说，当\\(\\mu \\ge20\\)时，可以认为近似正态分布\n\n\nlibrary(ggplot2)\n# Define the range for x\nx &lt;- 0:40\n\n# Define the lambda values\nlambdas &lt;- c(1, 4, 10, 20)\n\n# Set up the plot area\nplot(x, dpois(x, lambdas[1]), type=\"n\", ylim=c(0, max(dpois(x, lambdas))), \n     xlab=\"x\", ylab=\"Probability\", main=\"Poisson Distribution with Different λ Values\")\n\n# Plot the Poisson distributions for each lambda\ncolors &lt;- c(\"blue\", \"green\", \"red\", \"purple\")\nfor (i in 1:length(lambdas)) {\n  lines(x, dpois(x, lambdas[i]), type=\"b\", pch=19, col=colors[i])\n}\n\n# Add a legend\nlegend(\"topright\", legend=paste(\"λ =\", lambdas), col=colors, pch=19)\n\n\n\n\n\n\n\n\n\n\n\nPoisson Distribution with Different λ=nπ\n\n\n\n\n\n统计描述角度：直接法计算概率 [ Pr(X=K)={k}(1-){n-k},k=0,1,2,3,,n ]\n统计推断角度：区间估计、假设检验\n\n\n统计描述角度：直接法计算概率 [ Pr(X=K)=,k=0,1,2,]\n统计推断角度：区间估计、假设检验",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "离散型随机变量的概率分布"
    ]
  },
  {
    "objectID": "Learn/Basic/04-discrete-type-random-variable.html#二项分布binomial-distribution",
    "href": "Learn/Basic/04-discrete-type-random-variable.html#二项分布binomial-distribution",
    "title": "离散型随机变量的概率分布",
    "section": "",
    "text": "定义：\\(n\\)次伯努利试验，成功的次数为\\(X\\)的离散概率分布，其中每次试验的成功概率为\\(\\pi\\)，失败的概率为\\(1-\\pi\\)。\n\n\n\\(X\\)的总体均数\\(\\mu_{x}=n\\pi\\)\n\n总体方差\\(\\sigma_{x}=n\\pi(1-\\pi)\\)\n\n\nnotice：\n\n实际上，当\\(n=1\\)时，二项分布就是伯努利试验。\n伯努利试验要求：互斥、独立、重复\n\n\n\n\n\n\nBinomial Distribution with Different n/π",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "离散型随机变量的概率分布"
    ]
  },
  {
    "objectID": "Learn/Basic/04-discrete-type-random-variable.html#泊松分布poission-distribution",
    "href": "Learn/Basic/04-discrete-type-random-variable.html#泊松分布poission-distribution",
    "title": "离散型随机变量的概率分布",
    "section": "",
    "text": "定义：描述在单位面积、单位时间或单位空间中罕见事件发生次数的概率分布为泊松分布，记作\\(P(\\mu)\\)。泊松分布是二项分布的极限形式，当一个二项分布的\\(n\\)很大，\\(\\pi\\)很小时，此时，这个二项分布近似于泊松分布。\n\n其总体均数与总体方差相等，记为\\(\\mu\\)\n\n可加性：\\(X\\sim P(\\mu_{1})\\)，\\(Y\\sim P(\\mu_{2})\\)，若\\(X\\)与\\(Y\\) 独立，则\\(X+Y \\sim P(\\mu_{1}+\\mu_{1})\\)\n\n泊松分布只有一个参数\\(\\lambda(\\mu)\\)\n\n服从泊松分布的随机变量，其取值为\\(0\\)到\\(+\\infty\\)的概率之和为1\n一般来说，当\\(\\mu \\ge20\\)时，可以认为近似正态分布\n\n\nlibrary(ggplot2)\n# Define the range for x\nx &lt;- 0:40\n\n# Define the lambda values\nlambdas &lt;- c(1, 4, 10, 20)\n\n# Set up the plot area\nplot(x, dpois(x, lambdas[1]), type=\"n\", ylim=c(0, max(dpois(x, lambdas))), \n     xlab=\"x\", ylab=\"Probability\", main=\"Poisson Distribution with Different λ Values\")\n\n# Plot the Poisson distributions for each lambda\ncolors &lt;- c(\"blue\", \"green\", \"red\", \"purple\")\nfor (i in 1:length(lambdas)) {\n  lines(x, dpois(x, lambdas[i]), type=\"b\", pch=19, col=colors[i])\n}\n\n# Add a legend\nlegend(\"topright\", legend=paste(\"λ =\", lambdas), col=colors, pch=19)\n\n\n\n\n\n\n\n\n\n\n\nPoisson Distribution with Different λ=nπ",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "离散型随机变量的概率分布"
    ]
  },
  {
    "objectID": "Learn/Basic/04-discrete-type-random-variable.html#二项分布的应用",
    "href": "Learn/Basic/04-discrete-type-random-variable.html#二项分布的应用",
    "title": "离散型随机变量的概率分布",
    "section": "",
    "text": "统计描述角度：直接法计算概率 [ Pr(X=K)={k}(1-){n-k},k=0,1,2,3,,n ]\n统计推断角度：区间估计、假设检验",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "离散型随机变量的概率分布"
    ]
  },
  {
    "objectID": "Learn/Basic/04-discrete-type-random-variable.html#泊松分布的应用",
    "href": "Learn/Basic/04-discrete-type-random-variable.html#泊松分布的应用",
    "title": "离散型随机变量的概率分布",
    "section": "",
    "text": "统计描述角度：直接法计算概率 [ Pr(X=K)=,k=0,1,2,]\n统计推断角度：区间估计、假设检验",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "离散型随机变量的概率分布"
    ]
  },
  {
    "objectID": "Learn/Basic/02-descriptive-statistics.html",
    "href": "Learn/Basic/02-descriptive-statistics.html",
    "title": "不同资料的统计描述",
    "section": "",
    "text": "指标\n定义→本质\n表示方法\n计算方法\n应用条件\n\n\n\n\n算术均数\n先求和再平均\n(1)样本均数:\\(\\bar x\\)  (2)总体均数:\\(\\mu\\)\n(1)直接法：\\(\\bar X=\\frac{\\sum{X_{i}}}{n}\\)  (2)加权法：\\(\\bar X = \\frac{\\sum{f_{i}X_{i}}}{\\sum{f}}\\)，（\\(X\\)为组中值，\\(f\\)为频数）\n(1)对称分布，尤其是正态分布  (2)不含极端值\n\n\n几何均数\n先乘积再开方\n\\(G\\)\n(1)直接法：\\(G=\\sqrt[n]{x_{1}·x_{2}·x_{3}\\cdots}x_{n}\\)  (2)加权法：\\(G=\\ln^{-1}(\\frac{\\sum{f_{i}\\ln X_{i}}}{\\sum{f_{i}}})\\)\n(1)数据呈倍数变化或对数正态分布→正偏态分布  (2)观察值中不能有零且不能同时有正数和负数→对数性质\n\n\n中位数\n从小到大找中间  还要注意奇偶性\n\\(M\\)\n(1)直接法：n为奇数，\\(M=X_{\\frac{n+1}{x}}\\)  n为偶数，\\(M=\\frac{1}{2} (X_{\\frac{n}{2}}+X_{\\frac{n}{2}+1})\\)  (2)加权法：百分位数法\\(P_{X}=L_{X}+\\frac{i}{f_{x}}(nX\\%-\\sum{f_{i}})\\)\n任何资料\n\n\n众数\n出现次数最多\n\\\n(1)直接法：一组数据中出现次数最多的数值  加权法：f最多的组段的组中值\\(X\\)\n任何数据\n\n\n\n\n\n\n\n对称分布：算术均数\\(\\approx\\)中位数\n右偏态：算术均数\\(&gt;\\)中位数\n左偏态：算术均数\\(&lt;\\)中位数\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n指标\n本质→定义\n表示方式\n计算公式\n适用条件\n\n\n\n\n极差\n\\(X_{Max}-X_{Min}\\)\n\\(R\\)\n\n\n\n\n四分位间距/范围\n位置指标\n\\(IQR\\)\n\\(IQR=P_{75}-P_{25}\\)\n任何资料\n\n\n方差\n离均差平方和求平均\n样本：\\(s^{2}\\)  总体：\\(\\sigma^{2}\\)\n\\(s^{2}=\\frac{\\sum(x_{i}-x)^2}{(n-1)}\\)\n对称分布，尤其是正态分布;不含极端值\n\n\n标准差\n方差开根号\n样本：\\(s\\)  总体：\\(\\sigma\\)\n\\(s=\\sqrt{\\frac{\\sum(x_{i}-x)^2}{(n-1)}}\\)\n同上\n\n\n变异系数\n测量数据变异程度的相对统计量\n\\(CV\\)\n\\(CV=\\frac{s}{\\bar x}×100%\\)\n(1)单位相同：但均数相差悬殊；(2)单位不同\n\n\n\n\n\n\n\n直接法 \\[s=\\sqrt{\\frac{\\sum\\limits_{i=1}^nx_i^2-\\frac{\\left(\\sum\\limits_{i=1}^nx_i\\right)^2}{n}}{n-1}}\\]\n加权法：与讨算均数的方法类似，对频数表资料采用加权法，讨算公式为\n\n\\[s=\\sqrt{\\frac{\\sum\\limits_{k=1}^gf_kx_{mk}^2-\\left(\\sum\\limits_{k=1}^gf_kx_{mk}\\right)^2 \\left(\\sum\\limits_{k=1}^gf_k\\right)}{\\sum\\limits_{k=1}^gf_k-1}}\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n指标\n相对比\n构成比\n频率型指标\n强度性指标\n\n\n\n\n定义\n两个有关联的指标之比\n某一部分与总体之比\n某时期内累计出现的频率\n单位时间内某件事发生的频率\n\n\n计算公式\n\\(\\frac{A指标}{B指标}\\)\n\\(\\frac{某一事物总体中某一部分}{某一事物所有组成部分的总体}×100\\%\\)\n\\(\\frac{同时期实际发生某现象的观察单位数}{某时期可能发生某现象的观察单位总数}×K\\)\n\\(\\frac{发生某件事的观察单位数}{\\sum(观察单位×观察时间)}×K\\)\n\n\n量纲\n可有可无\n一般无量纲\n无\n有\n\n\n取值\n没有限制\n[0,1]\n[0,1]\n可大于1\n\n\n举例\nRR,变异系数CV\n死因构成比\n病死率，累计发病率\n发病率，发病密度\n\n\n\n\n\n\n\n绝对量指标\n\n累计增长量\n逐年增长量\n\n定基类指标\n\n定基发展速度\n定基增长速度\n\n环比类指标\n\n环比发展速度\n环比增长速度\n\n平均类指标\n\n平均发展速度\n平均增长速度\n\n\n\n\n\n\n频率型指标的解释要紧扣总体和属性\n计算相对数分母应该有足够的观察单位数 -如果观察例数太少，则相对数波动较大\n\n若因实际因素，观察例数确实过少，建议直接采用绝对数\n\n正确计算合计率：分子分母分别相加，再求合计率\n不能用结构相对数代替强度相对数，不能混淆频率型指标和强度型指标，不能以比代率\n注意资料的可比性\n不能仅用样本率比较，因为样本和总体之间存在抽样误差，需要进行假设检验推断总体的情况\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n指标\n参照人数\n目标人群\n过程\n\n\n\n\n直接标化法\n人口构成\n率\n各年龄组期望死亡数→期望死亡合计数→直接标化率\n\n\n简介标化法\n率\n人口构成\n各年龄组期望死亡数→期望死亡合计数→变化死亡比→间接标化率\n\n\n\nnotice：\n\n变化标化比\\(SMR=\\frac{实际死亡人数}{期望死亡人数}\\)\n直接标准化选择的标准是：各年龄组标准人口构成比或各年龄组标准人口数\n\n\n\n\n\n\n\n连续型变量\n\n计量资料\n定量资料\n\n离散型变量\n\n不具有分类性质的资料\n离散型定量资料\n\n分类资料\n\n有序分类资料\n等级资料\n半定量资料\n无序分类资料\n名义变量\n\n\nnotice：一般来说，统计图的选择，是综合考量了变量取值特点+研究目的。\n\n\n\n\n\n\n\n\n\n\n\n统计图\n资料类型\n分析目的\n\n\n\n\n圆图和百分条图\n构成比资料\n用圆的扇形面积或直条各段的长度表示事物各组成部分的构成情况\n\n\n直条图\n相互独立资料\n用直条长短表示相互独立的各指标的数值大小，一般用于比较不同组别的指标大小\n\n\n直方图\n连续型变量的频数分布\n用矩阵面积表示各组段的频数（频率）\n\n\n箱式图\n连续型资料\n描述数据的分布特征（包括中位数、四分位范围、最大值和最小值）\n\n\n普通线图\n连续型资料\n用线段的升降表示某事物在时间上的变化趋势、或某一现象随着另一现象变化的情况\n\n\n半对数线图\n连续型资料\n用线段的升降表示事物的相对变化速度\n\n\n散点图\n双变量连续型资料\n表示两种事物变化的相关性和趋势\n\n\n\n\n\n\n\n\n\nChoice of Statistical Charts",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "不同资料的统计描述"
    ]
  },
  {
    "objectID": "Learn/Basic/02-descriptive-statistics.html#定量资料的描述指标",
    "href": "Learn/Basic/02-descriptive-statistics.html#定量资料的描述指标",
    "title": "不同资料的统计描述",
    "section": "",
    "text": "指标\n定义→本质\n表示方法\n计算方法\n应用条件\n\n\n\n\n算术均数\n先求和再平均\n(1)样本均数:\\(\\bar x\\)  (2)总体均数:\\(\\mu\\)\n(1)直接法：\\(\\bar X=\\frac{\\sum{X_{i}}}{n}\\)  (2)加权法：\\(\\bar X = \\frac{\\sum{f_{i}X_{i}}}{\\sum{f}}\\)，（\\(X\\)为组中值，\\(f\\)为频数）\n(1)对称分布，尤其是正态分布  (2)不含极端值\n\n\n几何均数\n先乘积再开方\n\\(G\\)\n(1)直接法：\\(G=\\sqrt[n]{x_{1}·x_{2}·x_{3}\\cdots}x_{n}\\)  (2)加权法：\\(G=\\ln^{-1}(\\frac{\\sum{f_{i}\\ln X_{i}}}{\\sum{f_{i}}})\\)\n(1)数据呈倍数变化或对数正态分布→正偏态分布  (2)观察值中不能有零且不能同时有正数和负数→对数性质\n\n\n中位数\n从小到大找中间  还要注意奇偶性\n\\(M\\)\n(1)直接法：n为奇数，\\(M=X_{\\frac{n+1}{x}}\\)  n为偶数，\\(M=\\frac{1}{2} (X_{\\frac{n}{2}}+X_{\\frac{n}{2}+1})\\)  (2)加权法：百分位数法\\(P_{X}=L_{X}+\\frac{i}{f_{x}}(nX\\%-\\sum{f_{i}})\\)\n任何资料\n\n\n众数\n出现次数最多\n\\\n(1)直接法：一组数据中出现次数最多的数值  加权法：f最多的组段的组中值\\(X\\)\n任何数据\n\n\n\n\n\n\n\n对称分布：算术均数\\(\\approx\\)中位数\n右偏态：算术均数\\(&gt;\\)中位数\n左偏态：算术均数\\(&lt;\\)中位数",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "不同资料的统计描述"
    ]
  },
  {
    "objectID": "Learn/Basic/02-descriptive-statistics.html#离散数据的描述指标",
    "href": "Learn/Basic/02-descriptive-statistics.html#离散数据的描述指标",
    "title": "不同资料的统计描述",
    "section": "",
    "text": "指标\n本质→定义\n表示方式\n计算公式\n适用条件\n\n\n\n\n极差\n\\(X_{Max}-X_{Min}\\)\n\\(R\\)\n\n\n\n\n四分位间距/范围\n位置指标\n\\(IQR\\)\n\\(IQR=P_{75}-P_{25}\\)\n任何资料\n\n\n方差\n离均差平方和求平均\n样本：\\(s^{2}\\)  总体：\\(\\sigma^{2}\\)\n\\(s^{2}=\\frac{\\sum(x_{i}-x)^2}{(n-1)}\\)\n对称分布，尤其是正态分布;不含极端值\n\n\n标准差\n方差开根号\n样本：\\(s\\)  总体：\\(\\sigma\\)\n\\(s=\\sqrt{\\frac{\\sum(x_{i}-x)^2}{(n-1)}}\\)\n同上\n\n\n变异系数\n测量数据变异程度的相对统计量\n\\(CV\\)\n\\(CV=\\frac{s}{\\bar x}×100%\\)\n(1)单位相同：但均数相差悬殊；(2)单位不同\n\n\n\n\n\n\n\n直接法 \\[s=\\sqrt{\\frac{\\sum\\limits_{i=1}^nx_i^2-\\frac{\\left(\\sum\\limits_{i=1}^nx_i\\right)^2}{n}}{n-1}}\\]\n加权法：与讨算均数的方法类似，对频数表资料采用加权法，讨算公式为\n\n\\[s=\\sqrt{\\frac{\\sum\\limits_{k=1}^gf_kx_{mk}^2-\\left(\\sum\\limits_{k=1}^gf_kx_{mk}\\right)^2 \\left(\\sum\\limits_{k=1}^gf_k\\right)}{\\sum\\limits_{k=1}^gf_k-1}}\\]",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "不同资料的统计描述"
    ]
  },
  {
    "objectID": "Learn/Basic/02-descriptive-statistics.html#分类资料的描述指标",
    "href": "Learn/Basic/02-descriptive-statistics.html#分类资料的描述指标",
    "title": "不同资料的统计描述",
    "section": "",
    "text": "指标\n相对比\n构成比\n频率型指标\n强度性指标\n\n\n\n\n定义\n两个有关联的指标之比\n某一部分与总体之比\n某时期内累计出现的频率\n单位时间内某件事发生的频率\n\n\n计算公式\n\\(\\frac{A指标}{B指标}\\)\n\\(\\frac{某一事物总体中某一部分}{某一事物所有组成部分的总体}×100\\%\\)\n\\(\\frac{同时期实际发生某现象的观察单位数}{某时期可能发生某现象的观察单位总数}×K\\)\n\\(\\frac{发生某件事的观察单位数}{\\sum(观察单位×观察时间)}×K\\)\n\n\n量纲\n可有可无\n一般无量纲\n无\n有\n\n\n取值\n没有限制\n[0,1]\n[0,1]\n可大于1\n\n\n举例\nRR,变异系数CV\n死因构成比\n病死率，累计发病率\n发病率，发病密度\n\n\n\n\n\n\n\n绝对量指标\n\n累计增长量\n逐年增长量\n\n定基类指标\n\n定基发展速度\n定基增长速度\n\n环比类指标\n\n环比发展速度\n环比增长速度\n\n平均类指标\n\n平均发展速度\n平均增长速度\n\n\n\n\n\n\n频率型指标的解释要紧扣总体和属性\n计算相对数分母应该有足够的观察单位数 -如果观察例数太少，则相对数波动较大\n\n若因实际因素，观察例数确实过少，建议直接采用绝对数\n\n正确计算合计率：分子分母分别相加，再求合计率\n不能用结构相对数代替强度相对数，不能混淆频率型指标和强度型指标，不能以比代率\n注意资料的可比性\n不能仅用样本率比较，因为样本和总体之间存在抽样误差，需要进行假设检验推断总体的情况",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "不同资料的统计描述"
    ]
  },
  {
    "objectID": "Learn/Basic/02-descriptive-statistics.html#率的标准化",
    "href": "Learn/Basic/02-descriptive-statistics.html#率的标准化",
    "title": "不同资料的统计描述",
    "section": "",
    "text": "指标\n参照人数\n目标人群\n过程\n\n\n\n\n直接标化法\n人口构成\n率\n各年龄组期望死亡数→期望死亡合计数→直接标化率\n\n\n简介标化法\n率\n人口构成\n各年龄组期望死亡数→期望死亡合计数→变化死亡比→间接标化率\n\n\n\nnotice：\n\n变化标化比\\(SMR=\\frac{实际死亡人数}{期望死亡人数}\\)\n直接标准化选择的标准是：各年龄组标准人口构成比或各年龄组标准人口数",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "不同资料的统计描述"
    ]
  },
  {
    "objectID": "Learn/Basic/02-descriptive-statistics.html#常见统计图",
    "href": "Learn/Basic/02-descriptive-statistics.html#常见统计图",
    "title": "不同资料的统计描述",
    "section": "",
    "text": "连续型变量\n\n计量资料\n定量资料\n\n离散型变量\n\n不具有分类性质的资料\n离散型定量资料\n\n分类资料\n\n有序分类资料\n等级资料\n半定量资料\n无序分类资料\n名义变量\n\n\nnotice：一般来说，统计图的选择，是综合考量了变量取值特点+研究目的。\n\n\n\n\n\n\n\n\n\n\n\n统计图\n资料类型\n分析目的\n\n\n\n\n圆图和百分条图\n构成比资料\n用圆的扇形面积或直条各段的长度表示事物各组成部分的构成情况\n\n\n直条图\n相互独立资料\n用直条长短表示相互独立的各指标的数值大小，一般用于比较不同组别的指标大小\n\n\n直方图\n连续型变量的频数分布\n用矩阵面积表示各组段的频数（频率）\n\n\n箱式图\n连续型资料\n描述数据的分布特征（包括中位数、四分位范围、最大值和最小值）\n\n\n普通线图\n连续型资料\n用线段的升降表示某事物在时间上的变化趋势、或某一现象随着另一现象变化的情况\n\n\n半对数线图\n连续型资料\n用线段的升降表示事物的相对变化速度\n\n\n散点图\n双变量连续型资料\n表示两种事物变化的相关性和趋势\n\n\n\n\n\n\n\n\n\nChoice of Statistical Charts",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "不同资料的统计描述"
    ]
  },
  {
    "objectID": "Learn/Basic/02-descriptive-statistics.html#常见的概率抽样",
    "href": "Learn/Basic/02-descriptive-statistics.html#常见的概率抽样",
    "title": "不同资料的统计描述",
    "section": "2.1 常见的概率抽样",
    "text": "2.1 常见的概率抽样\n\n\n\n\n\n\n\n\n\n\n\n类别\n简单随机抽样\n系统抽样\n整群抽样\n分层抽样\n多阶段抽样\n\n\n\n\n概念\n将全部的观察单位编号，形成抽样框，在抽样框中随机抽取部分观察单位组成样本\n先将总体的观察单位按照某一顺序分成n个部分，再从第一部分随机抽取第k号观察单位，依次用相等间隔，从每一部分各抽取一个观察单位组成样本\n是以“群”为基本单位的抽样方法，先将总体分成若干群，从中随机抽取一些群，被抽中群内的全部个体组成调查的样本\n先将总体中全部个体按某种特征分成若干“层”，再从每一层内随机抽取一定数量的个体组成样本\n将整个抽样过程分成若干阶段进行，在初级抽样单位中抽取二级抽样单位，又在二级抽样单位中抽取三级抽样单位\n\n\n优点\n简单直观；均数（率）及其标准误计算简便\n易于理解、简便易行；可得到按比例分配的样本；样本在总体中的分布均匀\n便于组织调查；节约成本；容易控制调查质量\n抽样误差相对较小；可对不同层采用不同的抽样方法；可对不同层进行独立分析\n充分利用各种抽样方法的优势，克服各自的不足，并能节省人力、物力\n\n\n缺点\n观察单位较多，编号在实际工作中难以实现；当总体变异大时，抽样误差较分层抽样误差大\n观察单位按顺序有周期趋势或递增（减）时易产生偏差\n样本例数一定时，抽样误差大于简单随机抽样（因样本为广泛散布于总体中\n若分层变量选择不当，层内变异较大，层间变异较小，则分层抽样失去意义\n在抽样之前要掌握各级调查单位的人口资料及特点\n\n\n适用范围\n是其他抽样方法的基础，主要用于总体不太大的情形\n主要用于按抽样顺序个体随机分布的情形\n主要用于群间差异较小的情形\n主要用于层间差异较大的情形\n大型流行病学调查\n\n\n\n误差大小： 整群抽样&gt;简单随机抽样&gt;系统抽样&gt;分层抽样\n样本量大小：整群抽样&gt;简单随机抽样&gt;系统抽样&gt;分层抽样\n概率抽样：是指每个个体被抽样抽中的概率是非零的、已知的或可计算的。",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "不同资料的统计描述"
    ]
  },
  {
    "objectID": "Learn/Basic/02-descriptive-statistics.html#常见的非概率抽样",
    "href": "Learn/Basic/02-descriptive-statistics.html#常见的非概率抽样",
    "title": "不同资料的统计描述",
    "section": "2.2 常见的非概率抽样",
    "text": "2.2 常见的非概率抽样\n\n特点\n\n不需要考虑等概率原则\n依赖研究人员的经验和专业知识\n简便易行、节约资源\n结果的稳定性容易受主观影响\n\n\n\n\n\n\n\n\n\n类别\n概念\n\n\n\n\n偶遇抽样\n又称便利抽样，指研究者根据实际情况而采用最便利的方法来选取样本，可以抽取偶然遇到的人，或选择那些距离最近的、最容易找到的人作为调查对象\n\n\n目的抽样\n又称判断抽样，指研究者根据研究目标和对情况的主观判断来选择和确定调查对象的方法，是“有目的”地去选择对总体具有代表性的样本\n\n\n滚雪球抽样\n又称链式抽样或网络抽样，指当无法了解总体情形时，可以从能找到的少数个体入手，对他们进行调查，并请他们介绍其他符合条件的人，扩大调查面，如此重复下去直到达到所需的样本量\n\n\n定额抽样\n又称配额抽样，是按照总体的某种特征（年龄、性别、社会阶层等）进行分层（组），然后在每一层（组）中按照事先规定的比例或数量（即定额）用便利抽样或目的抽样的方法选取样本\n\n\n空间抽样\n指对具有空间关联性的各种调查对象及资源进行抽样的一种方法\n\n\n\nend.",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "不同资料的统计描述"
    ]
  },
  {
    "objectID": "Learn/Basic/00-basic.html",
    "href": "Learn/Basic/00-basic.html",
    "title": "医学统计学基础",
    "section": "",
    "text": "本章主要介绍基本的医学统计学内容，主要参照内容为：人卫第八版《卫生统计学》、科社第二版《医学统计学（基础版）》。\n\n章节主要分布如下：\n\n绪论\n\n医学统计学\n统计学的基本概念\n统计学在医学科研中的基本步骤\n统计学与相关学科的关系\n\n描述性统计\n随机事件与概率\n离散型随机变量\n连续型随机变量\n参数估计\n一个正态总体参数的假设检验\n两个正态总体参数的假设检验\n单因素方差分析\n多因素方差分析\n\\(\\chi^2\\)检验\n基于秩次的非参数检验\n一元线性回归\n相关分析\n\nend.",
    "crumbs": [
      "Home",
      "医学统计学基础"
    ]
  },
  {
    "objectID": "Guide/SAS/SAS-intro.html",
    "href": "Guide/SAS/SAS-intro.html",
    "title": "SAS",
    "section": "",
    "text": "SAS introduction\nSAS的历史很长，很强大，但是现代化做的一般（交互界面）。\n使用场景也是有限的，至少一般情况下用不上这么高级的工具。\n但是在某些领域又是极其重要的，像银行和药企，他们要追求足够的稳定和严谨，那么多年不曾有重大改变且一向以稳定著称的 SAS 自然可以很好的满足这一需求。\n\nSAS 对学术研究的支持是比较不友好的。正版太贵，除非学校有提供，个人基本不可能使用正版，这里下载破解版，搞SID(SAS的授权证书)需要时间成本，还容易有安装问题，没错你可以选择使用SAS的教育版，不过谁用谁知道。\n安装比较麻烦，尤其是在Linux上，我曾用两周的时间折腾在 Linux 上安装一个 SAS ，最后以失败告终，且在互联网上找不到解决的方案，AI也束手无策。\nSAS不开源，意味着你看到某些论文，里面使用一些比较新的统计分析方法，SAS不大可能有现成代码可以使用，而 Python 和 R 则大几率有现成的包可以调用，这里也会节省不少时间。\nSAS的强大一方面是性能稳定，可以处理几十上百GB的数据而不容易崩溃，但是医学数据一般容量比较小，并不是非得SAS才能跑的动。\nSAS相比其他编程语言来说是独树一帜(奇葩)的存在（proc和data步独步天下），从语法上面来说并没有什么和它相接近的语言，相反 R 和 Python 则会和一般的编程语言例如 Java, C 等有一些类似的地方，对以后万一还需要学习其他语言或者学习以后新诞生的编程软件诞有一定帮助。\nSAS 的支持有限，互联网上关于 SAS 的使用信息较少，一般都在出版的书中有可复现的内容，也没有像 Python 和 R 等活跃的社区可以提供较多的互动和支持，编程遇上问题不容易找到答案。\n\n用肯定能用，但是在使用中占多大的比重，就需要权衡一下，在 AI 时代，不一定要全部掌握，看得懂，知道怎么做，应该也可以了，当然如果要深入，那就另说。\n每个人的资源和时间都是有限的，用最少的资源和时间做最多的事才是最重要的。",
    "crumbs": [
      "Home",
      "统计软件使用指南",
      "SAS"
    ]
  },
  {
    "objectID": "Guide/SAS/2025-02-16-CLHLS.html",
    "href": "Guide/SAS/2025-02-16-CLHLS.html",
    "title": "使用SAS处理CLHLS数据",
    "section": "",
    "text": "“中国老年健康影响因素跟踪调查”（简称“中国老年健康调查”，英文缩写CLHLS），以下简称CLHLS数据，是由北京大学健康老龄与发展研究中心/国家发展研究院组织的老年人追踪调查，调查范围覆盖全国23个省市自治区，调查对象为65岁及以上老年人和35-64岁成年子女，调查问卷分为存活被访者问卷和死亡老人家属问卷两种。存活被访者问卷的调查内容包括老人及家庭基本状况、社会经济背景及家庭结构、经济来源和经济状况、健康和生活质量自评、认知功能、性格心理特征、日常活动能力、生活方式、生活照料、疾病治疗和医疗费承担；死亡老人家属问卷的调查内容包括老人死亡时间、死因等内容。该调查项目在1998年进行基线调查后分别于2000 年、2002年、2005年、2008-2009年、2011-2012年、2014年和2017-2018年进行了跟踪调查，最近的一次跟踪调查(2017-2018年)共访问15,874 名65+岁老年人,收集了2014-2018年期间死亡的2,226位老年人的信息。“中国老年健康调查”累计入户访问11.3万人次，其中最需照料的80岁及以上高龄老人占总样本67.4%，其余为较低龄老人和中年对照组；同时访问2.89万位65+岁已死亡被访老人的直接家庭成员，收集了老人死亡前健康状况、生活质量与医疗和照料需求成本等详细数据。CLHLS数据共有15874例样本，761个变量，由于本文主要研究老年人的自评和客观健康水平以及代际支持模式对健康水平的影响，因此需要对样本和变量进行筛选，保留符合要求的样本和变量进行后续的分析。DVN/WBO7LK_2020",
    "crumbs": [
      "Home",
      "统计软件使用指南",
      "SAS",
      "使用SAS处理CLHLS数据"
    ]
  },
  {
    "objectID": "Guide/SAS/2025-02-16-CLHLS.html#因变量的选取",
    "href": "Guide/SAS/2025-02-16-CLHLS.html#因变量的选取",
    "title": "使用SAS处理CLHLS数据",
    "section": "2.1 因变量的选取",
    "text": "2.1 因变量的选取\n老年人自评健康状况（SHEALTH）：对应变量 b12 （self-reported health），为有序变量（Ordinal），可用于衡量老年人对自身健康的主观评价，其赋值为：很好=1，好=2，一般=3，不好=4，很不好=5。\n生活自理能力（ADL）：对应变量 e1 （bathing，洗澡）、e2 （dressing，穿衣）、e3 （toileting，如厕）、e4 （indoor transferring，室内移动）、e5 （continence，大小便控制）、e6 （feeding，进食），均为有序变量（Ordinal）。通过这些变量的得分计算可体现老年人的生活自理能力。\n变量 e1b 、e2b 、e3b 、e4b 、e5b 、e6b 分别记录了在需要他人帮助情况下，这些活动的帮助持续天数，可作为辅助信息进一步分析生活自理能力情况。其变量赋值为：不需要帮扶=1，需要一个帮扶=2，需要多个帮扶=3，将其合并为ADL变量，相加值越低则表示生活自理能力越好，反之越差。\n工具型生活自理能力（IADL）：对应变量 e7 （able to go outside to visit neighbors，能外出拜访邻居）、e8 （able to go shopping by yourself，能自己去购物）、e9 （able to make food by yourself，能自己做饭）、e10 （able to wash clothes，能洗衣服）、e11 （able to walk one kilometer，能步行一公里）、e12 （able to carry 5kg weight，能搬运 5 公斤重物）、e13 （able to crouch and stand three times，能蹲下并站立三次）、e14 （able to take public transportation，能乘坐公共交通工具），均为有序变量（Ordinal）。这些变量可综合反映老年人在更复杂日常生活任务上的能力。其变量赋值为：可以=1，些微困难=2，不能=3，将其合并为IADL变量，相加值越低则表示工具型生活自理能力越好，反之越差。",
    "crumbs": [
      "Home",
      "统计软件使用指南",
      "SAS",
      "使用SAS处理CLHLS数据"
    ]
  },
  {
    "objectID": "Guide/SAS/2025-02-16-CLHLS.html#自变量的选取",
    "href": "Guide/SAS/2025-02-16-CLHLS.html#自变量的选取",
    "title": "使用SAS处理CLHLS数据",
    "section": "2.2 自变量的选取",
    "text": "2.2 自变量的选取\n经济支持：新设变量为 economic-support，对应的原始变量 f12a （how much did you receive from your son (s) or daughter (s)-in-law last year，去年从儿子或儿媳处收到多少钱）、f12b （how much did you receive from your daughter (s) or son (s)-in-law last year，去年从女儿或女婿处收到多少钱）、f12c （how much did you receive from your grandchild (ren) last year，去年从孙辈处收到多少钱），均为尺度变量（Scale），其中给与物质支持=99998，不知道=88888，缺失=99999，通过统计99998的个数来估计经济支持的程度，如果没有99998则赋值为0,。通过这些变量可衡量子女及孙辈在物质上给予老年人的经济支持。\n照料支持：新设变量为：residence，对应原始变量a51（co-residence of interviewee，受访者居住情况），有人同住=1，独居=2，住在机构=3；新设变量为living，对应变量 a52（how many people are living with you，有多少人居住在一起），数值型变量；新设变量 visit-fren，对应细分变量为f103a5 （frequent visits of the 1st child，第一个孩子的探访频率）、f103b5 （frequent visits of the 2nd child，第二个孩子的探访频率）、f103c5 （frequent visits of the 3rd child，第三个孩子的探访频率）等（一直到 f103k5 等关于各个孩子的探访频率变量），均为有序变量（Ordinal），有探访=1，没有=2，任一一个孩子=1即可认为有探访，同时给新变量赋值为1，如果没有则给新变量赋值为0。\n设置care-support变量，如果residence=1或visit-fren=1则给care-support赋值为1，否则赋值为0。\n用这些变量以老年人与子女相处和见面的频率来间接反映子女对老人的照料支持情况。\n情感支持（emotion support）：对应细分变量 f103a6 （contact with the 1st child，与第一个孩子的联系情况）、f103b6 （contact with the 2nd child，与第二个孩子的联系情况）、f103c6 （contact with the 3rd child，与第三个孩子的联系情况）等（一直到 f103k6 等关于各个孩子的联系情况变量），均为名义变量（Nominal）。根据这些变量所反映的与子女联系的情况来体现子女对老人的情感关怀。有联系=1，没联系=2，任一一个为1即可说明有孩子联系。",
    "crumbs": [
      "Home",
      "统计软件使用指南",
      "SAS",
      "使用SAS处理CLHLS数据"
    ]
  },
  {
    "objectID": "Guide/SAS/2025-02-16-CLHLS.html#控制变量的选取",
    "href": "Guide/SAS/2025-02-16-CLHLS.html#控制变量的选取",
    "title": "使用SAS处理CLHLS数据",
    "section": "2.3 控制变量的选取",
    "text": "2.3 控制变量的选取\n年龄：问卷中的 trueage “真实年龄”，用于获取老年人的实际年龄。\n性别：问卷中 a1 “性别”，男性赋值为 1，女性赋值为 2。\n受教育程度：问卷中的 f1 “受教育年限”，数值型变量，但是其中如果赋值为88或99则表示“不知道”或“缺失”。\n退休前的工作类型：问卷中 f2 “60 岁之前的主要职业”，名义变量，专业技术人员=0，政府、机构或管理人员=1，商业、服务或工业工人=2，自雇人士=3，农、林、牧或渔业工人=4，家政工人=5，军事人员=6，从未工作过=7，其他=8。\n婚姻状况：问卷中 f41 “您目前的婚姻状态是？”，将 “已婚或与伴侣同居” 赋值为 1，其他赋值为 0。\n户口类型：问卷中的 hukou “hukou type of the elderly being visited，被访老人的户口类型”， “城镇” 赋值为 1，“农村” 赋值为 2。\n社保和养老保险：问卷中的 nf64a f64b f64c（do you have any social security and social insurance now? 你是否有任何社保和社会保险？），有任何一种社保或养老保险则赋值为 1，没有赋值为 0；。\n医疗保险：问卷中f64d f64e f64f f64h(是否有医疗保险)，有任何一种医疗保险则赋值为 1，没有赋值为 0。\n子女年龄：通过对问卷中的 f103a4 f103b4 到 f103m4 来检查该老人的子女的年龄，如果最后一个还活着的孩子年龄&gt;60，赋值为1，则表示该老人的子女也是老年状态，否则为0。\n慢性病：问卷中 g15a1 g15b1 一直到 g15x1 表示是否患有某种慢性病，有任何一种慢性病赋值为 1，否则为 0。\n抽烟：问卷中 g151 “你24小时内抽烟吗？”，是赋值为 1，否赋值为 2。\n喝酒：问卷中 g161 “你24小时内饮酒吗？”，是赋值为 1，否赋值为 2。\n体育锻炼：问卷中d91 d92 分别表示“目前是否锻炼？”和“过去是否锻炼过？”，是赋值为 1，否赋值为 2。",
    "crumbs": [
      "Home",
      "统计软件使用指南",
      "SAS",
      "使用SAS处理CLHLS数据"
    ]
  },
  {
    "objectID": "Guide/SAS/2025-02-16-CLHLS.html#纳入标准",
    "href": "Guide/SAS/2025-02-16-CLHLS.html#纳入标准",
    "title": "使用SAS处理CLHLS数据",
    "section": "3.1 纳入标准",
    "text": "3.1 纳入标准\n年龄要求：年龄大于 60 岁，通过实际年龄 &gt; 60进行筛选。60 岁以上人群处于老年阶段，其健康、社会角色和代际关系有老年群体特征，符合本研究对老年人的研究范围。\n生育情况：生育过子女，通过反映生育子女数量的变量（如 f10 生育子女数），要求f10 &gt; 0。代际支持模式研究需存在代际关系，生育子女是形成代际关系的前提。\n子女存活情况：所生育子女中至少有一个存活。可通过检查如 f103a3 - f103m3 等表示孩子存活情况的变量，只要有一个值为表示存活的标识即可纳入（原始数据的变量赋值为存活=1，去世=2）。有在世子女才能开展代际支持研究。",
    "crumbs": [
      "Home",
      "统计软件使用指南",
      "SAS",
      "使用SAS处理CLHLS数据"
    ]
  },
  {
    "objectID": "Guide/SAS/2025-02-16-CLHLS.html#排除标准",
    "href": "Guide/SAS/2025-02-16-CLHLS.html#排除标准",
    "title": "使用SAS处理CLHLS数据",
    "section": "3.2 排除标准",
    "text": "3.2 排除标准\n关键变量缺失值：排除关键变量存在缺失值和无效值的样本。关键变量涵盖上述控制变量及后续分析的因变量、自变量等。缺失值或无效值会影响数据质量和分析结果准确性。\n不合理生育数量：生育子女数量超过合理上限（结合研究背景和数据确定，上限为 7）或者为缺失值，则需要排除（f10&gt;7 or f10 = null）。不合理生育数量可能是数据录入错误或特殊情况，干扰研究结果。\n通过多次尝试，以下是用于筛选的SAS代码：\n#| eval: false\n/* 导入必要的库 */\nproc import \n    datafile = 'C:\\Users\\asus\\Desktop\\test\\CLHLS\\Analysis-0214\\clhls_2018_15874.sav'  /* 请将这里替换为你的SAV文件的实际路径 */\n    out = raw_data \n    dbms = sav \n    replace;\nrun;\n\n/* 筛选合适的变量并排序 */\ndata selected_data;\n    set raw_data;\n    \n    /* 因变量 */\n    /* 老年人自评健康状况（SHEALTH） */\n    SHEALTH = b12;\n    \n    /* 生活自理能力（ADL） */\n    array adl_vars(*) e1 e2 e3 e4 e5 e6;\n    array adl_help_days(*) e1b e2b e3b e4b e5b e6b;\n    ADL = 0;\n    do i = 1 to dim(adl_vars);\n        if adl_help_days[i] = 1 then ADL = ADL + adl_vars[i];\n        else if adl_help_days[i] = 2 then ADL = ADL + adl_vars[i] * 2;\n        else if adl_help_days[i] = 3 then ADL = ADL + adl_vars[i] * 3;\n    end;\n    \n    /* 新增：生活自理障碍二分类变量 ADL2 */\n    ADL2 = 0;\n    do i = 1 to dim(adl_vars);\n        if adl_vars[i] &gt; 1 then do;\n            ADL2 = 1;\n            leave;\n        end;\n    end;\n    \n    /* 工具型生活自理能力（IADL） */\n    array iadl_vars(*) e7 e8 e9 e10 e11 e12 e13 e14;\n    IADL = 0;\n    do i = 1 to dim(iadl_vars);\n        IADL = IADL + iadl_vars[i];\n    end;\n    \n    /* 新增：工具型生活自理障碍二分类变量 IADL2 */\n    IADL2 = 0;\n    do i = 1 to dim(iadl_vars);\n        if iadl_vars[i] &gt; 1 then do;\n            IADL2 = 1;\n            leave;\n        end;\n    end;\n    \n    /* 自变量 */\n    /* 经济支持 */\n    array economic_vars(*) f12a f12b f12c;\n    economic_support = 0;\n    do i = 1 to dim(economic_vars);\n        if economic_vars[i] = 99998 then\n            economic_support = economic_support + 10000;\n        else if economic_vars[i] in (88888, 99999) then\n            continue; /* 跳过无效值或缺失值 */\n        else\n            economic_support = economic_support + economic_vars[i];\n    end;\n    \n    /* 照料支持 */\n    residence = a51;\n    living = a52;\n    array visit_freq(*) f103a5 f103b5 f103c5 f103d5 f103e5 f103f5 f103g5 f103h5 f103i5 f103j5 f103k5;\n    visit_fren = 0;\n    do i = 1 to dim(visit_freq);\n        if visit_freq[i] = 1 then do;\n            visit_fren = 1;\n            leave;\n        end;\n    end;\n    \n    /* 情感支持 */\n    array contact_vars(*) f103a6 f103b6 f103c6 f103d6 f103e6 f103f6 f103g6 f103h6 f103i6 f103j6 f103k6;\n    emotion_support = 2; /* 先假设没联系 */\n    do i = 1 to dim(contact_vars);\n        if contact_vars[i] = 1 then do;\n            emotion_support = 1;\n            leave;\n        end;\n    end;\n    \n    /* 控制变量 */\n    /* 年龄 */\n    age = trueage;\n    \n    /* 性别 */\n    gender = a1;\n    \n    /* 受教育程度 */\n    education = f1;\n    \n    /* 退休前的工作类型 */\n    job_type = f2;\n    \n    /* 婚姻状况 */\n    if f41 = 1 then marriage_status = 1; /* 假设 1 代表已婚或与伴侣同居 */\n    else marriage_status = 0;\n    \n    /* 户口类型 */\n    hukou_type = hukou;\n    \n    /* 社保和养老保险 */\n    if nf64a = 0 or f64b = 1 or f64c = 1 or f64i = 1 then social_insurance = 1;\n    else social_insurance = 0;\n    \n    /* 医疗保险 */\n    if f64d = 1 or f64e = 1 or f64g = 1 or f64h = 1 then medical_insurance = 1;\n    else medical_insurance = 0;\n    \n    /* 慢性病 */\n    array chronic_vars(*) g15a1 g15b1 g15c1 g15d1 g15e1 g15f1 g15g1 g15h1 g15i1 g15j1 g15k1 g15l1 g15m1 g15n1 g15o1 g15p1 g15q1 g15r1 g15s1 g15t1 g15u1 g15v1 g15w1 g15x1;\n    chronic_disease = 0;\n    do i = 1 to dim(chronic_vars);\n        if chronic_vars[i] = 1 then chronic_disease = 1;\n        if chronic_disease = 1 then leave;\n    end;\n    \n    /* 抽烟 */\n    smoking = g151;\n    \n    /* 喝酒 */\n    drinking = g161;\n    \n    /* 体育锻炼 */\n    if d91 = 1 or d92 = 1 then exercise = 1;\n    else exercise = 2;\n\n    /* 子女年龄状态 */\n    array child_ages(*) f103a4 f103b4 f103c4 f103d4 f103e4 f103f4 f103g4 f103h4 f103i4 f103j4 f103k4 f103l4 f103m4;\n    array child_alive(*) f103a3 f103b3 f103c3 f103d3 f103e3 f103f3 f103g3 f103h3 f103i3 f103j3 f103k3 f103l3 f103m3;\n    last_alive_child_age = .;\n    do i = dim(child_ages) to 1 by -1;\n        if child_alive[i] = 1 then do;\n            last_alive_child_age = child_ages[i];\n            leave;\n        end;\n    end;\n    if last_alive_child_age &gt; 60 then child_elderly_status = 1;\n    else child_elderly_status = 0;\n\n    /* 生成 care - support 变量 */\n    if residence = 1 or visit_fren = 1 then care_support = 1;\n    else care_support = 0;\n    \n    /* 选择需要的变量 */\n    keep SHEALTH ADL ADL2 IADL IADL2 economic_support residence living visit_fren emotion_support \n         f10 age gender education job_type marriage_status hukou_type \n         social_insurance medical_insurance chronic_disease smoking drinking exercise\n         child_elderly_status care_support f103a3 f103b3 f103c3 f103d3 f103e3 f103f3 f103g3 f103h3 f103i3 f103j3 f103k3 f103l3 f103m3;\nrun;\n\n/* 将筛选后的保存为 XLSX 格式文件 */\n/*\nproc export data=selected_data\n    outfile='C:\\Users\\asus\\Desktop\\test\\CLHLS\\CLHLS数据\\CLHLS数据\\clhls_2018_sort0220.xlsx'\n    dbms=xlsx\n    replace;\nrun;\n*/\n\n/*检查f10 生育子女数的分布情况*/\nproc freq data=selected_data;\n    tables f10;\nrun;\n\n/*检查子女存活状态*/\nproc freq data=selected_data;\n    tables f103a3 f103b3 f103c3 f103d3 f103e3 f103f3 f103g3 f103h3 f103i3 f103j3 f103k3 f103l3 f103m3;\nrun;\n\n/* 样本筛选 */\ndata temp_data;\n    set selected_data;\n\n    /* 纳入标准 */\n    /* 年龄要求 */\n    /*age_include = (age &gt; 60);*/\n    /* 生育情况 */\n    fertility_include = (f10 &gt; 0);\n\n    /* 子女存活情况 */\n    array child_alive(*) f103a3 f103b3 f103c3 f103d3 f103e3 f103f3 f103g3 f103h3 f103i3 f103j3 f103k3 f103l3 f103m3;\n    child_alive_include = 0;\n    do i = 1 to dim(child_alive);\n        if child_alive[i] = 1 then do;\n            child_alive_include = 1;\n            leave;\n        end;\n    end;\n    meet_include = fertility_include and child_alive_include;\n\n    /* 排除标准 */ \n    /* 关键变量缺失值检查 */\n    /*array key_vars(*) SHEALTH ADL IADL;*/\n    array key_vars(*) SHEALTH ADL ADL2 IADL IADL2 economic_support residence living visit_fren emotion_support \n                      age gender education job_type marriage_status hukou_type \n                      social_insurance medical_insurance chronic_disease smoking drinking exercise\n                      child_elderly_status care_support;\n    has_missing = 0;\n    do i = 1 to dim(key_vars);\n        if missing(key_vars[i]) then do;\n            has_missing = 1;\n            leave;\n        end;\n    end;\n    /* 不合理生育数量检查 */\n    unreasonable_fertility = (f10 &gt; 7 or missing(f10));\n    meet_exclude = has_missing or unreasonable_fertility;\n\n    /* 筛选符合条件的样本 */\n    if meet_include and not meet_exclude;\n\n\n    /* 移除临时判断变量 */\n    drop fertility_include child_alive_include has_missing unreasonable_fertility meet_include meet_exclude;\n    /*移除部分原始变量*/\n    drop f103a3 f103b3 f103c3 f103d3 f103e3 f103f3 f103g3 f103h3 f103i3 f103j3 f103k3 f103l3 f103m3;\nrun;\n\n/*打印所有变量的频数分布表，检查是否含有异常值*/\n/*\nproc freq data=final_data;\n    tables _all_;\nrun;\n*/\n\n/*还需要删除含有的样本，即某些变量中赋值为9（not applicable）和88（don't know）的样本*/\n/*具体需要剔除变量满足这些条件的样本：SHEALTH&gt;8,ADL&gt;18,IADL&gt;24,residence&gt;3,eudcation&gt;22,smoking&gt;2,drinking&gt;2*/\n/* 删除满足特定条件的样本 */\ndata final_data;\n    set temp_data;\n    if (SHEALTH &lt;= 8) and (ADL &lt;= 18) and (IADL &lt;= 24) and (residence &lt;= 3) and (age&gt;=60) and (education &lt;= 22) and (smoking &lt;= 2) and (drinking &lt;= 2);\nrun;\n\nproc freq data=final_data;\n    tables _all_;\nrun;\n\n/* 保存筛选后的数据为 XLSX 格式 */\nproc export\n    data = final_data\n    outfile = 'C:\\Users\\asus\\Desktop\\test\\CLHLS\\Analysis-0214\\final_data.xlsx' /* 请替换为实际保存路径 */\n    dbms = xlsx\n    replace;\nrun;\n\n/* 对 age 变量进行分组 */\ndata final_data_grouped;\n    set final_data;\n    if age &lt; 70 then age_group = '60 - 69';\n    else if age &lt; 80 then age_group = '70 - 79';\n    else if age &lt; 90 then age_group = '80 - 89';\n    else age_group = '90+';\nrun;\n\n/* 探查每个变量的基本统计信息，查看是否有异常值 */\nproc means data=final_data n nmiss min max mean std;\n    var SHEALTH ADL ADL2 IADL IADL2 economic_support residence living visit_fren emotion_support\n        age gender education job_type marriage_status hukou_type\n        social_insurance medical_insurance chronic_disease smoking drinking exercise\n        child_elderly_status care_support;\nrun;\n\n/* 查看字符型变量的唯一值，看是否有异常字符 */\nproc freq data=final_data_grouped;\n    tables age_group gender education job_type marriage_status hukou_type;\nrun;\n\n/* 打印因变量、自变量和控制变量的频数分布表并汇总 */\nproc freq data=final_data_grouped noprint;\n    tables SHEALTH ADL ADL2 IADL IADL2 economic_support residence living visit_fren emotion_support\n           age_group gender education job_type marriage_status hukou_type\n           social_insurance medical_insurance chronic_disease smoking drinking exercise\n           child_elderly_status care_support / out=freq_summary;\nrun;\n\n/* 导出频数汇总表到 Excel */\nproc export\n    data = freq_summary\n    outfile = 'C:\\Users\\asus\\Desktop\\test\\CLHLS\\Analysis-0214\\frequency_summary.xlsx' /* 请替换为实际保存路径 */\n    dbms = xlsx\n    replace;\nrun;\nNotes:在Qmd中输入SAS代码时，不可以直接使用\n```{sas eval=false} your SAS code here ```\n进行标注，应使用如下形式：\n```{sas} #| eval: false your code here ```\n否则会在输出报错，使用了错误的\n``````````````````` :::\n原因是因为，在 Quarto 中，fenced div 的正确语法是：\n::: {.class-name}  Content here  :::",
    "crumbs": [
      "Home",
      "统计软件使用指南",
      "SAS",
      "使用SAS处理CLHLS数据"
    ]
  },
  {
    "objectID": "Guide/R/R-install.html",
    "href": "Guide/R/R-install.html",
    "title": "MacOS安装 R 和 Rstudio",
    "section": "",
    "text": "进入官网：https://www.r-project.org/\n找到适合操作系统的安装包与合适的版本\n\n点击download R\n找个离你近的学校或者随便哪个都行\n根据电脑选择一下安装包\nmacOS需要看一下是Intel还是arm的CPU，arm目前在M1/M2上搭载\n下载到download中\n在download中查看，选中R-4.3.2-x86_64.pkg这个文件，右键后选择第一个option“open”\n\n进入安装界面\n\n然后一直continue\n出现上面页面后，点击install后需要输入电脑密码，解锁后安装\n安装完成后可以选择保留安装包或者将其移入trash（废纸篓）\n安装完成后在Launchpad中找到R，双击进入操作界面\n进入后发现系统有点缺陷，因为是新电脑，有很多不完善的地方，找了一些办法解决\nDuring startup - Warning messages:  \n1: Setting LC_CTYPE failed, using \"C\"   \n2: Setting LC_COLLATE failed, using \"C\"   \n3: Setting LC_TIME failed, using \"C\"   \n4: Setting LC_MESSAGES failed, using \"C\"   \n5: Setting LC_MONETARY failed, using \"C\"   \n[R.app GUI 1.80 (8281) x86_64-apple-darwin20]    \nWARNING: You're using a non-UTF8 locale, therefore only ASCII characters will work. Please read R for Mac OS X FAQ (see Help) section 9 and adjust your system preferences accordingly.\n以上是warning，解决办法是\n⌘+space(空格键）调出Spotlight Search，然后输入terminal再点击open，打开后输入locale查看本地的设置，得到如下\n{bash,eval = FALSE} LANG=\"\" LC_COLLATE=\"C\" LC_CTYPE=\"UTF-8\" LC_MESSAGES=\"C\" LC_MONETARY=\"C\" LC_NUMERIC=\"C\" LC_TIME=\"C\" LC_ALL=\n这些还没有配置好，进行一些配置：\n{bash，eval = FALSE}        export LC_CTYPE=en_US.UTF-8 export LC_COLLATE=en_US.UTF-8 export LC_TIME=en_US.UTF-8 export LC_MESSAGES=en_US.UTF-8 export LC_MONETARY=en_US.UTF-8\n这样就可以了。\n然后再安装Rstudio，RStudio是为R语言设计的一种跨平台集成开发环境。其特色包括可客制化的软件套件视觉化界面与同团队开发的一系列数据可视化与出版工具。\n在Rstudio中下载合适的版本，按照上述操作再来亿遍即可。",
    "crumbs": [
      "Home",
      "统计软件使用指南",
      "R introduction",
      "MacOS安装 R 和 Rstudio"
    ]
  },
  {
    "objectID": "Guide/Python/Python-intro.html",
    "href": "Guide/Python/Python-intro.html",
    "title": "Python",
    "section": "",
    "text": "Python（英式发音：/ˈpaɪθən/；美式发音：/ˈpaɪθɑːn/），是一种广泛使用的解释型、高级和通用的编程语言。Python支持多种编程范型，包括结构化、过程式、反射式、面向对象和函数式编程。它拥有动态类型系统和垃圾回收功能，能够自动管理内存使用，并且其本身拥有一个巨大而广泛的标准库。它的语言结构以及面向对象的方法，旨在帮助程序员为小型的和大型的项目编写逻辑清晰的代码。\n和Python结缘在2020年末，当时朋友正在学，我也跟着一起，跑了几个代码，做了几个图，但是没有啥应用计划，后来就没咋关注了。\n等毕了业，有感觉应该学一学，要是工作了也算有一个技能，于是又捡了起来，还行，随着理解力的提升，逐渐能掌握这一门语言了，当然，AI 的辅助也是功不可没。\nPython 的故事很多，关于它的内容在互联网可能看一年都看不完，全世界的人都在使用它，因此我这里也不做过多的赘述，显得很多余。\n使用Python的第一步，就是来一个电脑，当然没有电脑也行，因为可以用Google的 Colab ，挺好用，如果做机器学习，是一个很好的选择（当然是要开Pro）。\n然后安装，新手就安装普通的 Python 吧，先试试，来个编辑器，用 VS code、vim、pycharm 都可以，个人推荐用 VS code（这个也要学，没那么简单）。\n再然后学会 pip 安装包/库，创建一个文件 .py 开始运行。\nMOOC和B站上有很多教程，市面上的书也很多，选一本自己看得过去/感兴趣的。\n关于书的话，这些可以看看：\n\nPython Cookbook 3rd\nPython编程:从入门到实践\nPython基础教程 \n利用Python进行数据分析（做数据分析的可以着重看这一本）\n\n等逐渐熟悉Python了，可以用下 anaconda ，对环境的管理要好不少，且可以使用 spyder（神器，就是还不支持 AI）。\nend.",
    "crumbs": [
      "Home",
      "统计软件使用历程",
      "Python"
    ]
  },
  {
    "objectID": "Guide/Guide-intro.html",
    "href": "Guide/Guide-intro.html",
    "title": "统计软件",
    "section": "",
    "text": "一些统计软件的使用记录。\n最早是学的Python，应该是20年的时候，看的MOOC上的北理嵩天老师的课程，过了一遍，没有深入研究。\n后来学的SPSS，21年，因为开始上统计学课了，课上老师用SPSS做分析演示，我还负责给全专业分发SPSS安装包和密钥，并帮他们安装。\n21年还试着用过MATLAB，因为20年的时候数学老师说可以准备数学建模的比赛，20年疫请然后没人管事，21年计算机学院的一位老师担下了这个活，随机我们组队在21年秋天比赛，但是数理教研组所承诺的培训和指导都是泡影，我和队友在数理教研室办公室待了两个晚上，不断地从互联网上查找相关的资料和代码，然后在MATLAB中进行复现，其实这个时候的认识和技能是很糟糕的，数学上了微积分和线代，但是和建模关系最大的运筹学要在大二的下学期才上。就这样，紧张又无聊的三天就这么过去了，现在来看（2025年）真的是既心酸又好笑，但是也不失为一个有趣的记忆。\n21年写完大创的论文后，就逐渐没有再关注这些软件的使用了，因为用不上，直到23年毕业的时候，又拿着SPSS做了一下毕业论文的分析。\n23年毕业后，选择了二战，暑假又回了学校和同学租房备考，在逛丁香园的时候，发现本校的一位老师在上面更新了Rmarkdown的课程，我好奇，随机花了一周的时间学了一下，是一个很好用的“thing”，结合了R、Markdown和LaTeX。正好当时需要整理统计学的笔记，随开始尝试并使用。\n其实23年的时候Posit已经在开发Quarto了，但是新事物到达普通人的视野中总是需要多耗费一些时间，到了24年我才知道有这么个“thing”，但是后面的学习节奏，不允许我抽出大量的时间来“改换门庭”。同时我的Rstudio一直无法正确的创建和使用Quarto，和社区交流后无果，只能使用VS Code来作为编辑器。\n直到24年考完空闲下来，我才开始系统地转换这个笔记并重新部署在GitHub上。\n24年上半年在长沙的时候，二战失败，五月找工作也失败。安慰自己说，没事，我可以干点别的，就重新开始学Python，并尝试学了SAS。\n25年开年朋友请我帮他做一些Stata的分析，我便拿出了22年朋友送的《Stata统计分析·社会科学应用指南》开始速成，得益于AI的发展，专供某一个方向也是不难的。在这种理解下，我开始系统地学习统计学和数据分析的内容，这个网站被用来记录和整理相关的内容与想法。\n我也不知道最后会学成什么样，但是希望能留下一些有意义的东西，以供后来者。\n2025-04-28 Stata作为一个商业软件，确有其独到之处，稳定，简便，支持很好是很好的有点，相较于R的开源与不稳定，这在多次使用与复现中是很重要的一点。最近在用R做概率图模型的时候就复现不出来，功能强大是优点，但是无法复现也就意味着断层，对于学习者来说是一件很麻烦的事情。\n2025-04-29 昨晚弄好 Stata 18 以后，晚上想起 Stata 官网说可以和 Python 联用，开发了包在 Ipython 中调用 Stata ，这很有意思，我在想，既然 Quarto 可以编译 .ipynb 文件为 PDF、html 等文件，那么是否可以在 Quarto 中使用 .ipynb 文件做一个容器，然后将 Satat 程序放在里面进行编译后，再由 Quarto 生成 html 文件，最后再组成网站，可以无损/流畅地展示 Stata 程序和输出结果。网上有 Python + Stata 结合使用的相关信息，但是没有和 Quarto 配合的，于是自己进行尝试，成功。",
    "crumbs": [
      "Home",
      "统计软件"
    ]
  },
  {
    "objectID": "Guide/Python/2025-02-20-Medical-expenses.html",
    "href": "Guide/Python/2025-02-20-Medical-expenses.html",
    "title": "用Python和Stata处理一份卫生费用数据",
    "section": "",
    "text": "本篇博客用来记录2025年1月到2月帮助学弟处理一份某二级医院2018-2023年的医疗费用，最开始用的Stata，但是越往后，越感觉到Stata的难用，以及AI对这种程序的支持程度极其有限，随改用 Python + Stata 来继续完成相关的分析。\n\n\n运行此文档需要电脑上以安装Python，并且下列包已被安装并且能被调用：\nnumpy jupyter-cache pandas openpyxl\n你可以使用 pip 或 conda 进行安装： pip install jupyter-cache\n\n\n\n我们可以使用pandas包来查看部分原始数据，数据的基本样式如下：\n\n# 安装并加载必要的包\nimport pandas as pd\nimport numpy as np\n\n# 导入 Excel 文件\nfile_path = \"C:/Users/asus/Desktop/test/stata/prepare.xlsx\"\ndata = pd.read_excel(file_path, sheet_name=0, engine='openpyxl')     \n\n# 数据脱敏，删除地方\ncolumns_to_drop = [\"籍贯\", \"出生地\"]\ndata = data.drop(columns=columns_to_drop, errors='ignore')  # errors='ignore' 防止列不存在时报错\n\n# 随机抽取10个样本数据\nsample_data = data.sample(n=10, random_state=42)\n\n# 打印样本数据\nprint(sample_data)\n\n      次数        出生日期 性别   年龄      医疗付费方式  国籍 新生儿出生体重 新生儿入院体重  民族     职业  ...  \\\n1138   1  1956-09-06  男  61岁    新型农村合作医疗  中国       －       －  汉族     农民  ...   \n2024   1  1959-08-15  女  59岁  城镇居民基本医疗保险  中国       －       －  汉族     居民  ...   \n1605   1  1973-02-05  女  45岁    新型农村合作医疗  中国       －       －  汉族     农民  ...   \n1975  11  2012-09-20  男   6岁    新型农村合作医疗  中国       －       －  汉族  学龄前儿童  ...   \n1701   1  1963-01-23  男  55岁         全自费  中国       －       －  汉族      无  ...   \n218    1  1969-06-08  女  48岁    新型农村合作医疗  中国       －       －  汉族     农民  ...   \n1344   1  1960-09-11  女  57岁    新型农村合作医疗  中国       －       －  汉族     务农  ...   \n252    1  1944-05-01  女  73岁    新型农村合作医疗  中国       －       －  汉族     农民  ...   \n1921   5  2013-10-17  女   5岁    新型农村合作医疗  中国       －       －  汉族  学龄前儿童  ...   \n643    1  1997-09-02  男  20岁         全自费  中国       －       －  汉族     战士  ...   \n\n     麻醉开始时间3 麻醉结束时间3 麻醉方式3 麻醉分级3  切口部位3 切口等级3 NNIS分级3  手术部位感染3  术前住院天数3  \\\n1138     NaN     NaN   NaN   NaN    NaN   NaN     NaN      NaN      NaN   \n2024     NaN     NaN   NaN   NaN    NaN   NaN     NaN      NaN      NaN   \n1605     NaN     NaN   NaN   NaN    NaN   NaN     NaN      NaN      NaN   \n1975     NaN     NaN   NaN   NaN    NaN   NaN     NaN      NaN      NaN   \n1701     NaN     NaN   NaN   NaN    NaN   NaN     NaN      NaN      NaN   \n218      NaN     NaN   NaN   NaN    NaN   NaN     NaN      NaN      NaN   \n1344     NaN     NaN   NaN   NaN    NaN   NaN     NaN      NaN      NaN   \n252      NaN     NaN   NaN   NaN    NaN   NaN     NaN      NaN      NaN   \n1921     NaN     NaN   NaN   NaN    NaN   NaN     NaN      NaN      NaN   \n643      NaN     NaN   NaN   NaN    NaN   NaN     NaN      NaN      NaN   \n\n     手术持续时间3  \n1138     NaN  \n2024     NaN  \n1605     NaN  \n1975     NaN  \n1701     NaN  \n218      NaN  \n1344     NaN  \n252      NaN  \n1921     NaN  \n643      NaN  \n\n[10 rows x 200 columns]\n\n\n我们可以看到，该数据的列很多，第一张表中有200列，我们需要对其进行一些筛选。\n\n\n\n从哪里开始是一个需要思考的问题，对于数据的认识决定了你处理问题的方向和效率。首先，理解数据的来源至关重要，这包括了解数据是如何收集的、收集过程中可能出现的偏差或错误。其次，明确数据的类型与结构也是关键步骤之一，不同类型的数据（如定量数据、定性数据）需要采用不同的分析方法。再者，对数据进行初步探索，比如通过可视化手段观察数据分布特征，或是计算一些基本统计量来了解数据的基本情况，能够帮助你更好地制定数据处理策略。\n在真正开始处理数据之前，还需要考虑你的目标是什么。是为了回答一个具体的问题，还是为了探索潜在的模式？明确了目标之后，才能有针对性地选择合适的工具和技术。此外，考虑到数据质量的问题，数据清洗是不可跳过的一步，它包括去除异常值、填补缺失值等操作，这对于提高分析结果的准确性非常关键。\n最后，保持对数据伦理的关注同样重要，在整个数据分析的过程中，确保遵循相关的隐私保护法规和道德标准，这样才能确保你的工作不仅有效，而且负责任。通过对数据全面而深刻的理解，你可以更加自信地从数据中提取有价值的信息，并为决策提供有力支持。\n\n\n这份Excel文件有6张sheet，分别是2018-2023年，首先需要检查这六张sheet中的变量是否一致：\n\nimport pandas as pd\n\n# 导入 Excel 文件\nfile_path = \"C:/Users/asus/Desktop/test/stata/prepare.xlsx\"\nsheet_names = [\"2018\", \"2019\", \"2020\", \"2021\", \"2022\", \"2023\"]\n\n# 读取所有 sheet 的数据\nsheets_data = {sheet: pd.read_excel(file_path, sheet_name=sheet) for sheet in sheet_names}\n\n# 获取每个 sheet 的列名\nsheets_columns = {sheet: set(data.columns) for sheet, data in sheets_data.items()}\n\n# 找出所有 sheet 的共同变量和不一致的变量\ncommon_columns = set.intersection(*sheets_columns.values())\nall_columns = set.union(*sheets_columns.values())\ninconsistent_columns = all_columns - common_columns\n\n# 打印结果\nprint(\"一致的变量名:\")\nprint(common_columns)\n\nprint(\"\\n不一致的变量名:\")\nprint(inconsistent_columns)\n\n# 打印每个 sheet 的变量\nfor sheet, columns in sheets_columns.items():\n    print(f\"\\n{sheet} 的变量: {columns}\")\n\n一致的变量名:\n{'目的', '断脐后预防性使用抗菌药物给药时间1', '6麻醉方式', '1愈合', '死亡患者尸检', '入院途径', '2.4临床诊断项目费', '清洁手术预防使用抗菌药物总天数', '麻醉结束时间1', '麻醉结束时间2', '术前使用预防性抗菌药物1', '10.其他费', '新生儿出生体重', '6.2抗菌药物费用', '7.2中草药费', '出生地', '抗菌药物使用天数', '1级别', '新生儿入院体重', '5.中医治疗费', '手术持续时间1', '术前住院天数2', '切口部位1', '病室', '性别', '病室.1', '是否有出院31天内再住院计划', '3愈合', '总药品费', '9.3手术用一次性医用材料费', '手术开始时间2', '术前使用预防性抗菌药物2', '入院诊断', '手术次数2', '断脐后预防性使用抗菌药物给药时间2', '麻醉开始时间1', '是否有使用抗菌药物2', '麻醉分级2', '3麻醉方式', '职业', '2愈合', '手术部位感染2', '5愈合', '术前预防性抗菌药物给药时间1', '1.3护理费', '输血反应', '1.1一般医疗服务费', 'RH', '2手术编码', '8.4凝血因子类制品费', '9.1检查用一次性医用材料费', '术前预防性抗菌药物给药时间2', '1手术时间', '手术操作名称1', '是否非计划重返手术室病例2', '2切口', '3手术时间', '是否有使用抗菌药物1', '入院日期', '出院诊断', '手术次数1', '血管介入治疗', '4手术编码', '6切口', '输液反应', '3.4麻醉费', '麻醉分级1', '6愈合', '患者入住重症监护室（ICU）情况', '3手术编码', '预防性抗菌药物使用时机2', '入院科别', '是否微创手术1', '药占比%', '5切口', '腔镜手术名称2', '6.1西药费', '切口等级1', '出院科别', '4切口', '出生日期', '2手术名称', '输血反应次数', '感染情况', '3手术名称', '出院日期', '细菌名称2', '是否非计划重返手术室病例1', '血管介入治疗抗菌药物使用天数', '手术预防性使用抗菌药物天数2', '1麻醉方式', '3.1非手术治疗项目费', '4愈合', '1手术名称', '5级别', '病案质量', '1.2一般治疗操作费', '术后预防性抗菌药物结束时间2', '3级别', '4手术名称', '手术操作名称2', '国籍', '是否在术后使用预防性抗菌药物2', '7.1中成药费', '8.1血费', '医疗付费方式', '9.2治疗用一次性医用材料费', '本次住院期间有无重返手术室的计划1', '6手术时间', '5手术名称', '自付金额', '离院方式', '6手术名称', '择期手术1', '手术操作编码2', '病理诊断', '细菌名称4', '6手术编码', '输液反应次数', '3.3手术治疗费', '手术部位感染1', '次数', '2麻醉方式', '3切口', '是否临床路径', '婚姻', '2.1病理诊断费', '入院前颅脑损伤昏迷时间', '本次住院期间有无重返手术室的计划2', '手术操作编码1', '麻醉开始时间2', '3.5手术费', '预防性抗菌药物使用时机1', 'NNIS分级2', '3.2临床物理治疗费', '6级别', 'NNIS分级1', '5手术时间', '2手术时间', '术后预防性抗菌药物结束时间1', '手术持续时间2', '1.4其他费用', '是否在术后使用预防性抗菌药物1', '手术结束时间1', '择期手术2', '麻醉方式1', '手术开始时间1', '切口等级2', '切口部位2', '年龄', '4.康复费', '民族', '血型', '术前住院天数1', '5手术编码', '2.2实验室诊断费', '院内感染', '1切口', '籍贯', '愈合1', '住院天数', '4级别', '总费用', '清洁手术预防使用抗菌药物品种数', '1手术编码', '手术预防性使用抗菌药物天数1', '8.3球蛋白类制品费', '腔镜手术名称1', '手术结束时间2', '2级别', '药物过敏', '5麻醉方式', '2.3影像学诊断费', '麻醉方式2', '4手术时间', '入院后颅脑损伤昏迷时间', '级别2', '8.2白蛋白类制品费', '细菌名称1', '是否药物过敏', '细菌名称3', '8.5细胞因子类制品费', '级别1'}\n\n不一致的变量名:\n{'愈合2', '手术开始时间3', '7手术编码', '7级别', '7切口', '手术部位感染3', '手术次数3', '8麻醉方式', '7手术时间', '手术持续时间3', '是否微创手术2', '8手术时间', '8愈合', '4麻醉方式', '麻醉开始时间3', '术前住院天数3', '切口部位3', 'NNIS分级3', '8切口', '麻醉结束时间3', '麻醉分级3', '8手术编码', '切口等级3', '手术操作名称3', '麻醉方式3', '手术操作编码3', '8级别', '4麻醉医师', '8手术名称', '7愈合', '手术结束时间3', '择期手术3', '7手术名称', '7麻醉方式'}\n\n2018 的变量: {'目的', '愈合2', '断脐后预防性使用抗菌药物给药时间1', '6麻醉方式', '手术开始时间3', '死亡患者尸检', '1愈合', '入院途径', '2.4临床诊断项目费', '清洁手术预防使用抗菌药物总天数', '麻醉结束时间1', '麻醉结束时间2', '术前使用预防性抗菌药物1', '10.其他费', '新生儿出生体重', '6.2抗菌药物费用', '7.2中草药费', '出生地', '抗菌药物使用天数', '1级别', '新生儿入院体重', '5.中医治疗费', '手术持续时间1', '术前住院天数2', '切口部位1', '病室', '性别', '病室.1', '是否有出院31天内再住院计划', '3愈合', '总药品费', '9.3手术用一次性医用材料费', '手术开始时间2', '术前使用预防性抗菌药物2', '入院诊断', '手术次数2', '断脐后预防性使用抗菌药物给药时间2', '麻醉结束时间3', '麻醉开始时间1', '切口等级3', '是否有使用抗菌药物2', '麻醉分级2', '3麻醉方式', '职业', '2愈合', '手术部位感染2', '麻醉方式3', '5愈合', '术前预防性抗菌药物给药时间1', '1.3护理费', '输血反应', '1.1一般医疗服务费', 'RH', '2手术编码', '8.4凝血因子类制品费', '9.1检查用一次性医用材料费', '术前预防性抗菌药物给药时间2', '1手术时间', '手术操作名称1', '是否非计划重返手术室病例2', '2切口', '手术部位感染3', '3手术时间', '是否有使用抗菌药物1', '入院日期', '出院诊断', '手术次数1', '血管介入治疗', '4手术编码', '6切口', '输液反应', '3.4麻醉费', '麻醉分级1', '麻醉开始时间3', '6愈合', '切口部位3', '患者入住重症监护室（ICU）情况', '3手术编码', '预防性抗菌药物使用时机2', '入院科别', '是否微创手术1', '药占比%', '5切口', '腔镜手术名称2', '6.1西药费', '切口等级1', '出院科别', '手术操作名称3', '4切口', '出生日期', '2手术名称', '输血反应次数', '感染情况', '3手术名称', '手术操作编码3', '出院日期', '细菌名称2', '是否非计划重返手术室病例1', '血管介入治疗抗菌药物使用天数', '手术预防性使用抗菌药物天数2', '手术结束时间3', '1麻醉方式', '3.1非手术治疗项目费', '择期手术3', '4愈合', '1手术名称', '病案质量', '5级别', '1.2一般治疗操作费', '术后预防性抗菌药物结束时间2', '3级别', '手术次数3', '4手术名称', '手术操作名称2', '国籍', '是否在术后使用预防性抗菌药物2', '7.1中成药费', '8.1血费', '医疗付费方式', '手术持续时间3', '9.2治疗用一次性医用材料费', '本次住院期间有无重返手术室的计划1', '6手术时间', '是否微创手术2', '5手术名称', '自付金额', '离院方式', '6手术名称', '择期手术1', '手术操作编码2', '病理诊断', '细菌名称4', '6手术编码', '输液反应次数', '4麻醉方式', '3.3手术治疗费', '术前住院天数3', '手术部位感染1', '次数', '2麻醉方式', '3切口', '是否临床路径', '婚姻', '2.1病理诊断费', '入院前颅脑损伤昏迷时间', '本次住院期间有无重返手术室的计划2', '麻醉分级3', '手术操作编码1', '麻醉开始时间2', '3.5手术费', '预防性抗菌药物使用时机1', 'NNIS分级2', '3.2临床物理治疗费', '6级别', 'NNIS分级1', '5手术时间', '2手术时间', '术后预防性抗菌药物结束时间1', '手术持续时间2', '1.4其他费用', '是否在术后使用预防性抗菌药物1', '手术结束时间1', '择期手术2', '麻醉方式1', '手术开始时间1', '切口等级2', '切口部位2', '年龄', '4.康复费', '民族', '血型', '术前住院天数1', '5手术编码', '2.2实验室诊断费', '院内感染', '1切口', '籍贯', '愈合1', '住院天数', '4级别', '总费用', '清洁手术预防使用抗菌药物品种数', '1手术编码', '手术预防性使用抗菌药物天数1', '8.3球蛋白类制品费', '腔镜手术名称1', '手术结束时间2', 'NNIS分级3', '2级别', '药物过敏', '5麻醉方式', '2.3影像学诊断费', '麻醉方式2', '4手术时间', '入院后颅脑损伤昏迷时间', '级别2', '8.2白蛋白类制品费', '细菌名称1', '是否药物过敏', '细菌名称3', '8.5细胞因子类制品费', '级别1'}\n\n2019 的变量: {'目的', '愈合2', '断脐后预防性使用抗菌药物给药时间1', '6麻醉方式', '手术开始时间3', '死亡患者尸检', '1愈合', '入院途径', '2.4临床诊断项目费', '清洁手术预防使用抗菌药物总天数', '麻醉结束时间1', '麻醉结束时间2', '术前使用预防性抗菌药物1', '10.其他费', '新生儿出生体重', '6.2抗菌药物费用', '7.2中草药费', '出生地', '抗菌药物使用天数', '1级别', '新生儿入院体重', '5.中医治疗费', '手术持续时间1', '术前住院天数2', '切口部位1', '病室', '性别', '病室.1', '是否有出院31天内再住院计划', '3愈合', '总药品费', '9.3手术用一次性医用材料费', '手术开始时间2', '术前使用预防性抗菌药物2', '入院诊断', '手术次数2', '断脐后预防性使用抗菌药物给药时间2', '麻醉开始时间1', '是否有使用抗菌药物2', '麻醉分级2', '3麻醉方式', '职业', '2愈合', '手术部位感染2', '5愈合', '术前预防性抗菌药物给药时间1', '1.3护理费', '输血反应', '1.1一般医疗服务费', 'RH', '2手术编码', '8.4凝血因子类制品费', '9.1检查用一次性医用材料费', '术前预防性抗菌药物给药时间2', '1手术时间', '手术操作名称1', '是否非计划重返手术室病例2', '7手术编码', '2切口', '3手术时间', '是否有使用抗菌药物1', '入院日期', '7手术时间', '出院诊断', '手术次数1', '血管介入治疗', '4手术编码', '6切口', '输液反应', '3.4麻醉费', '麻醉分级1', '6愈合', '患者入住重症监护室（ICU）情况', '3手术编码', '预防性抗菌药物使用时机2', '入院科别', '是否微创手术1', '药占比%', '5切口', '腔镜手术名称2', '6.1西药费', '切口等级1', '出院科别', '手术操作名称3', '4切口', '出生日期', '2手术名称', '输血反应次数', '感染情况', '3手术名称', '手术操作编码3', '出院日期', '细菌名称2', '是否非计划重返手术室病例1', '血管介入治疗抗菌药物使用天数', '手术预防性使用抗菌药物天数2', '手术结束时间3', '1麻醉方式', '3.1非手术治疗项目费', '4愈合', '1手术名称', '5级别', '病案质量', '7级别', '7切口', '3级别', '1.2一般治疗操作费', '术后预防性抗菌药物结束时间2', '手术次数3', '4手术名称', '手术操作名称2', '国籍', '是否在术后使用预防性抗菌药物2', '7.1中成药费', '8.1血费', '医疗付费方式', '9.2治疗用一次性医用材料费', '本次住院期间有无重返手术室的计划1', '6手术时间', '是否微创手术2', '5手术名称', '自付金额', '离院方式', '6手术名称', '择期手术1', '手术操作编码2', '病理诊断', '细菌名称4', '6手术编码', '输液反应次数', '4麻醉方式', '3.3手术治疗费', '手术部位感染1', '次数', '2麻醉方式', '3切口', '是否临床路径', '婚姻', '2.1病理诊断费', '入院前颅脑损伤昏迷时间', '本次住院期间有无重返手术室的计划2', '手术操作编码1', '麻醉开始时间2', '3.5手术费', '预防性抗菌药物使用时机1', 'NNIS分级2', '3.2临床物理治疗费', '6级别', 'NNIS分级1', '7愈合', '5手术时间', '2手术时间', '术后预防性抗菌药物结束时间1', '7麻醉方式', '手术持续时间2', '1.4其他费用', '是否在术后使用预防性抗菌药物1', '手术结束时间1', '择期手术2', '麻醉方式1', '手术开始时间1', '切口等级2', '切口部位2', '年龄', '4.康复费', '民族', '血型', '术前住院天数1', '5手术编码', '2.2实验室诊断费', '院内感染', '1切口', '籍贯', '愈合1', '住院天数', '4级别', '总费用', '清洁手术预防使用抗菌药物品种数', '1手术编码', '手术预防性使用抗菌药物天数1', '8.3球蛋白类制品费', '腔镜手术名称1', '手术结束时间2', '2级别', '药物过敏', '5麻醉方式', '2.3影像学诊断费', '麻醉方式2', '4手术时间', '入院后颅脑损伤昏迷时间', '级别2', '8.2白蛋白类制品费', '细菌名称1', '是否药物过敏', '细菌名称3', '8.5细胞因子类制品费', '7手术名称', '级别1'}\n\n2020 的变量: {'目的', '断脐后预防性使用抗菌药物给药时间1', '6麻醉方式', '死亡患者尸检', '1愈合', '入院途径', '2.4临床诊断项目费', '清洁手术预防使用抗菌药物总天数', '麻醉结束时间1', '麻醉结束时间2', '术前使用预防性抗菌药物1', '10.其他费', '新生儿出生体重', '6.2抗菌药物费用', '7.2中草药费', '出生地', '抗菌药物使用天数', '1级别', '新生儿入院体重', '5.中医治疗费', '手术持续时间1', '术前住院天数2', '切口部位1', '病室', '性别', '病室.1', '是否有出院31天内再住院计划', '3愈合', '总药品费', '9.3手术用一次性医用材料费', '手术开始时间2', '术前使用预防性抗菌药物2', '入院诊断', '手术次数2', '断脐后预防性使用抗菌药物给药时间2', '麻醉开始时间1', '是否有使用抗菌药物2', '麻醉分级2', '3麻醉方式', '职业', '2愈合', '手术部位感染2', '5愈合', '术前预防性抗菌药物给药时间1', '1.3护理费', '输血反应', '1.1一般医疗服务费', 'RH', '2手术编码', '8.4凝血因子类制品费', '9.1检查用一次性医用材料费', '术前预防性抗菌药物给药时间2', '1手术时间', '手术操作名称1', '是否非计划重返手术室病例2', '7手术编码', '2切口', '3手术时间', '是否有使用抗菌药物1', '入院日期', '7手术时间', '出院诊断', '手术次数1', '血管介入治疗', '4手术编码', '6切口', '输液反应', '3.4麻醉费', '麻醉分级1', '6愈合', '患者入住重症监护室（ICU）情况', '3手术编码', '预防性抗菌药物使用时机2', '入院科别', '是否微创手术1', '药占比%', '5切口', '腔镜手术名称2', '6.1西药费', '切口等级1', '出院科别', '4切口', '出生日期', '2手术名称', '输血反应次数', '感染情况', '3手术名称', '出院日期', '细菌名称2', '是否非计划重返手术室病例1', '血管介入治疗抗菌药物使用天数', '手术预防性使用抗菌药物天数2', '1麻醉方式', '3.1非手术治疗项目费', '4愈合', '1手术名称', '5级别', '病案质量', '7级别', '7切口', '3级别', '1.2一般治疗操作费', '术后预防性抗菌药物结束时间2', '4手术名称', '手术操作名称2', '国籍', '是否在术后使用预防性抗菌药物2', '7.1中成药费', '8.1血费', '医疗付费方式', '9.2治疗用一次性医用材料费', '本次住院期间有无重返手术室的计划1', '6手术时间', '5手术名称', '自付金额', '离院方式', '6手术名称', '择期手术1', '手术操作编码2', '病理诊断', '细菌名称4', '8愈合', '6手术编码', '4麻醉方式', '3.3手术治疗费', '输液反应次数', '手术部位感染1', '次数', '2麻醉方式', '3切口', '是否临床路径', '婚姻', '2.1病理诊断费', '入院前颅脑损伤昏迷时间', '本次住院期间有无重返手术室的计划2', '8手术编码', '手术操作编码1', '麻醉开始时间2', '3.5手术费', '预防性抗菌药物使用时机1', 'NNIS分级2', '3.2临床物理治疗费', '6级别', 'NNIS分级1', '8手术名称', '7愈合', '5手术时间', '2手术时间', '术后预防性抗菌药物结束时间1', '7麻醉方式', '手术持续时间2', '1.4其他费用', '是否在术后使用预防性抗菌药物1', '手术结束时间1', '择期手术2', '麻醉方式1', '手术开始时间1', '8麻醉方式', '切口等级2', '切口部位2', '年龄', '4.康复费', '民族', '血型', '术前住院天数1', '5手术编码', '2.2实验室诊断费', '院内感染', '1切口', '籍贯', '8手术时间', '愈合1', '住院天数', '4级别', '总费用', '清洁手术预防使用抗菌药物品种数', '1手术编码', '手术预防性使用抗菌药物天数1', '8.3球蛋白类制品费', '腔镜手术名称1', '手术结束时间2', '2级别', '8切口', '药物过敏', '5麻醉方式', '2.3影像学诊断费', '麻醉方式2', '4手术时间', '入院后颅脑损伤昏迷时间', '8级别', '级别2', '8.2白蛋白类制品费', '细菌名称1', '是否药物过敏', '细菌名称3', '8.5细胞因子类制品费', '7手术名称', '级别1'}\n\n2021 的变量: {'目的', '断脐后预防性使用抗菌药物给药时间1', '6麻醉方式', '死亡患者尸检', '1愈合', '入院途径', '2.4临床诊断项目费', '清洁手术预防使用抗菌药物总天数', '麻醉结束时间1', '麻醉结束时间2', '术前使用预防性抗菌药物1', '10.其他费', '新生儿出生体重', '6.2抗菌药物费用', '7.2中草药费', '出生地', '抗菌药物使用天数', '1级别', '新生儿入院体重', '5.中医治疗费', '手术持续时间1', '术前住院天数2', '切口部位1', '病室', '性别', '病室.1', '是否有出院31天内再住院计划', '3愈合', '总药品费', '9.3手术用一次性医用材料费', '手术开始时间2', '术前使用预防性抗菌药物2', '入院诊断', '手术次数2', '断脐后预防性使用抗菌药物给药时间2', '麻醉开始时间1', '是否有使用抗菌药物2', '麻醉分级2', '3麻醉方式', '职业', '2愈合', '手术部位感染2', '5愈合', '术前预防性抗菌药物给药时间1', '1.3护理费', '输血反应', '1.1一般医疗服务费', 'RH', '2手术编码', '8.4凝血因子类制品费', '9.1检查用一次性医用材料费', '术前预防性抗菌药物给药时间2', '1手术时间', '手术操作名称1', '是否非计划重返手术室病例2', '7手术编码', '2切口', '3手术时间', '是否有使用抗菌药物1', '入院日期', '7手术时间', '出院诊断', '手术次数1', '血管介入治疗', '4手术编码', '6切口', '输液反应', '3.4麻醉费', '麻醉分级1', '6愈合', '患者入住重症监护室（ICU）情况', '3手术编码', '预防性抗菌药物使用时机2', '入院科别', '是否微创手术1', '药占比%', '5切口', '腔镜手术名称2', '6.1西药费', '切口等级1', '出院科别', '4切口', '出生日期', '2手术名称', '输血反应次数', '感染情况', '3手术名称', '出院日期', '细菌名称2', '是否非计划重返手术室病例1', '血管介入治疗抗菌药物使用天数', '手术预防性使用抗菌药物天数2', '1麻醉方式', '3.1非手术治疗项目费', '4愈合', '1手术名称', '5级别', '病案质量', '7级别', '7切口', '3级别', '1.2一般治疗操作费', '术后预防性抗菌药物结束时间2', '4手术名称', '手术操作名称2', '国籍', '是否在术后使用预防性抗菌药物2', '7.1中成药费', '8.1血费', '医疗付费方式', '9.2治疗用一次性医用材料费', '本次住院期间有无重返手术室的计划1', '6手术时间', '5手术名称', '自付金额', '离院方式', '6手术名称', '择期手术1', '手术操作编码2', '病理诊断', '细菌名称4', '6手术编码', '8愈合', '4麻醉方式', '3.3手术治疗费', '输液反应次数', '手术部位感染1', '次数', '2麻醉方式', '3切口', '是否临床路径', '婚姻', '2.1病理诊断费', '入院前颅脑损伤昏迷时间', '本次住院期间有无重返手术室的计划2', '8手术编码', '手术操作编码1', '麻醉开始时间2', '3.5手术费', '预防性抗菌药物使用时机1', 'NNIS分级2', '3.2临床物理治疗费', '6级别', 'NNIS分级1', '8手术名称', '7愈合', '5手术时间', '2手术时间', '术后预防性抗菌药物结束时间1', '7麻醉方式', '手术持续时间2', '1.4其他费用', '是否在术后使用预防性抗菌药物1', '手术结束时间1', '择期手术2', '麻醉方式1', '手术开始时间1', '8麻醉方式', '切口等级2', '切口部位2', '年龄', '4.康复费', '民族', '血型', '术前住院天数1', '5手术编码', '2.2实验室诊断费', '院内感染', '1切口', '籍贯', '8手术时间', '愈合1', '住院天数', '4级别', '总费用', '清洁手术预防使用抗菌药物品种数', '1手术编码', '手术预防性使用抗菌药物天数1', '8.3球蛋白类制品费', '腔镜手术名称1', '手术结束时间2', '2级别', '8切口', '药物过敏', '5麻醉方式', '2.3影像学诊断费', '麻醉方式2', '4手术时间', '入院后颅脑损伤昏迷时间', '8级别', '级别2', '8.2白蛋白类制品费', '细菌名称1', '是否药物过敏', '细菌名称3', '8.5细胞因子类制品费', '7手术名称', '级别1'}\n\n2022 的变量: {'目的', '断脐后预防性使用抗菌药物给药时间1', '6麻醉方式', '死亡患者尸检', '1愈合', '入院途径', '2.4临床诊断项目费', '清洁手术预防使用抗菌药物总天数', '麻醉结束时间1', '麻醉结束时间2', '术前使用预防性抗菌药物1', '10.其他费', '新生儿出生体重', '6.2抗菌药物费用', '7.2中草药费', '出生地', '抗菌药物使用天数', '1级别', '新生儿入院体重', '5.中医治疗费', '手术持续时间1', '术前住院天数2', '切口部位1', '病室', '性别', '病室.1', '是否有出院31天内再住院计划', '3愈合', '总药品费', '9.3手术用一次性医用材料费', '手术开始时间2', '术前使用预防性抗菌药物2', '入院诊断', '手术次数2', '断脐后预防性使用抗菌药物给药时间2', '麻醉开始时间1', '是否有使用抗菌药物2', '麻醉分级2', '3麻醉方式', '职业', '2愈合', '手术部位感染2', '5愈合', '术前预防性抗菌药物给药时间1', '1.3护理费', '输血反应', '1.1一般医疗服务费', 'RH', '2手术编码', '8.4凝血因子类制品费', '9.1检查用一次性医用材料费', '术前预防性抗菌药物给药时间2', '1手术时间', '手术操作名称1', '是否非计划重返手术室病例2', '7手术编码', '2切口', '3手术时间', '是否有使用抗菌药物1', '入院日期', '7手术时间', '出院诊断', '手术次数1', '血管介入治疗', '4手术编码', '6切口', '输液反应', '3.4麻醉费', '麻醉分级1', '6愈合', '患者入住重症监护室（ICU）情况', '3手术编码', '预防性抗菌药物使用时机2', '入院科别', '是否微创手术1', '药占比%', '5切口', '腔镜手术名称2', '6.1西药费', '切口等级1', '出院科别', '4切口', '出生日期', '2手术名称', '输血反应次数', '感染情况', '3手术名称', '出院日期', '细菌名称2', '是否非计划重返手术室病例1', '血管介入治疗抗菌药物使用天数', '手术预防性使用抗菌药物天数2', '1麻醉方式', '3.1非手术治疗项目费', '4愈合', '1手术名称', '5级别', '病案质量', '7级别', '7切口', '3级别', '1.2一般治疗操作费', '术后预防性抗菌药物结束时间2', '4手术名称', '手术操作名称2', '国籍', '是否在术后使用预防性抗菌药物2', '7.1中成药费', '8.1血费', '医疗付费方式', '9.2治疗用一次性医用材料费', '本次住院期间有无重返手术室的计划1', '6手术时间', '5手术名称', '自付金额', '离院方式', '6手术名称', '择期手术1', '手术操作编码2', '病理诊断', '细菌名称4', '6手术编码', '8愈合', '4麻醉方式', '3.3手术治疗费', '输液反应次数', '手术部位感染1', '次数', '2麻醉方式', '3切口', '是否临床路径', '婚姻', '2.1病理诊断费', '入院前颅脑损伤昏迷时间', '本次住院期间有无重返手术室的计划2', '8手术编码', '手术操作编码1', '麻醉开始时间2', '3.5手术费', '预防性抗菌药物使用时机1', 'NNIS分级2', '3.2临床物理治疗费', '6级别', 'NNIS分级1', '8手术名称', '7愈合', '5手术时间', '2手术时间', '术后预防性抗菌药物结束时间1', '7麻醉方式', '手术持续时间2', '1.4其他费用', '是否在术后使用预防性抗菌药物1', '手术结束时间1', '择期手术2', '麻醉方式1', '手术开始时间1', '8麻醉方式', '切口等级2', '切口部位2', '年龄', '4.康复费', '民族', '血型', '术前住院天数1', '5手术编码', '2.2实验室诊断费', '院内感染', '1切口', '籍贯', '8手术时间', '愈合1', '住院天数', '4级别', '总费用', '清洁手术预防使用抗菌药物品种数', '1手术编码', '手术预防性使用抗菌药物天数1', '8.3球蛋白类制品费', '腔镜手术名称1', '手术结束时间2', '2级别', '8切口', '药物过敏', '5麻醉方式', '2.3影像学诊断费', '麻醉方式2', '4手术时间', '入院后颅脑损伤昏迷时间', '8级别', '级别2', '8.2白蛋白类制品费', '细菌名称1', '是否药物过敏', '细菌名称3', '8.5细胞因子类制品费', '7手术名称', '级别1'}\n\n2023 的变量: {'目的', '断脐后预防性使用抗菌药物给药时间1', '6麻醉方式', '死亡患者尸检', '1愈合', '入院途径', '2.4临床诊断项目费', '清洁手术预防使用抗菌药物总天数', '麻醉结束时间1', '麻醉结束时间2', '术前使用预防性抗菌药物1', '10.其他费', '新生儿出生体重', '6.2抗菌药物费用', '7.2中草药费', '出生地', '抗菌药物使用天数', '1级别', '新生儿入院体重', '5.中医治疗费', '手术持续时间1', '术前住院天数2', '切口部位1', '病室', '性别', '病室.1', '是否有出院31天内再住院计划', '3愈合', '总药品费', '9.3手术用一次性医用材料费', '手术开始时间2', '术前使用预防性抗菌药物2', '入院诊断', '手术次数2', '断脐后预防性使用抗菌药物给药时间2', '麻醉开始时间1', '是否有使用抗菌药物2', '麻醉分级2', '3麻醉方式', '职业', '2愈合', '手术部位感染2', '5愈合', '术前预防性抗菌药物给药时间1', '1.3护理费', '输血反应', '1.1一般医疗服务费', 'RH', '2手术编码', '8.4凝血因子类制品费', '9.1检查用一次性医用材料费', '术前预防性抗菌药物给药时间2', '1手术时间', '手术操作名称1', '是否非计划重返手术室病例2', '7手术编码', '2切口', '3手术时间', '是否有使用抗菌药物1', '入院日期', '7手术时间', '出院诊断', '手术次数1', '血管介入治疗', '4手术编码', '6切口', '输液反应', '3.4麻醉费', '麻醉分级1', '6愈合', '患者入住重症监护室（ICU）情况', '3手术编码', '预防性抗菌药物使用时机2', '入院科别', '是否微创手术1', '药占比%', '5切口', '腔镜手术名称2', '6.1西药费', '切口等级1', '出院科别', '4切口', '出生日期', '2手术名称', '输血反应次数', '感染情况', '3手术名称', '出院日期', '细菌名称2', '4麻醉医师', '血管介入治疗抗菌药物使用天数', '是否非计划重返手术室病例1', '手术预防性使用抗菌药物天数2', '1麻醉方式', '3.1非手术治疗项目费', '4愈合', '1手术名称', '5级别', '病案质量', '7级别', '7切口', '3级别', '1.2一般治疗操作费', '术后预防性抗菌药物结束时间2', '4手术名称', '手术操作名称2', '国籍', '是否在术后使用预防性抗菌药物2', '7.1中成药费', '8.1血费', '医疗付费方式', '9.2治疗用一次性医用材料费', '本次住院期间有无重返手术室的计划1', '6手术时间', '5手术名称', '自付金额', '离院方式', '6手术名称', '择期手术1', '手术操作编码2', '病理诊断', '细菌名称4', '6手术编码', '8愈合', '输液反应次数', '3.3手术治疗费', '手术部位感染1', '次数', '2麻醉方式', '3切口', '是否临床路径', '婚姻', '2.1病理诊断费', '入院前颅脑损伤昏迷时间', '本次住院期间有无重返手术室的计划2', '8手术编码', '手术操作编码1', '麻醉开始时间2', '3.5手术费', '预防性抗菌药物使用时机1', 'NNIS分级2', '3.2临床物理治疗费', '6级别', 'NNIS分级1', '8手术名称', '7愈合', '5手术时间', '2手术时间', '术后预防性抗菌药物结束时间1', '7麻醉方式', '手术持续时间2', '1.4其他费用', '是否在术后使用预防性抗菌药物1', '手术结束时间1', '择期手术2', '麻醉方式1', '手术开始时间1', '8麻醉方式', '切口等级2', '切口部位2', '年龄', '4.康复费', '民族', '血型', '术前住院天数1', '5手术编码', '2.2实验室诊断费', '院内感染', '1切口', '籍贯', '8手术时间', '愈合1', '住院天数', '4级别', '总费用', '清洁手术预防使用抗菌药物品种数', '1手术编码', '手术预防性使用抗菌药物天数1', '8.3球蛋白类制品费', '腔镜手术名称1', '手术结束时间2', '2级别', '8切口', '药物过敏', '5麻醉方式', '2.3影像学诊断费', '麻醉方式2', '4手术时间', '入院后颅脑损伤昏迷时间', '8级别', '级别2', '8.2白蛋白类制品费', '细菌名称1', '是否药物过敏', '细菌名称3', '8.5细胞因子类制品费', '7手术名称', '级别1'}\n\n\n然后剔除不一致的变量数据，同时创建一个新变量year，用sheet的年份对其进行填充，再按变量名对应合并6张表格的数据称为一张总表，命名为merge-sheet.xlsx输出到你需要存放数据的文件夹中。\n变量还是太多了，那接下来对变量进行筛选，首先我们可以对所有键值为空的变量进行剔除，或者根据实际的研究需要，剔除一部分键值全部为null的变量。\n这里我选择对键值全部为null或0的变量进行剔除。\n第一次尝试的时候，打开表后进行查看，发现变量顺序很乱，没有按照原始顺序进行排列，处理办法则是在前面的变量筛选部分使用DataFrame的loc方法选择列，同时保持列的顺序。\n同时为了节省时间，因为在Quarto中运行Python代码很慢，暂时还不知道原因，待以后调试一下。所以最后用一个程序解决上述这些问题，节省时间。\n\nimport pandas as pd\n\n# 导入 Excel 文件\nfile_path = \"C:/Users/asus/Desktop/test/stata/prepare.xlsx\"\noutput_path = \"C:/Users/asus/Desktop/test/stata/data/merge-data.xlsx\"\nfinal_output_path = \"C:/Users/asus/Desktop/test/stata/data/cleaned-merge-data.xlsx\"\nsheet_names = [\"2018\", \"2019\", \"2020\", \"2021\", \"2022\", \"2023\"]\n\n# 读取所有 sheet 的数据\nsheets_data = {sheet: pd.read_excel(file_path, sheet_name=sheet) for sheet in sheet_names}\n\n# 获取每个 sheet 的列名\nsheets_columns = {sheet: set(data.columns) for sheet, data in sheets_data.items()}\n\n# 找出所有 sheet 的共同变量\ncommon_columns = set.intersection(*sheets_columns.values())\n# 保持原始顺序\ncommon_columns = list(common_columns)  \n\n# 剔除不一致的变量数据，并添加 year 变量\nfor sheet, data in sheets_data.items():\n    sheets_data[sheet] = data[list(common_columns)]\n    sheets_data[sheet]['year'] = sheet\n\n# 合并所有 sheet 的数据\nmerged_data = pd.concat(sheets_data.values(), ignore_index=True)\n\n# 输出合并后的数据到指定路径\nmerged_data.to_excel(output_path, index=False)\n\n# 重新导入合并后的数据\nmerged_data = pd.read_excel(output_path)\n\n# 剔除键值全部为 null 或 0 的变量，同时保持原始变量的顺序\nnon_null_columns = merged_data.dropna(axis=1, how='all').columns\nnon_zero_columns = merged_data.loc[:, (merged_data != 0).any(axis=0)].columns\nvalid_columns = [col for col in merged_data.columns if col in non_null_columns and col in non_zero_columns]\n\ncleaned_data = merged_data.loc[:, valid_columns]\n\n# 输出清理后的数据到指定路径\ncleaned_data.to_excel(final_output_path, index=False)\n\nprint(f\"清理后的数据已输出到 {final_output_path}\")\n\n# 展示部分数据\n\n# 随机抽取10个样本数据\nsample_data = cleaned_data.sample(n=10)\n\n# 打印样本数据\nprint(sample_data)\n\n清理后的数据已输出到 C:/Users/asus/Desktop/test/stata/data/cleaned-merge-data.xlsx\n      目的 断脐后预防性使用抗菌药物给药时间1 6麻醉方式  1愈合 死亡患者尸检 入院途径  2.4临床诊断项目费  \\\n14170  -               NaN   NaN  NaN    NaN   急诊      1553.0   \n20116  -               NaN   NaN  NaN    NaN   门诊      1272.5   \n37053  -               NaN   NaN  NaN    NaN   门诊         0.0   \n43824  -               NaN   NaN    甲      否   门诊      1106.0   \n32348  -               NaN   NaN  NaN    NaN   门诊       398.5   \n37403  -               NaN   NaN  NaN    NaN   门诊        29.0   \n31026  -               NaN   NaN    甲    NaN   门诊      1814.0   \n12348  -               NaN   NaN    乙    NaN   门诊       592.0   \n28312  -               NaN   NaN   其他    NaN   门诊      2022.5   \n35851  -               NaN   NaN   其他    NaN   门诊      1417.5   \n\n       清洁手术预防使用抗菌药物总天数              麻醉结束时间1 麻醉结束时间2  ...  2.3影像学诊断费 麻醉方式2  \\\n14170              NaN                  NaN     NaN  ...          0   NaN   \n20116              NaN                  NaN     NaN  ...          0   NaN   \n37053              NaN                  NaN     NaN  ...          0   NaN   \n43824              1.0  2023-07-07 12:05:33     NaN  ...        256   NaN   \n32348              NaN                  NaN     NaN  ...          0   NaN   \n37403              NaN                  NaN     NaN  ...          0   NaN   \n31026              NaN                  NaN     NaN  ...          0   NaN   \n12348              NaN                  NaN     NaN  ...          0   NaN   \n28312              NaN                  NaN     NaN  ...        640   NaN   \n35851              NaN  2022-07-07 16:25:49     NaN  ...          0   NaN   \n\n       4手术时间 入院后颅脑损伤昏迷时间  级别2  细菌名称1 是否药物过敏 细菌名称3  级别1  year  \n14170    NaN      -天-时-分  NaN    NaN      无   NaN  NaN  2020  \n20116    NaN      -天-时-分  NaN    NaN      无   NaN  NaN  2020  \n37053    NaN      -天-时-分  NaN    NaN      无   NaN  NaN  2022  \n43824    NaN      -天-时-分  NaN      -      无     -  4.0  2023  \n32348    NaN      -天-时-分  NaN    NaN      无   NaN  NaN  2022  \n37403    NaN      -天-时-分  NaN    NaN      无   NaN  NaN  2022  \n31026    NaN      -天-时-分  NaN    NaN      无   NaN  NaN  2021  \n12348    NaN      -天-时-分  NaN    NaN      无   NaN  NaN  2020  \n28312    NaN      -天-时-分  NaN    NaN      无   NaN  NaN  2021  \n35851    NaN      -天-时-分  NaN      -      无     -  2.0  2022  \n\n[10 rows x 160 columns]\n\n\n\n\n\n\n经过上述筛选后的变量依然还有很多，其中不乏无用信息变量或无效信息变量，对变量做进一步筛选。\n对样本进行筛选，需要满足在当年收治且出院，满足常规医保使用条件，关键变量含有缺失值的样本。\n使用 pandas 进行处理（根据Excel视图挑选的缺失数据的变量或含有较多缺失值的变量）：\n\nimport pandas as pd\n\n# 文件路径\ninput_file = r\"C:\\Users\\asus\\Desktop\\test\\stata\\data\\cleaned-merge-data.xlsx\"\noutput_file = r\"C:\\Users\\asus\\Desktop\\test\\stata\\data\\allclean.xlsx\"\n\n# 读取 Excel 文件\ndf = pd.read_excel(input_file)\n\n# 要删除的列列表\ncolumns_to_drop = [\n    \"新生儿出生体重\", \"新生儿入院体重\", \"国籍\", \"籍贯\", \"病室\", \"病室.1\", \"是否有出院31天内再住院计划\",\n    \"病理诊断\", \"院内感染\", \"药物过敏\", \"死亡患者尸检\", \"血型\", \"RH\",\n    \"1手术编码\", \"1手术时间\", \"1级别\", \"1切口\", \"1愈合\", \"1麻醉方式\",\n    \"2手术名称\", \"2手术编码\", \"2手术时间\", \"2级别\", \"2切口\", \"2愈合\", \"2麻醉方式\",\n    \"3手术名称\", \"3手术编码\", \"3手术时间\", \"3级别\", \"3切口\", \"3愈合\", \"3麻醉方式\",\n    \"4手术名称\", \"4手术编码\", \"4手术时间\", \"4级别\", \"4切口\", \"4愈合\", \"4麻醉方式\",\n    \"5手术名称\", \"5手术编码\", \"5手术时间\", \"5级别\", \"5切口\", \"5愈合\", \"5麻醉方式\",\n    \"6手术名称\", \"6手术编码\", \"6手术时间\", \"6级别\", \"6切口\", \"6愈合\", \"6麻醉方式\",\n    \"7手术名称\", \"7手术编码\", \"7手术时间\", \"7级别\", \"7切口\", \"7愈合\", \"7麻醉方式\",\n    \"8手术名称\", \"8手术编码\", \"8手术时间\", \"8级别\", \"8切口\", \"8愈合\", \"8麻醉方式\",\n    \"目的\", \"入院前颅脑损伤昏迷时间\", \"入院后颅脑损伤昏迷时间\",\n    \"抗菌药物使用天数\", \"清洁手术预防使用抗菌药物品种数\", \"是否临床路径\", \"清洁手术预防使用抗菌药物总天数\",\n    \"患者入住重症监护室（ICU）情况\", \"感染情况\", \"输血反应\", \"输血反应次数\", \"输液反应\", \"输液反应次数\",\n    \"细菌名称1\", \"细菌名称2\", \"细菌名称3\", \"细菌名称4\", \"血管介入治疗\", \"血管介入治疗抗菌药物使用天数\",\n    \"手术次数1\", \"手术操作名称1\", \"手术操作编码1\", \"手术开始时间1\", \"手术结束时间1\", \"择期手术1\",\n    \"麻醉开始时间1\", \"麻醉结束时间1\", \"麻醉方式1\", \"麻醉分级1\", \"切口部位1\", \"切口等级1\", \"NNIS分级1\",\n    \"手术部位感染1\", \"术前住院天数1\", \"手术持续时间1\", \"是否非计划重返手术室病例1\", \"术前使用预防性抗菌药物1\",\n    \"术前预防性抗菌药物给药时间1\", \"是否在术后使用预防性抗菌药物1\", \"术后预防性抗菌药物结束时间1\",\n    \"手术预防性使用抗菌药物天数1\", \"是否有使用抗菌药物1\", \"预防性抗菌药物使用时机1\",\n    \"断脐后预防性使用抗菌药物给药时间1\", \"本次住院期间有无重返手术室的计划1\", \"腔镜手术名称1\", \"级别1\", \"愈合1\",\n    \"是否微创手术1\", \"手术次数2\", \"手术操作名称2\", \"手术操作编码2\", \"手术开始时间2\", \"手术结束时间2\",\n    \"择期手术2\", \"麻醉开始时间2\", \"麻醉结束时间2\", \"麻醉方式2\", \"麻醉分级2\", \"切口部位2\", \"切口等级2\",\n    \"NNIS分级2\", \"手术部位感染2\", \"术前住院天数2\", \"手术持续时间2\", \"是否非计划重返手术室病例2\",\n    \"术前使用预防性抗菌药物2\", \"术前预防性抗菌药物给药时间2\", \"是否在术后使用预防性抗菌药物2\",\n    \"术后预防性抗菌药物结束时间2\", \"手术预防性使用抗菌药物天数2\", \"是否有使用抗菌药物2\",\n    \"预防性抗菌药物使用时机2\", \"断脐后预防性使用抗菌药物给药时间2\", \"本次住院期间有无重返手术室的计划2\",\n    \"腔镜手术名称2\", \"级别2\", \"愈合2\", \"是否微创手术2\", \"手术次数3\", \"手术操作名称3\", \"手术操作编码3\", \"手术开始时间3\",\n    \"手术结束时间3\", \"择期手术3\", \"麻醉开始时间3\", \"麻醉结束时间3\", \"麻醉方式3\", \"麻醉分级3\", \"切口部位3\", \"切口等级3\",\n    \"NNIS分级3\", \"手术部位感染3\", \"术前住院天数3\", \"手术持续时间3\", \"4麻醉医师\", \"出生地\", \"籍贯\"\n]\n\n# 删除指定的列\ndf = df.drop(columns=columns_to_drop, errors='ignore')\n\n# 过滤掉 '公安病区'\nif '入院科别' in df.columns and '出院科别' in df.columns:\n    df = df[~df['入院科别'].isin(['公安病区'])]\n    df = df[~df['出院科别'].isin(['公安病区'])]\n\n# 打印随机 10 个样本\nprint(\"随机 10 个样本：\")\nprint(df.sample(10))\n\n# 将处理后的 DataFrame 写入新的 Excel 文件\n# df.to_excel(output_file, index=False)\n\n# print(f\"数据清洗完成，已保存到 {output_file}\")\n\n随机 10 个样本：\n      入院途径  2.4临床诊断项目费   10.其他费  7.2中草药费 性别    总药品费  \\\n45540   门诊       225.0    28.98      0.0  女   22.17   \n27023   门诊      1105.0  9923.46      0.0  男   77.87   \n10102   门诊       178.3  3442.00      0.0  女  168.30   \n29291   门诊       977.5   511.57      0.0  女  626.99   \n18117   门诊       624.0   139.90      0.0  女  526.41   \n48037   门诊       264.9  3286.00      0.0  男   88.97   \n35602   门诊       201.0   336.92      0.0  男  723.32   \n17413   门诊      1278.5   357.29      0.0  女  702.13   \n966     门诊         0.0    24.75      0.0  女    0.00   \n14589   门诊       147.3  4724.00      0.0  女  196.45   \n\n                                                    入院诊断     职业  1.3护理费  \\\n45540                       老年核性白内障|H25.100,翼状胬肉|H11.000     农民    25.0   \n27023              结肠恶性肿瘤个人史|Z85.006,手术后恶性肿瘤化学治疗|Z51.102     农民    75.0   \n10102                       老年性白内障|H25.900,玻璃体混浊|H43.300     农民    50.0   \n29291                           结肠息肉|K63.500,胃息肉|K31.703  自由职业者   196.0   \n18117  大疱性类天疱疮|L12.000,冠状动脉粥样硬化性心脏病|I25.103,心功能Ⅲ级|I50...     居民    85.0   \n48037                                    老年核性白内障|H25.100     农民    50.0   \n35602                       节肢动物咬伤|T63.402,过敏性皮炎|L23.901     农民   200.6   \n17413                                         腹痛|R10.400     居民   125.0   \n966                                      脑外伤后综合征|F07.201      -   156.0   \n14589  老年性白内障|H25.900,翼状胬肉|H11.000,玻璃体混浊|H43.300,特指手术...     农民    50.0   \n\n       1.1一般医疗服务费  ...  婚姻  3.5手术费   年龄  民族 2.2实验室诊断费  住院天数       总费用  \\\n45540        32.0  ...  已婚     0.0  61岁  汉族     372.0     1    716.25   \n27023       105.0  ...  已婚     0.0  29岁  汉族     499.0     3  11888.53   \n10102        52.0  ...  已婚  1976.0  76岁  汉族     387.0     2   6314.60   \n29291       245.0  ...  已婚     0.0  67岁  汉族     589.0     7  11239.16   \n18117       294.0  ...  已婚     0.0  92岁  汉族    1095.0     3   3133.31   \n48037        32.0  ...  已婚  1976.0  77岁  汉族     381.0     1   6164.87   \n35602       140.0  ...  已婚     0.0  56岁  汉族     731.0     4   2475.84   \n17413       160.0  ...  已婚     0.0  60岁  汉族     608.0     5   4195.02   \n966         414.0  ...  未婚     0.0   8岁  汉族       0.0    13   7004.75   \n14589        52.0  ...  已婚  1976.0  78岁  汉族       0.0     2   7166.75   \n\n      2.3影像学诊断费 是否药物过敏  year  \n45540         0      无  2023  \n27023         0      无  2021  \n10102        36      无  2019  \n29291         0      无  2021  \n18117         0      无  2020  \n48037        36      无  2023  \n35602         0      无  2022  \n17413         0      无  2020  \n966           0      无  2018  \n14589         0      无  2020  \n\n[10 rows x 39 columns]\n\n\n\n\n\n\n\n因为需要对疾病进行分类与根据诊断信息确定来生成共病信息，根据出院诊断来对疾病进行分类与赋值，这里使用 Stata 来完成。\n**************\n* 1. 清理环境并导入数据\n**************\nclear all\n\n* 读取 Excel 文件，假设第一行为列名\nimport excel \"C:\\Users\\asus\\Desktop\\test\\stata\\data\\allclean.xlsx\", ///\n    firstrow case(lower) clear\n\n* 注意：\n*  - firstrow 表示将第一行作为变量名\n*  - case(lower) 将变量名转换为小写，避免中文或大小写冲突\n*  - 如果您的表格存在中文列名，可能需要手动 rename\n\n************************\n* 2. 处理、提取与分类: 以“出院诊断”列为例\n************************\n\n*------------------\ngen disease = 出院诊断\n*------------------\n\n* 假设您已经将\"出院诊断\"重命名为了 \"disease\"\n* 现在要从 disease 里提取 ICD 编码到 icd10 列。\n* 如果原数据已包含 icd10 这列，可跳过此步。\n* 这里只是示例，具体提取逻辑需根据实际字符串格式做 parsing:\n* 例如： 出院诊断 字符串为 \"急性化脓性阑尾炎|K35.902|有,高血压病|I10.x00|有\"\n\n*（示例）如果 disease 形如 \"XXX|K35.902|有,YYY|I10.x00|有\"\n* 可以先把逗号换成某种分隔，然后再拆分，这里仅给示例逻辑\n* 注意：以下只是思路示例，可能需正则表达式、substr、split 等更复杂处理\n\n// 对disease进行拆分\n* 1. 按 | 分隔 disease 列，生成多个新变量\nsplit disease, parse(\"|\") generate(disease_part)\n \n// 提取第一个 ICD 编码\n* 2. 提取第二部分（part2）作为 icd10，使用正则表达式剔除多余编码\n* 保留 disease_part2 的前7个字符作为 icd10，形如 C15.900\ngen icd10 = substr(disease_part2, 1, 7)\ngen icd_com = substr(disease_part4, 1, 7)\n* 去除前后的空格\nreplace icd10 = trim(icd10)\n\n* 3. 删除所有拆分部分\ndrop disease_part1-disease_part55\n\n* 4. 检查结果\nlist disease icd10 in 1/10\n\n***************************************\n* 按 ICD 数量判断是否共病\n***************************************\ngen comorbidity = 0  // 初始值为 0\nreplace comorbidity = 1 if !missing(icd10) & !missing(icd_com) \n// 如果ICD10和ICD_com都不为空，则赋值为1\n\n// 查看前10行的数据\nlist icd10 icd_com comorbidity in 1/10\n\n***************************************\n* 筛除部分变量\n***************************************\n\ndrop 入院日期 入院科别 出院日期 出院科别 出院诊断 disease 离院方式 病案质量\n\n***************************************\n* 按 ICD 编码生成截取变量\n***************************************\n\n* 如果 icd10 是数值型，转换为字符串型\ntostring icd10, replace  \n\n* 检查并创建 icd_3c 变量\ngen icd_3c = \"\"   // 如果 icd_3c 不存在，创建一个空的字符串变量\n\n* 截取 icd10 的前三位并赋值给 icd_3c\nreplace icd_3c = substr(icd10, 1, 3)  \n\n* 如果 icd_3c 是数值型，转换为字符串型\ntostring icd_3c, replace \n\n* 创建 icd_str1 变量\ngen icd_str1 = \"\"\n\n* icd_str1: ICD 编码首位\nreplace icd_str1 = substr(icd10,1,1)\n\n* 如果 icd_str1 是数值型，转换为字符串型\ntostring icd_str1, replace \n\n* 使用 trim() 来去除空格\nreplace icd_str1 = trim(icd_str1)\n\n* 查看 icd_str1 的数据类型\ndescribe icd_str1\n\n* 查看是否有空值或特殊字符\n* list icd_str1 if missing(icd_str1)\n\n************************\n* 按照ICD编码归为22类\n************************\n\n* 创建icd分类变量：icd_chapter\ngen icd_chapter = \"\" \n\n* 字符转换为数值\ndestring icd_chapter,replace\n\n// 为icd_chapter赋值\n\nreplace icd_chapter=1 if icd_str1==\"A\"|icd_str1==\"B\"\nreplace icd_chapter=2 if icd_str1==\"C\"|(icd_3c&gt;=\"D00\"&icd_3c&lt;=\"D48\")\nreplace icd_chapter=3 if icd_3c&gt;=\"D50\"&icd_3c&lt;=\"D89\"\nreplace icd_chapter=4 if icd_3c&gt;=\"E00\"&icd_3c&lt;=\"E90\"\nreplace icd_chapter=5 if icd_3c&gt;=\"F00\"&icd_3c&lt;=\"F99\"\nreplace icd_chapter=6 if icd_3c&gt;=\"G00\"&icd_3c&lt;=\"G99\"\nreplace icd_chapter=7 if icd_3c&gt;=\"H00\"&icd_3c&lt;=\"H59\"\nreplace icd_chapter=8 if icd_3c&gt;=\"H60\"&icd_3c&lt;=\"H99\"\nreplace icd_chapter=9 if icd_str1==\"I\"\nreplace icd_chapter=10 if icd_str1==\"J\"\nreplace icd_chapter=11 if icd_str1==\"K\"\nreplace icd_chapter=12 if icd_str1==\"L\"\nreplace icd_chapter=13 if icd_str1==\"M\"\nreplace icd_chapter=14 if icd_str1==\"N\"\nreplace icd_chapter=15 if icd_str1==\"O\"\nreplace icd_chapter=16 if icd_str1==\"P\"\nreplace icd_chapter=17 if icd_str1==\"Q\"\nreplace icd_chapter=18 if icd_str1==\"R\"\nreplace icd_chapter=19 if icd_str1==\"S\"| icd_str1==\"T\"\nreplace icd_chapter=20 if icd_str1==\"V\"| icd_str1==\"Y\"\nreplace icd_chapter=21 if icd_str1==\"Z\"\nreplace icd_chapter=22 if icd_str1==\"U\"\nreplace icd_chapter=20 if icd_str1==\"V\"| icd_str1==\"Y\"|icd_str1==\"X\"|icd_str1==\"W\"\nreplace icd_chapter=21 if icd_str1==\"Z\"| substr(trim(icd10),1,2)==\"WW\"\nreplace icd_chapter=22 if icd_str1==\"U\"\n\n***************************************\n* 检查分类缺失\n***************************************\ntab icd_3c if icd_chapter==.\n\n****************************\n* 3. 导出处理后的数据\n****************************\n\n* 导出为 Stata 格式\nsave \"C:\\Users\\asus\\Desktop\\test\\stata\\data\\ICD-result.dta\", replace\n\n\n\n// 数据处理\nclear all\nuse \"C:\\Users\\asus\\Desktop\\test\\stata\\data\\ICD-result.dta\",clear\n\ncapture drop Cost  // 捕获可能发生的错误，如果变量不存在则继续执行\n\n* 创建 id 变量并赋值\ngen id = _n\n\nsort id year\nxtset id year\n\n*- 次均费用，需要查看总费用是否和各项目费用加总一致，此处不一致\n* gen Cost = 总费用 / 次数 \n\n*- 住院天数\ngen Day = 住院天数\n\n*- DIP政策\ngen DIP = .\nreplace DIP = 0 if year == 2018\nreplace DIP = 0 if year == 2019\nreplace DIP = 0 if year == 2020\nreplace DIP = 0 if year == 2021\nreplace DIP = 1 if year == 2022\nreplace DIP = 1 if year == 2023\n\n*- 控制变量序列\n*- 年龄\ngen Age = 年龄\n\n*- 性别（虚拟变量；当受访者性别为女性时，赋值为\"0\"，否则为\"1\"）\ngen Gender = 0 if 性别 == \"女\"\nrecode Gender .= 1\n\n*- 婚姻（虚拟变量；当受访者已婚时，赋值为\"1\"，否则为\"0\"）\ngen Marriage = 1 if 婚姻 == \"已婚\"\nrecode Marriage .= 0\n\n*- 药物过敏\ngen Sensitive = 1 if 是否药物过敏 == \"有\"\nrecode Sensitive .= 0\n\n*- 是否手术\ngen Opera = 1 if 手术费 &gt; 0\nreplace Cmedicine = 0 if 手术费 == 0\n\n*- 职业\ngen Career = 1 if strmatch(职业, \"*农*\")\nreplace Career = 2 if strmatch(职业, \"*职*\")\nreplace Career = 3 if strmatch(职业, \"*无业*\")\nreplace Career = 4 if Career == .\n\n*- 是否共病\ngen Comorbidity = 1 if comorbidity == 1\nreplace Comorbidity = 0 if comorbidity == 0\n\n* 疾病类型按照 ICD-10 划分\ngen Disease = icd_chapter\n\ngen Insurance = 1 if strmatch(医疗付费方式, \"*自费*\")\nreplace Insurance = 2 if strmatch(医疗付费方式, \"*商业*\")\nreplace Insurance = 3 if strmatch(医疗付费方式, \"*城乡居民*\")\nreplace Insurance = 3 if strmatch(医疗付费方式, \"*城镇居民*\")\nreplace Insurance = 4 if strmatch(医疗付费方式, \"*城镇职工*\")\nreplace Insurance = 5 if strmatch(医疗付费方式, \"*贫困救助*\")\nreplace Insurance = 6 if strmatch(医疗付费方式, \"*新型农村合作*\")\nreplace Insurance = 7 if strmatch(医疗付费方式, \"*全公费*\")\nreplace Insurance = 2 if Insurance == .\n\n*- 是否使用中药\ngen Cmedicine = 1 if 中成药费 &gt; 0\nreplace Cmedicine = 1 if 中草药费 &gt; 0\nreplace Cmedicine = 0 if Cmedicine == .\n\n*- 入院途径\ngen category = 1 if 入院途径 == \"门诊\"\nreplace category = 0 if 入院途径 == \"急诊\"\n\n*- 自付金额\ngen SelfCost = 自付金额 / 次数\n\n*- 除去空值变量\ndrop 其他费用 病理诊断费 临床物理治疗费 手术治疗费 康复费 中医治疗费 抗菌药物费用 白蛋白类制品费 球蛋白类制品费 凝血因子类制品费 细胞因子类制品费 检查用一次性医用材料费 治疗用一次性医用材料费 手术用一次性医用材料费\n\n*- 费用变量数据\ngen GService = 一般医疗服务费 / 次数\n* gen GOperate = 一般治疗操作费 / 次数\ngen GSurgery = 手术费 / 次数\ngen GNurse = 护理费 / 次数\ngen GNonoperate = 非手术治疗项目费 / 次数\ngen GNarcosis = 麻醉费 / 次数\ngen GDrug = 西药费 / 次数\ngen GBlood = 血费 / 次数\ngen Others = 其他费 / 次数\n// 计算行总和\negen temp_total_diagnose = rowtotal(实验室诊断费 影像学诊断费 临床诊断项目费)\n\n// 进行除法运算\ngen GDiagnose = temp_total_diagnose / 次数\n\n// 删除临时变量\ndrop temp_total_diagnose\n\n// 计算行总和\negen temp_total_cdrug = rowtotal(中成药费 中草药费)\n\n// 进行除法运算\ngen GCDrug = temp_total_cdrug / 次数\n\n// 删除临时变量\ndrop temp_total_cdrug\n\n*- 次均费用\negen Cost = rowtotal(GService GSurgery GNurse GNonoperate GNarcosis GDrug GBlood GDiagnose GCDrug Others) \n\n*- 对变量进行排序\norder id year Cost SelfCost Day DIP Age Gender Marriage Sensitive Opera Career Disease Comorbidity Insurance Cmedicine category GService GSurgery GNurse GNonoperate GNarcosis GDrug GCDrug GBlood GDiagnose Others\n\n\n\n\n\n\n// 描述性统计 保留小数点后两位\nestpost summarize Cost SelfCost Day DIP Age Gender Marriage Sensitive Opera Career Disease Comorbidity Insurance Cmedicine category GService GSurgery GNurse GNonoperate GNarcosis GDrug GCDrug GBlood GDiagnose, detail\nesttab, cells(\"count mean(fmt(2)) sd(fmt(2)) min(fmt(2)) p50(fmt(2)) max(fmt(2))\") noobs compress replace title(Descriptive statistics)\nesttab using \"C:\\Users\\asus\\Desktop\\test\\stata\\ICD-10\\25.02.09\\analysis-result\\描述性统计0218.rtf\", cells(\"count mean(fmt(2)) sd(fmt(2)) min(fmt(2)) p50(fmt(2)) max(fmt(2))\") noobs compress replace title(Descriptive statistics)\n\n\n// 全样本费用指标\ntabstat Cost SelfCost Day GService GSurgery GNurse GNonoperate GNarcosis GDrug GCDrug GBlood GDiagnose Others, s(mean) by(year)\n\n// 变量指标\ntabstat Cost SelfCost Day DIP Age Gender Marriage Sensitive Opera Career Disease Comorbidity Insurance Cmedicine category, s(mean) by(year)\n\n* 计算所有年份的均值\nsummarize Cost SelfCost Day GService GSurgery GNurse GNonoperate GNarcosis GDrug GCDrug GBlood GDiagnose Others\n\n\n\n为了稳健性，对因变量进行缩尾处理。\n*- 缩尾处理（目的：剔除异常值；剔除的比例根据研究而定）\nwinsor2 Cost Day Age, replace cuts(1, 99)\n\n// 全局暂元\nglobal Control Age Gender Career Marriage category Disease Opera Comorbidity Cmedicine Insurance \n\n// 基准模型\nreg Cost DIP $Control, r\nest store m1\nreg SelfCost DIP $Control, r\nest store m2\nreg Day DIP $Control Sensitive, r // Sensitive 只在Day的模型中出现\nest store m3\nreg Cost DIP $Control Day, r\nest store m4\nreg SelfCost DIP $Control Day, r\nest store m5\n\n* 输出基准模型结果\nesttab m1 m2 m3 m4 m5 using \"C:\\Users\\asus\\Desktop\\test\\stata\\ICD-10\\25.02.09\\analysis-result0218\\基准模型结果.rtf\", replace b(2) t(2) ar2 star(* 0.1 ** 0.05 *** 0.01) nogap\n\n// 调节效应分析\nglobal Control Age Gender Career Marriage Disease Opera Comorbidity Cmedicine Insurance\n\nreg Cost DIP $Control Day if category == 1, r\nest store m1\nreg Cost DIP $Control Day if category == 0, r\nest store m2\n\n\n*- esttab m1 m2 m3 using \nesttab m1 m2 using \"C:\\Users\\asus\\Desktop\\test\\stata\\ICD-10\\25.02.09\\analysis-result0218\\调节效应结果-cost&dip.rtf\", replace b(2) t(2) ar2 star(* 0.1 ** 0.05 *** 0.01) nogap\n\nreg SelfCost DIP $Control Day if category==1, r\nest store m1\nreg SelfCost DIP $Control Day if category==0, r\nest store m2\n\n\nesttab m1 m2 using \"C:\\Users\\asus\\Desktop\\test\\stata\\ICD-10\\25.02.09\\analysis-result0218\\调节效应结果-self&dip.rtf\", replace b(2) t(2) ar2 star(* 0.1 ** 0.05 *** 0.01) nogap\n\nreg Day DIP $Control Sensitive if category==1, r\nest store m1\nreg Day DIP $Control Sensitive if category==0, r\nest store m2\n\n\nesttab m1 m2 using \"C:\\Users\\asus\\Desktop\\test\\stata\\ICD-10\\25.02.09\\analysis-result0218\\调节效应结果-day&dip.rtf\", replace b(2) t(2) ar2 star(* 0.1 ** 0.05 *** 0.01) nogap",
    "crumbs": [
      "Home",
      "统计软件使用历程",
      "Python",
      "用Python和Stata处理一份卫生费用数据"
    ]
  },
  {
    "objectID": "Guide/Python/2025-02-20-Medical-expenses.html#必须配置",
    "href": "Guide/Python/2025-02-20-Medical-expenses.html#必须配置",
    "title": "用Python和Stata处理一份卫生费用数据",
    "section": "",
    "text": "运行此文档需要电脑上以安装Python，并且下列包已被安装并且能被调用：\nnumpy jupyter-cache pandas openpyxl\n你可以使用 pip 或 conda 进行安装： pip install jupyter-cache",
    "crumbs": [
      "Home",
      "统计软件使用历程",
      "Python",
      "用Python和Stata处理一份卫生费用数据"
    ]
  },
  {
    "objectID": "Guide/Python/2025-02-20-Medical-expenses.html#初步认识数据",
    "href": "Guide/Python/2025-02-20-Medical-expenses.html#初步认识数据",
    "title": "用Python和Stata处理一份卫生费用数据",
    "section": "",
    "text": "我们可以使用pandas包来查看部分原始数据，数据的基本样式如下：\n\n# 安装并加载必要的包\nimport pandas as pd\nimport numpy as np\n\n# 导入 Excel 文件\nfile_path = \"C:/Users/asus/Desktop/test/stata/prepare.xlsx\"\ndata = pd.read_excel(file_path, sheet_name=0, engine='openpyxl')     \n\n# 数据脱敏，删除地方\ncolumns_to_drop = [\"籍贯\", \"出生地\"]\ndata = data.drop(columns=columns_to_drop, errors='ignore')  # errors='ignore' 防止列不存在时报错\n\n# 随机抽取10个样本数据\nsample_data = data.sample(n=10, random_state=42)\n\n# 打印样本数据\nprint(sample_data)\n\n      次数        出生日期 性别   年龄      医疗付费方式  国籍 新生儿出生体重 新生儿入院体重  民族     职业  ...  \\\n1138   1  1956-09-06  男  61岁    新型农村合作医疗  中国       －       －  汉族     农民  ...   \n2024   1  1959-08-15  女  59岁  城镇居民基本医疗保险  中国       －       －  汉族     居民  ...   \n1605   1  1973-02-05  女  45岁    新型农村合作医疗  中国       －       －  汉族     农民  ...   \n1975  11  2012-09-20  男   6岁    新型农村合作医疗  中国       －       －  汉族  学龄前儿童  ...   \n1701   1  1963-01-23  男  55岁         全自费  中国       －       －  汉族      无  ...   \n218    1  1969-06-08  女  48岁    新型农村合作医疗  中国       －       －  汉族     农民  ...   \n1344   1  1960-09-11  女  57岁    新型农村合作医疗  中国       －       －  汉族     务农  ...   \n252    1  1944-05-01  女  73岁    新型农村合作医疗  中国       －       －  汉族     农民  ...   \n1921   5  2013-10-17  女   5岁    新型农村合作医疗  中国       －       －  汉族  学龄前儿童  ...   \n643    1  1997-09-02  男  20岁         全自费  中国       －       －  汉族     战士  ...   \n\n     麻醉开始时间3 麻醉结束时间3 麻醉方式3 麻醉分级3  切口部位3 切口等级3 NNIS分级3  手术部位感染3  术前住院天数3  \\\n1138     NaN     NaN   NaN   NaN    NaN   NaN     NaN      NaN      NaN   \n2024     NaN     NaN   NaN   NaN    NaN   NaN     NaN      NaN      NaN   \n1605     NaN     NaN   NaN   NaN    NaN   NaN     NaN      NaN      NaN   \n1975     NaN     NaN   NaN   NaN    NaN   NaN     NaN      NaN      NaN   \n1701     NaN     NaN   NaN   NaN    NaN   NaN     NaN      NaN      NaN   \n218      NaN     NaN   NaN   NaN    NaN   NaN     NaN      NaN      NaN   \n1344     NaN     NaN   NaN   NaN    NaN   NaN     NaN      NaN      NaN   \n252      NaN     NaN   NaN   NaN    NaN   NaN     NaN      NaN      NaN   \n1921     NaN     NaN   NaN   NaN    NaN   NaN     NaN      NaN      NaN   \n643      NaN     NaN   NaN   NaN    NaN   NaN     NaN      NaN      NaN   \n\n     手术持续时间3  \n1138     NaN  \n2024     NaN  \n1605     NaN  \n1975     NaN  \n1701     NaN  \n218      NaN  \n1344     NaN  \n252      NaN  \n1921     NaN  \n643      NaN  \n\n[10 rows x 200 columns]\n\n\n我们可以看到，该数据的列很多，第一张表中有200列，我们需要对其进行一些筛选。",
    "crumbs": [
      "Home",
      "统计软件使用历程",
      "Python",
      "用Python和Stata处理一份卫生费用数据"
    ]
  },
  {
    "objectID": "Guide/Python/2025-02-20-Medical-expenses.html#对数据的思考",
    "href": "Guide/Python/2025-02-20-Medical-expenses.html#对数据的思考",
    "title": "用Python和Stata处理一份卫生费用数据",
    "section": "",
    "text": "从哪里开始是一个需要思考的问题，对于数据的认识决定了你处理问题的方向和效率。首先，理解数据的来源至关重要，这包括了解数据是如何收集的、收集过程中可能出现的偏差或错误。其次，明确数据的类型与结构也是关键步骤之一，不同类型的数据（如定量数据、定性数据）需要采用不同的分析方法。再者，对数据进行初步探索，比如通过可视化手段观察数据分布特征，或是计算一些基本统计量来了解数据的基本情况，能够帮助你更好地制定数据处理策略。\n在真正开始处理数据之前，还需要考虑你的目标是什么。是为了回答一个具体的问题，还是为了探索潜在的模式？明确了目标之后，才能有针对性地选择合适的工具和技术。此外，考虑到数据质量的问题，数据清洗是不可跳过的一步，它包括去除异常值、填补缺失值等操作，这对于提高分析结果的准确性非常关键。\n最后，保持对数据伦理的关注同样重要，在整个数据分析的过程中，确保遵循相关的隐私保护法规和道德标准，这样才能确保你的工作不仅有效，而且负责任。通过对数据全面而深刻的理解，你可以更加自信地从数据中提取有价值的信息，并为决策提供有力支持。\n\n\n这份Excel文件有6张sheet，分别是2018-2023年，首先需要检查这六张sheet中的变量是否一致：\n\nimport pandas as pd\n\n# 导入 Excel 文件\nfile_path = \"C:/Users/asus/Desktop/test/stata/prepare.xlsx\"\nsheet_names = [\"2018\", \"2019\", \"2020\", \"2021\", \"2022\", \"2023\"]\n\n# 读取所有 sheet 的数据\nsheets_data = {sheet: pd.read_excel(file_path, sheet_name=sheet) for sheet in sheet_names}\n\n# 获取每个 sheet 的列名\nsheets_columns = {sheet: set(data.columns) for sheet, data in sheets_data.items()}\n\n# 找出所有 sheet 的共同变量和不一致的变量\ncommon_columns = set.intersection(*sheets_columns.values())\nall_columns = set.union(*sheets_columns.values())\ninconsistent_columns = all_columns - common_columns\n\n# 打印结果\nprint(\"一致的变量名:\")\nprint(common_columns)\n\nprint(\"\\n不一致的变量名:\")\nprint(inconsistent_columns)\n\n# 打印每个 sheet 的变量\nfor sheet, columns in sheets_columns.items():\n    print(f\"\\n{sheet} 的变量: {columns}\")\n\n一致的变量名:\n{'目的', '断脐后预防性使用抗菌药物给药时间1', '6麻醉方式', '1愈合', '死亡患者尸检', '入院途径', '2.4临床诊断项目费', '清洁手术预防使用抗菌药物总天数', '麻醉结束时间1', '麻醉结束时间2', '术前使用预防性抗菌药物1', '10.其他费', '新生儿出生体重', '6.2抗菌药物费用', '7.2中草药费', '出生地', '抗菌药物使用天数', '1级别', '新生儿入院体重', '5.中医治疗费', '手术持续时间1', '术前住院天数2', '切口部位1', '病室', '性别', '病室.1', '是否有出院31天内再住院计划', '3愈合', '总药品费', '9.3手术用一次性医用材料费', '手术开始时间2', '术前使用预防性抗菌药物2', '入院诊断', '手术次数2', '断脐后预防性使用抗菌药物给药时间2', '麻醉开始时间1', '是否有使用抗菌药物2', '麻醉分级2', '3麻醉方式', '职业', '2愈合', '手术部位感染2', '5愈合', '术前预防性抗菌药物给药时间1', '1.3护理费', '输血反应', '1.1一般医疗服务费', 'RH', '2手术编码', '8.4凝血因子类制品费', '9.1检查用一次性医用材料费', '术前预防性抗菌药物给药时间2', '1手术时间', '手术操作名称1', '是否非计划重返手术室病例2', '2切口', '3手术时间', '是否有使用抗菌药物1', '入院日期', '出院诊断', '手术次数1', '血管介入治疗', '4手术编码', '6切口', '输液反应', '3.4麻醉费', '麻醉分级1', '6愈合', '患者入住重症监护室（ICU）情况', '3手术编码', '预防性抗菌药物使用时机2', '入院科别', '是否微创手术1', '药占比%', '5切口', '腔镜手术名称2', '6.1西药费', '切口等级1', '出院科别', '4切口', '出生日期', '2手术名称', '输血反应次数', '感染情况', '3手术名称', '出院日期', '细菌名称2', '是否非计划重返手术室病例1', '血管介入治疗抗菌药物使用天数', '手术预防性使用抗菌药物天数2', '1麻醉方式', '3.1非手术治疗项目费', '4愈合', '1手术名称', '5级别', '病案质量', '1.2一般治疗操作费', '术后预防性抗菌药物结束时间2', '3级别', '4手术名称', '手术操作名称2', '国籍', '是否在术后使用预防性抗菌药物2', '7.1中成药费', '8.1血费', '医疗付费方式', '9.2治疗用一次性医用材料费', '本次住院期间有无重返手术室的计划1', '6手术时间', '5手术名称', '自付金额', '离院方式', '6手术名称', '择期手术1', '手术操作编码2', '病理诊断', '细菌名称4', '6手术编码', '输液反应次数', '3.3手术治疗费', '手术部位感染1', '次数', '2麻醉方式', '3切口', '是否临床路径', '婚姻', '2.1病理诊断费', '入院前颅脑损伤昏迷时间', '本次住院期间有无重返手术室的计划2', '手术操作编码1', '麻醉开始时间2', '3.5手术费', '预防性抗菌药物使用时机1', 'NNIS分级2', '3.2临床物理治疗费', '6级别', 'NNIS分级1', '5手术时间', '2手术时间', '术后预防性抗菌药物结束时间1', '手术持续时间2', '1.4其他费用', '是否在术后使用预防性抗菌药物1', '手术结束时间1', '择期手术2', '麻醉方式1', '手术开始时间1', '切口等级2', '切口部位2', '年龄', '4.康复费', '民族', '血型', '术前住院天数1', '5手术编码', '2.2实验室诊断费', '院内感染', '1切口', '籍贯', '愈合1', '住院天数', '4级别', '总费用', '清洁手术预防使用抗菌药物品种数', '1手术编码', '手术预防性使用抗菌药物天数1', '8.3球蛋白类制品费', '腔镜手术名称1', '手术结束时间2', '2级别', '药物过敏', '5麻醉方式', '2.3影像学诊断费', '麻醉方式2', '4手术时间', '入院后颅脑损伤昏迷时间', '级别2', '8.2白蛋白类制品费', '细菌名称1', '是否药物过敏', '细菌名称3', '8.5细胞因子类制品费', '级别1'}\n\n不一致的变量名:\n{'愈合2', '手术开始时间3', '7手术编码', '7级别', '7切口', '手术部位感染3', '手术次数3', '8麻醉方式', '7手术时间', '手术持续时间3', '是否微创手术2', '8手术时间', '8愈合', '4麻醉方式', '麻醉开始时间3', '术前住院天数3', '切口部位3', 'NNIS分级3', '8切口', '麻醉结束时间3', '麻醉分级3', '8手术编码', '切口等级3', '手术操作名称3', '麻醉方式3', '手术操作编码3', '8级别', '4麻醉医师', '8手术名称', '7愈合', '手术结束时间3', '择期手术3', '7手术名称', '7麻醉方式'}\n\n2018 的变量: {'目的', '愈合2', '断脐后预防性使用抗菌药物给药时间1', '6麻醉方式', '手术开始时间3', '死亡患者尸检', '1愈合', '入院途径', '2.4临床诊断项目费', '清洁手术预防使用抗菌药物总天数', '麻醉结束时间1', '麻醉结束时间2', '术前使用预防性抗菌药物1', '10.其他费', '新生儿出生体重', '6.2抗菌药物费用', '7.2中草药费', '出生地', '抗菌药物使用天数', '1级别', '新生儿入院体重', '5.中医治疗费', '手术持续时间1', '术前住院天数2', '切口部位1', '病室', '性别', '病室.1', '是否有出院31天内再住院计划', '3愈合', '总药品费', '9.3手术用一次性医用材料费', '手术开始时间2', '术前使用预防性抗菌药物2', '入院诊断', '手术次数2', '断脐后预防性使用抗菌药物给药时间2', '麻醉结束时间3', '麻醉开始时间1', '切口等级3', '是否有使用抗菌药物2', '麻醉分级2', '3麻醉方式', '职业', '2愈合', '手术部位感染2', '麻醉方式3', '5愈合', '术前预防性抗菌药物给药时间1', '1.3护理费', '输血反应', '1.1一般医疗服务费', 'RH', '2手术编码', '8.4凝血因子类制品费', '9.1检查用一次性医用材料费', '术前预防性抗菌药物给药时间2', '1手术时间', '手术操作名称1', '是否非计划重返手术室病例2', '2切口', '手术部位感染3', '3手术时间', '是否有使用抗菌药物1', '入院日期', '出院诊断', '手术次数1', '血管介入治疗', '4手术编码', '6切口', '输液反应', '3.4麻醉费', '麻醉分级1', '麻醉开始时间3', '6愈合', '切口部位3', '患者入住重症监护室（ICU）情况', '3手术编码', '预防性抗菌药物使用时机2', '入院科别', '是否微创手术1', '药占比%', '5切口', '腔镜手术名称2', '6.1西药费', '切口等级1', '出院科别', '手术操作名称3', '4切口', '出生日期', '2手术名称', '输血反应次数', '感染情况', '3手术名称', '手术操作编码3', '出院日期', '细菌名称2', '是否非计划重返手术室病例1', '血管介入治疗抗菌药物使用天数', '手术预防性使用抗菌药物天数2', '手术结束时间3', '1麻醉方式', '3.1非手术治疗项目费', '择期手术3', '4愈合', '1手术名称', '病案质量', '5级别', '1.2一般治疗操作费', '术后预防性抗菌药物结束时间2', '3级别', '手术次数3', '4手术名称', '手术操作名称2', '国籍', '是否在术后使用预防性抗菌药物2', '7.1中成药费', '8.1血费', '医疗付费方式', '手术持续时间3', '9.2治疗用一次性医用材料费', '本次住院期间有无重返手术室的计划1', '6手术时间', '是否微创手术2', '5手术名称', '自付金额', '离院方式', '6手术名称', '择期手术1', '手术操作编码2', '病理诊断', '细菌名称4', '6手术编码', '输液反应次数', '4麻醉方式', '3.3手术治疗费', '术前住院天数3', '手术部位感染1', '次数', '2麻醉方式', '3切口', '是否临床路径', '婚姻', '2.1病理诊断费', '入院前颅脑损伤昏迷时间', '本次住院期间有无重返手术室的计划2', '麻醉分级3', '手术操作编码1', '麻醉开始时间2', '3.5手术费', '预防性抗菌药物使用时机1', 'NNIS分级2', '3.2临床物理治疗费', '6级别', 'NNIS分级1', '5手术时间', '2手术时间', '术后预防性抗菌药物结束时间1', '手术持续时间2', '1.4其他费用', '是否在术后使用预防性抗菌药物1', '手术结束时间1', '择期手术2', '麻醉方式1', '手术开始时间1', '切口等级2', '切口部位2', '年龄', '4.康复费', '民族', '血型', '术前住院天数1', '5手术编码', '2.2实验室诊断费', '院内感染', '1切口', '籍贯', '愈合1', '住院天数', '4级别', '总费用', '清洁手术预防使用抗菌药物品种数', '1手术编码', '手术预防性使用抗菌药物天数1', '8.3球蛋白类制品费', '腔镜手术名称1', '手术结束时间2', 'NNIS分级3', '2级别', '药物过敏', '5麻醉方式', '2.3影像学诊断费', '麻醉方式2', '4手术时间', '入院后颅脑损伤昏迷时间', '级别2', '8.2白蛋白类制品费', '细菌名称1', '是否药物过敏', '细菌名称3', '8.5细胞因子类制品费', '级别1'}\n\n2019 的变量: {'目的', '愈合2', '断脐后预防性使用抗菌药物给药时间1', '6麻醉方式', '手术开始时间3', '死亡患者尸检', '1愈合', '入院途径', '2.4临床诊断项目费', '清洁手术预防使用抗菌药物总天数', '麻醉结束时间1', '麻醉结束时间2', '术前使用预防性抗菌药物1', '10.其他费', '新生儿出生体重', '6.2抗菌药物费用', '7.2中草药费', '出生地', '抗菌药物使用天数', '1级别', '新生儿入院体重', '5.中医治疗费', '手术持续时间1', '术前住院天数2', '切口部位1', '病室', '性别', '病室.1', '是否有出院31天内再住院计划', '3愈合', '总药品费', '9.3手术用一次性医用材料费', '手术开始时间2', '术前使用预防性抗菌药物2', '入院诊断', '手术次数2', '断脐后预防性使用抗菌药物给药时间2', '麻醉开始时间1', '是否有使用抗菌药物2', '麻醉分级2', '3麻醉方式', '职业', '2愈合', '手术部位感染2', '5愈合', '术前预防性抗菌药物给药时间1', '1.3护理费', '输血反应', '1.1一般医疗服务费', 'RH', '2手术编码', '8.4凝血因子类制品费', '9.1检查用一次性医用材料费', '术前预防性抗菌药物给药时间2', '1手术时间', '手术操作名称1', '是否非计划重返手术室病例2', '7手术编码', '2切口', '3手术时间', '是否有使用抗菌药物1', '入院日期', '7手术时间', '出院诊断', '手术次数1', '血管介入治疗', '4手术编码', '6切口', '输液反应', '3.4麻醉费', '麻醉分级1', '6愈合', '患者入住重症监护室（ICU）情况', '3手术编码', '预防性抗菌药物使用时机2', '入院科别', '是否微创手术1', '药占比%', '5切口', '腔镜手术名称2', '6.1西药费', '切口等级1', '出院科别', '手术操作名称3', '4切口', '出生日期', '2手术名称', '输血反应次数', '感染情况', '3手术名称', '手术操作编码3', '出院日期', '细菌名称2', '是否非计划重返手术室病例1', '血管介入治疗抗菌药物使用天数', '手术预防性使用抗菌药物天数2', '手术结束时间3', '1麻醉方式', '3.1非手术治疗项目费', '4愈合', '1手术名称', '5级别', '病案质量', '7级别', '7切口', '3级别', '1.2一般治疗操作费', '术后预防性抗菌药物结束时间2', '手术次数3', '4手术名称', '手术操作名称2', '国籍', '是否在术后使用预防性抗菌药物2', '7.1中成药费', '8.1血费', '医疗付费方式', '9.2治疗用一次性医用材料费', '本次住院期间有无重返手术室的计划1', '6手术时间', '是否微创手术2', '5手术名称', '自付金额', '离院方式', '6手术名称', '择期手术1', '手术操作编码2', '病理诊断', '细菌名称4', '6手术编码', '输液反应次数', '4麻醉方式', '3.3手术治疗费', '手术部位感染1', '次数', '2麻醉方式', '3切口', '是否临床路径', '婚姻', '2.1病理诊断费', '入院前颅脑损伤昏迷时间', '本次住院期间有无重返手术室的计划2', '手术操作编码1', '麻醉开始时间2', '3.5手术费', '预防性抗菌药物使用时机1', 'NNIS分级2', '3.2临床物理治疗费', '6级别', 'NNIS分级1', '7愈合', '5手术时间', '2手术时间', '术后预防性抗菌药物结束时间1', '7麻醉方式', '手术持续时间2', '1.4其他费用', '是否在术后使用预防性抗菌药物1', '手术结束时间1', '择期手术2', '麻醉方式1', '手术开始时间1', '切口等级2', '切口部位2', '年龄', '4.康复费', '民族', '血型', '术前住院天数1', '5手术编码', '2.2实验室诊断费', '院内感染', '1切口', '籍贯', '愈合1', '住院天数', '4级别', '总费用', '清洁手术预防使用抗菌药物品种数', '1手术编码', '手术预防性使用抗菌药物天数1', '8.3球蛋白类制品费', '腔镜手术名称1', '手术结束时间2', '2级别', '药物过敏', '5麻醉方式', '2.3影像学诊断费', '麻醉方式2', '4手术时间', '入院后颅脑损伤昏迷时间', '级别2', '8.2白蛋白类制品费', '细菌名称1', '是否药物过敏', '细菌名称3', '8.5细胞因子类制品费', '7手术名称', '级别1'}\n\n2020 的变量: {'目的', '断脐后预防性使用抗菌药物给药时间1', '6麻醉方式', '死亡患者尸检', '1愈合', '入院途径', '2.4临床诊断项目费', '清洁手术预防使用抗菌药物总天数', '麻醉结束时间1', '麻醉结束时间2', '术前使用预防性抗菌药物1', '10.其他费', '新生儿出生体重', '6.2抗菌药物费用', '7.2中草药费', '出生地', '抗菌药物使用天数', '1级别', '新生儿入院体重', '5.中医治疗费', '手术持续时间1', '术前住院天数2', '切口部位1', '病室', '性别', '病室.1', '是否有出院31天内再住院计划', '3愈合', '总药品费', '9.3手术用一次性医用材料费', '手术开始时间2', '术前使用预防性抗菌药物2', '入院诊断', '手术次数2', '断脐后预防性使用抗菌药物给药时间2', '麻醉开始时间1', '是否有使用抗菌药物2', '麻醉分级2', '3麻醉方式', '职业', '2愈合', '手术部位感染2', '5愈合', '术前预防性抗菌药物给药时间1', '1.3护理费', '输血反应', '1.1一般医疗服务费', 'RH', '2手术编码', '8.4凝血因子类制品费', '9.1检查用一次性医用材料费', '术前预防性抗菌药物给药时间2', '1手术时间', '手术操作名称1', '是否非计划重返手术室病例2', '7手术编码', '2切口', '3手术时间', '是否有使用抗菌药物1', '入院日期', '7手术时间', '出院诊断', '手术次数1', '血管介入治疗', '4手术编码', '6切口', '输液反应', '3.4麻醉费', '麻醉分级1', '6愈合', '患者入住重症监护室（ICU）情况', '3手术编码', '预防性抗菌药物使用时机2', '入院科别', '是否微创手术1', '药占比%', '5切口', '腔镜手术名称2', '6.1西药费', '切口等级1', '出院科别', '4切口', '出生日期', '2手术名称', '输血反应次数', '感染情况', '3手术名称', '出院日期', '细菌名称2', '是否非计划重返手术室病例1', '血管介入治疗抗菌药物使用天数', '手术预防性使用抗菌药物天数2', '1麻醉方式', '3.1非手术治疗项目费', '4愈合', '1手术名称', '5级别', '病案质量', '7级别', '7切口', '3级别', '1.2一般治疗操作费', '术后预防性抗菌药物结束时间2', '4手术名称', '手术操作名称2', '国籍', '是否在术后使用预防性抗菌药物2', '7.1中成药费', '8.1血费', '医疗付费方式', '9.2治疗用一次性医用材料费', '本次住院期间有无重返手术室的计划1', '6手术时间', '5手术名称', '自付金额', '离院方式', '6手术名称', '择期手术1', '手术操作编码2', '病理诊断', '细菌名称4', '8愈合', '6手术编码', '4麻醉方式', '3.3手术治疗费', '输液反应次数', '手术部位感染1', '次数', '2麻醉方式', '3切口', '是否临床路径', '婚姻', '2.1病理诊断费', '入院前颅脑损伤昏迷时间', '本次住院期间有无重返手术室的计划2', '8手术编码', '手术操作编码1', '麻醉开始时间2', '3.5手术费', '预防性抗菌药物使用时机1', 'NNIS分级2', '3.2临床物理治疗费', '6级别', 'NNIS分级1', '8手术名称', '7愈合', '5手术时间', '2手术时间', '术后预防性抗菌药物结束时间1', '7麻醉方式', '手术持续时间2', '1.4其他费用', '是否在术后使用预防性抗菌药物1', '手术结束时间1', '择期手术2', '麻醉方式1', '手术开始时间1', '8麻醉方式', '切口等级2', '切口部位2', '年龄', '4.康复费', '民族', '血型', '术前住院天数1', '5手术编码', '2.2实验室诊断费', '院内感染', '1切口', '籍贯', '8手术时间', '愈合1', '住院天数', '4级别', '总费用', '清洁手术预防使用抗菌药物品种数', '1手术编码', '手术预防性使用抗菌药物天数1', '8.3球蛋白类制品费', '腔镜手术名称1', '手术结束时间2', '2级别', '8切口', '药物过敏', '5麻醉方式', '2.3影像学诊断费', '麻醉方式2', '4手术时间', '入院后颅脑损伤昏迷时间', '8级别', '级别2', '8.2白蛋白类制品费', '细菌名称1', '是否药物过敏', '细菌名称3', '8.5细胞因子类制品费', '7手术名称', '级别1'}\n\n2021 的变量: {'目的', '断脐后预防性使用抗菌药物给药时间1', '6麻醉方式', '死亡患者尸检', '1愈合', '入院途径', '2.4临床诊断项目费', '清洁手术预防使用抗菌药物总天数', '麻醉结束时间1', '麻醉结束时间2', '术前使用预防性抗菌药物1', '10.其他费', '新生儿出生体重', '6.2抗菌药物费用', '7.2中草药费', '出生地', '抗菌药物使用天数', '1级别', '新生儿入院体重', '5.中医治疗费', '手术持续时间1', '术前住院天数2', '切口部位1', '病室', '性别', '病室.1', '是否有出院31天内再住院计划', '3愈合', '总药品费', '9.3手术用一次性医用材料费', '手术开始时间2', '术前使用预防性抗菌药物2', '入院诊断', '手术次数2', '断脐后预防性使用抗菌药物给药时间2', '麻醉开始时间1', '是否有使用抗菌药物2', '麻醉分级2', '3麻醉方式', '职业', '2愈合', '手术部位感染2', '5愈合', '术前预防性抗菌药物给药时间1', '1.3护理费', '输血反应', '1.1一般医疗服务费', 'RH', '2手术编码', '8.4凝血因子类制品费', '9.1检查用一次性医用材料费', '术前预防性抗菌药物给药时间2', '1手术时间', '手术操作名称1', '是否非计划重返手术室病例2', '7手术编码', '2切口', '3手术时间', '是否有使用抗菌药物1', '入院日期', '7手术时间', '出院诊断', '手术次数1', '血管介入治疗', '4手术编码', '6切口', '输液反应', '3.4麻醉费', '麻醉分级1', '6愈合', '患者入住重症监护室（ICU）情况', '3手术编码', '预防性抗菌药物使用时机2', '入院科别', '是否微创手术1', '药占比%', '5切口', '腔镜手术名称2', '6.1西药费', '切口等级1', '出院科别', '4切口', '出生日期', '2手术名称', '输血反应次数', '感染情况', '3手术名称', '出院日期', '细菌名称2', '是否非计划重返手术室病例1', '血管介入治疗抗菌药物使用天数', '手术预防性使用抗菌药物天数2', '1麻醉方式', '3.1非手术治疗项目费', '4愈合', '1手术名称', '5级别', '病案质量', '7级别', '7切口', '3级别', '1.2一般治疗操作费', '术后预防性抗菌药物结束时间2', '4手术名称', '手术操作名称2', '国籍', '是否在术后使用预防性抗菌药物2', '7.1中成药费', '8.1血费', '医疗付费方式', '9.2治疗用一次性医用材料费', '本次住院期间有无重返手术室的计划1', '6手术时间', '5手术名称', '自付金额', '离院方式', '6手术名称', '择期手术1', '手术操作编码2', '病理诊断', '细菌名称4', '6手术编码', '8愈合', '4麻醉方式', '3.3手术治疗费', '输液反应次数', '手术部位感染1', '次数', '2麻醉方式', '3切口', '是否临床路径', '婚姻', '2.1病理诊断费', '入院前颅脑损伤昏迷时间', '本次住院期间有无重返手术室的计划2', '8手术编码', '手术操作编码1', '麻醉开始时间2', '3.5手术费', '预防性抗菌药物使用时机1', 'NNIS分级2', '3.2临床物理治疗费', '6级别', 'NNIS分级1', '8手术名称', '7愈合', '5手术时间', '2手术时间', '术后预防性抗菌药物结束时间1', '7麻醉方式', '手术持续时间2', '1.4其他费用', '是否在术后使用预防性抗菌药物1', '手术结束时间1', '择期手术2', '麻醉方式1', '手术开始时间1', '8麻醉方式', '切口等级2', '切口部位2', '年龄', '4.康复费', '民族', '血型', '术前住院天数1', '5手术编码', '2.2实验室诊断费', '院内感染', '1切口', '籍贯', '8手术时间', '愈合1', '住院天数', '4级别', '总费用', '清洁手术预防使用抗菌药物品种数', '1手术编码', '手术预防性使用抗菌药物天数1', '8.3球蛋白类制品费', '腔镜手术名称1', '手术结束时间2', '2级别', '8切口', '药物过敏', '5麻醉方式', '2.3影像学诊断费', '麻醉方式2', '4手术时间', '入院后颅脑损伤昏迷时间', '8级别', '级别2', '8.2白蛋白类制品费', '细菌名称1', '是否药物过敏', '细菌名称3', '8.5细胞因子类制品费', '7手术名称', '级别1'}\n\n2022 的变量: {'目的', '断脐后预防性使用抗菌药物给药时间1', '6麻醉方式', '死亡患者尸检', '1愈合', '入院途径', '2.4临床诊断项目费', '清洁手术预防使用抗菌药物总天数', '麻醉结束时间1', '麻醉结束时间2', '术前使用预防性抗菌药物1', '10.其他费', '新生儿出生体重', '6.2抗菌药物费用', '7.2中草药费', '出生地', '抗菌药物使用天数', '1级别', '新生儿入院体重', '5.中医治疗费', '手术持续时间1', '术前住院天数2', '切口部位1', '病室', '性别', '病室.1', '是否有出院31天内再住院计划', '3愈合', '总药品费', '9.3手术用一次性医用材料费', '手术开始时间2', '术前使用预防性抗菌药物2', '入院诊断', '手术次数2', '断脐后预防性使用抗菌药物给药时间2', '麻醉开始时间1', '是否有使用抗菌药物2', '麻醉分级2', '3麻醉方式', '职业', '2愈合', '手术部位感染2', '5愈合', '术前预防性抗菌药物给药时间1', '1.3护理费', '输血反应', '1.1一般医疗服务费', 'RH', '2手术编码', '8.4凝血因子类制品费', '9.1检查用一次性医用材料费', '术前预防性抗菌药物给药时间2', '1手术时间', '手术操作名称1', '是否非计划重返手术室病例2', '7手术编码', '2切口', '3手术时间', '是否有使用抗菌药物1', '入院日期', '7手术时间', '出院诊断', '手术次数1', '血管介入治疗', '4手术编码', '6切口', '输液反应', '3.4麻醉费', '麻醉分级1', '6愈合', '患者入住重症监护室（ICU）情况', '3手术编码', '预防性抗菌药物使用时机2', '入院科别', '是否微创手术1', '药占比%', '5切口', '腔镜手术名称2', '6.1西药费', '切口等级1', '出院科别', '4切口', '出生日期', '2手术名称', '输血反应次数', '感染情况', '3手术名称', '出院日期', '细菌名称2', '是否非计划重返手术室病例1', '血管介入治疗抗菌药物使用天数', '手术预防性使用抗菌药物天数2', '1麻醉方式', '3.1非手术治疗项目费', '4愈合', '1手术名称', '5级别', '病案质量', '7级别', '7切口', '3级别', '1.2一般治疗操作费', '术后预防性抗菌药物结束时间2', '4手术名称', '手术操作名称2', '国籍', '是否在术后使用预防性抗菌药物2', '7.1中成药费', '8.1血费', '医疗付费方式', '9.2治疗用一次性医用材料费', '本次住院期间有无重返手术室的计划1', '6手术时间', '5手术名称', '自付金额', '离院方式', '6手术名称', '择期手术1', '手术操作编码2', '病理诊断', '细菌名称4', '6手术编码', '8愈合', '4麻醉方式', '3.3手术治疗费', '输液反应次数', '手术部位感染1', '次数', '2麻醉方式', '3切口', '是否临床路径', '婚姻', '2.1病理诊断费', '入院前颅脑损伤昏迷时间', '本次住院期间有无重返手术室的计划2', '8手术编码', '手术操作编码1', '麻醉开始时间2', '3.5手术费', '预防性抗菌药物使用时机1', 'NNIS分级2', '3.2临床物理治疗费', '6级别', 'NNIS分级1', '8手术名称', '7愈合', '5手术时间', '2手术时间', '术后预防性抗菌药物结束时间1', '7麻醉方式', '手术持续时间2', '1.4其他费用', '是否在术后使用预防性抗菌药物1', '手术结束时间1', '择期手术2', '麻醉方式1', '手术开始时间1', '8麻醉方式', '切口等级2', '切口部位2', '年龄', '4.康复费', '民族', '血型', '术前住院天数1', '5手术编码', '2.2实验室诊断费', '院内感染', '1切口', '籍贯', '8手术时间', '愈合1', '住院天数', '4级别', '总费用', '清洁手术预防使用抗菌药物品种数', '1手术编码', '手术预防性使用抗菌药物天数1', '8.3球蛋白类制品费', '腔镜手术名称1', '手术结束时间2', '2级别', '8切口', '药物过敏', '5麻醉方式', '2.3影像学诊断费', '麻醉方式2', '4手术时间', '入院后颅脑损伤昏迷时间', '8级别', '级别2', '8.2白蛋白类制品费', '细菌名称1', '是否药物过敏', '细菌名称3', '8.5细胞因子类制品费', '7手术名称', '级别1'}\n\n2023 的变量: {'目的', '断脐后预防性使用抗菌药物给药时间1', '6麻醉方式', '死亡患者尸检', '1愈合', '入院途径', '2.4临床诊断项目费', '清洁手术预防使用抗菌药物总天数', '麻醉结束时间1', '麻醉结束时间2', '术前使用预防性抗菌药物1', '10.其他费', '新生儿出生体重', '6.2抗菌药物费用', '7.2中草药费', '出生地', '抗菌药物使用天数', '1级别', '新生儿入院体重', '5.中医治疗费', '手术持续时间1', '术前住院天数2', '切口部位1', '病室', '性别', '病室.1', '是否有出院31天内再住院计划', '3愈合', '总药品费', '9.3手术用一次性医用材料费', '手术开始时间2', '术前使用预防性抗菌药物2', '入院诊断', '手术次数2', '断脐后预防性使用抗菌药物给药时间2', '麻醉开始时间1', '是否有使用抗菌药物2', '麻醉分级2', '3麻醉方式', '职业', '2愈合', '手术部位感染2', '5愈合', '术前预防性抗菌药物给药时间1', '1.3护理费', '输血反应', '1.1一般医疗服务费', 'RH', '2手术编码', '8.4凝血因子类制品费', '9.1检查用一次性医用材料费', '术前预防性抗菌药物给药时间2', '1手术时间', '手术操作名称1', '是否非计划重返手术室病例2', '7手术编码', '2切口', '3手术时间', '是否有使用抗菌药物1', '入院日期', '7手术时间', '出院诊断', '手术次数1', '血管介入治疗', '4手术编码', '6切口', '输液反应', '3.4麻醉费', '麻醉分级1', '6愈合', '患者入住重症监护室（ICU）情况', '3手术编码', '预防性抗菌药物使用时机2', '入院科别', '是否微创手术1', '药占比%', '5切口', '腔镜手术名称2', '6.1西药费', '切口等级1', '出院科别', '4切口', '出生日期', '2手术名称', '输血反应次数', '感染情况', '3手术名称', '出院日期', '细菌名称2', '4麻醉医师', '血管介入治疗抗菌药物使用天数', '是否非计划重返手术室病例1', '手术预防性使用抗菌药物天数2', '1麻醉方式', '3.1非手术治疗项目费', '4愈合', '1手术名称', '5级别', '病案质量', '7级别', '7切口', '3级别', '1.2一般治疗操作费', '术后预防性抗菌药物结束时间2', '4手术名称', '手术操作名称2', '国籍', '是否在术后使用预防性抗菌药物2', '7.1中成药费', '8.1血费', '医疗付费方式', '9.2治疗用一次性医用材料费', '本次住院期间有无重返手术室的计划1', '6手术时间', '5手术名称', '自付金额', '离院方式', '6手术名称', '择期手术1', '手术操作编码2', '病理诊断', '细菌名称4', '6手术编码', '8愈合', '输液反应次数', '3.3手术治疗费', '手术部位感染1', '次数', '2麻醉方式', '3切口', '是否临床路径', '婚姻', '2.1病理诊断费', '入院前颅脑损伤昏迷时间', '本次住院期间有无重返手术室的计划2', '8手术编码', '手术操作编码1', '麻醉开始时间2', '3.5手术费', '预防性抗菌药物使用时机1', 'NNIS分级2', '3.2临床物理治疗费', '6级别', 'NNIS分级1', '8手术名称', '7愈合', '5手术时间', '2手术时间', '术后预防性抗菌药物结束时间1', '7麻醉方式', '手术持续时间2', '1.4其他费用', '是否在术后使用预防性抗菌药物1', '手术结束时间1', '择期手术2', '麻醉方式1', '手术开始时间1', '8麻醉方式', '切口等级2', '切口部位2', '年龄', '4.康复费', '民族', '血型', '术前住院天数1', '5手术编码', '2.2实验室诊断费', '院内感染', '1切口', '籍贯', '8手术时间', '愈合1', '住院天数', '4级别', '总费用', '清洁手术预防使用抗菌药物品种数', '1手术编码', '手术预防性使用抗菌药物天数1', '8.3球蛋白类制品费', '腔镜手术名称1', '手术结束时间2', '2级别', '8切口', '药物过敏', '5麻醉方式', '2.3影像学诊断费', '麻醉方式2', '4手术时间', '入院后颅脑损伤昏迷时间', '8级别', '级别2', '8.2白蛋白类制品费', '细菌名称1', '是否药物过敏', '细菌名称3', '8.5细胞因子类制品费', '7手术名称', '级别1'}\n\n\n然后剔除不一致的变量数据，同时创建一个新变量year，用sheet的年份对其进行填充，再按变量名对应合并6张表格的数据称为一张总表，命名为merge-sheet.xlsx输出到你需要存放数据的文件夹中。\n变量还是太多了，那接下来对变量进行筛选，首先我们可以对所有键值为空的变量进行剔除，或者根据实际的研究需要，剔除一部分键值全部为null的变量。\n这里我选择对键值全部为null或0的变量进行剔除。\n第一次尝试的时候，打开表后进行查看，发现变量顺序很乱，没有按照原始顺序进行排列，处理办法则是在前面的变量筛选部分使用DataFrame的loc方法选择列，同时保持列的顺序。\n同时为了节省时间，因为在Quarto中运行Python代码很慢，暂时还不知道原因，待以后调试一下。所以最后用一个程序解决上述这些问题，节省时间。\n\nimport pandas as pd\n\n# 导入 Excel 文件\nfile_path = \"C:/Users/asus/Desktop/test/stata/prepare.xlsx\"\noutput_path = \"C:/Users/asus/Desktop/test/stata/data/merge-data.xlsx\"\nfinal_output_path = \"C:/Users/asus/Desktop/test/stata/data/cleaned-merge-data.xlsx\"\nsheet_names = [\"2018\", \"2019\", \"2020\", \"2021\", \"2022\", \"2023\"]\n\n# 读取所有 sheet 的数据\nsheets_data = {sheet: pd.read_excel(file_path, sheet_name=sheet) for sheet in sheet_names}\n\n# 获取每个 sheet 的列名\nsheets_columns = {sheet: set(data.columns) for sheet, data in sheets_data.items()}\n\n# 找出所有 sheet 的共同变量\ncommon_columns = set.intersection(*sheets_columns.values())\n# 保持原始顺序\ncommon_columns = list(common_columns)  \n\n# 剔除不一致的变量数据，并添加 year 变量\nfor sheet, data in sheets_data.items():\n    sheets_data[sheet] = data[list(common_columns)]\n    sheets_data[sheet]['year'] = sheet\n\n# 合并所有 sheet 的数据\nmerged_data = pd.concat(sheets_data.values(), ignore_index=True)\n\n# 输出合并后的数据到指定路径\nmerged_data.to_excel(output_path, index=False)\n\n# 重新导入合并后的数据\nmerged_data = pd.read_excel(output_path)\n\n# 剔除键值全部为 null 或 0 的变量，同时保持原始变量的顺序\nnon_null_columns = merged_data.dropna(axis=1, how='all').columns\nnon_zero_columns = merged_data.loc[:, (merged_data != 0).any(axis=0)].columns\nvalid_columns = [col for col in merged_data.columns if col in non_null_columns and col in non_zero_columns]\n\ncleaned_data = merged_data.loc[:, valid_columns]\n\n# 输出清理后的数据到指定路径\ncleaned_data.to_excel(final_output_path, index=False)\n\nprint(f\"清理后的数据已输出到 {final_output_path}\")\n\n# 展示部分数据\n\n# 随机抽取10个样本数据\nsample_data = cleaned_data.sample(n=10)\n\n# 打印样本数据\nprint(sample_data)\n\n清理后的数据已输出到 C:/Users/asus/Desktop/test/stata/data/cleaned-merge-data.xlsx\n      目的 断脐后预防性使用抗菌药物给药时间1 6麻醉方式  1愈合 死亡患者尸检 入院途径  2.4临床诊断项目费  \\\n14170  -               NaN   NaN  NaN    NaN   急诊      1553.0   \n20116  -               NaN   NaN  NaN    NaN   门诊      1272.5   \n37053  -               NaN   NaN  NaN    NaN   门诊         0.0   \n43824  -               NaN   NaN    甲      否   门诊      1106.0   \n32348  -               NaN   NaN  NaN    NaN   门诊       398.5   \n37403  -               NaN   NaN  NaN    NaN   门诊        29.0   \n31026  -               NaN   NaN    甲    NaN   门诊      1814.0   \n12348  -               NaN   NaN    乙    NaN   门诊       592.0   \n28312  -               NaN   NaN   其他    NaN   门诊      2022.5   \n35851  -               NaN   NaN   其他    NaN   门诊      1417.5   \n\n       清洁手术预防使用抗菌药物总天数              麻醉结束时间1 麻醉结束时间2  ...  2.3影像学诊断费 麻醉方式2  \\\n14170              NaN                  NaN     NaN  ...          0   NaN   \n20116              NaN                  NaN     NaN  ...          0   NaN   \n37053              NaN                  NaN     NaN  ...          0   NaN   \n43824              1.0  2023-07-07 12:05:33     NaN  ...        256   NaN   \n32348              NaN                  NaN     NaN  ...          0   NaN   \n37403              NaN                  NaN     NaN  ...          0   NaN   \n31026              NaN                  NaN     NaN  ...          0   NaN   \n12348              NaN                  NaN     NaN  ...          0   NaN   \n28312              NaN                  NaN     NaN  ...        640   NaN   \n35851              NaN  2022-07-07 16:25:49     NaN  ...          0   NaN   \n\n       4手术时间 入院后颅脑损伤昏迷时间  级别2  细菌名称1 是否药物过敏 细菌名称3  级别1  year  \n14170    NaN      -天-时-分  NaN    NaN      无   NaN  NaN  2020  \n20116    NaN      -天-时-分  NaN    NaN      无   NaN  NaN  2020  \n37053    NaN      -天-时-分  NaN    NaN      无   NaN  NaN  2022  \n43824    NaN      -天-时-分  NaN      -      无     -  4.0  2023  \n32348    NaN      -天-时-分  NaN    NaN      无   NaN  NaN  2022  \n37403    NaN      -天-时-分  NaN    NaN      无   NaN  NaN  2022  \n31026    NaN      -天-时-分  NaN    NaN      无   NaN  NaN  2021  \n12348    NaN      -天-时-分  NaN    NaN      无   NaN  NaN  2020  \n28312    NaN      -天-时-分  NaN    NaN      无   NaN  NaN  2021  \n35851    NaN      -天-时-分  NaN      -      无     -  2.0  2022  \n\n[10 rows x 160 columns]",
    "crumbs": [
      "Home",
      "统计软件使用历程",
      "Python",
      "用Python和Stata处理一份卫生费用数据"
    ]
  },
  {
    "objectID": "Guide/Python/2025-02-20-Medical-expenses.html#筛选变量",
    "href": "Guide/Python/2025-02-20-Medical-expenses.html#筛选变量",
    "title": "用Python和Stata处理一份卫生费用数据",
    "section": "",
    "text": "经过上述筛选后的变量依然还有很多，其中不乏无用信息变量或无效信息变量，对变量做进一步筛选。\n对样本进行筛选，需要满足在当年收治且出院，满足常规医保使用条件，关键变量含有缺失值的样本。\n使用 pandas 进行处理（根据Excel视图挑选的缺失数据的变量或含有较多缺失值的变量）：\n\nimport pandas as pd\n\n# 文件路径\ninput_file = r\"C:\\Users\\asus\\Desktop\\test\\stata\\data\\cleaned-merge-data.xlsx\"\noutput_file = r\"C:\\Users\\asus\\Desktop\\test\\stata\\data\\allclean.xlsx\"\n\n# 读取 Excel 文件\ndf = pd.read_excel(input_file)\n\n# 要删除的列列表\ncolumns_to_drop = [\n    \"新生儿出生体重\", \"新生儿入院体重\", \"国籍\", \"籍贯\", \"病室\", \"病室.1\", \"是否有出院31天内再住院计划\",\n    \"病理诊断\", \"院内感染\", \"药物过敏\", \"死亡患者尸检\", \"血型\", \"RH\",\n    \"1手术编码\", \"1手术时间\", \"1级别\", \"1切口\", \"1愈合\", \"1麻醉方式\",\n    \"2手术名称\", \"2手术编码\", \"2手术时间\", \"2级别\", \"2切口\", \"2愈合\", \"2麻醉方式\",\n    \"3手术名称\", \"3手术编码\", \"3手术时间\", \"3级别\", \"3切口\", \"3愈合\", \"3麻醉方式\",\n    \"4手术名称\", \"4手术编码\", \"4手术时间\", \"4级别\", \"4切口\", \"4愈合\", \"4麻醉方式\",\n    \"5手术名称\", \"5手术编码\", \"5手术时间\", \"5级别\", \"5切口\", \"5愈合\", \"5麻醉方式\",\n    \"6手术名称\", \"6手术编码\", \"6手术时间\", \"6级别\", \"6切口\", \"6愈合\", \"6麻醉方式\",\n    \"7手术名称\", \"7手术编码\", \"7手术时间\", \"7级别\", \"7切口\", \"7愈合\", \"7麻醉方式\",\n    \"8手术名称\", \"8手术编码\", \"8手术时间\", \"8级别\", \"8切口\", \"8愈合\", \"8麻醉方式\",\n    \"目的\", \"入院前颅脑损伤昏迷时间\", \"入院后颅脑损伤昏迷时间\",\n    \"抗菌药物使用天数\", \"清洁手术预防使用抗菌药物品种数\", \"是否临床路径\", \"清洁手术预防使用抗菌药物总天数\",\n    \"患者入住重症监护室（ICU）情况\", \"感染情况\", \"输血反应\", \"输血反应次数\", \"输液反应\", \"输液反应次数\",\n    \"细菌名称1\", \"细菌名称2\", \"细菌名称3\", \"细菌名称4\", \"血管介入治疗\", \"血管介入治疗抗菌药物使用天数\",\n    \"手术次数1\", \"手术操作名称1\", \"手术操作编码1\", \"手术开始时间1\", \"手术结束时间1\", \"择期手术1\",\n    \"麻醉开始时间1\", \"麻醉结束时间1\", \"麻醉方式1\", \"麻醉分级1\", \"切口部位1\", \"切口等级1\", \"NNIS分级1\",\n    \"手术部位感染1\", \"术前住院天数1\", \"手术持续时间1\", \"是否非计划重返手术室病例1\", \"术前使用预防性抗菌药物1\",\n    \"术前预防性抗菌药物给药时间1\", \"是否在术后使用预防性抗菌药物1\", \"术后预防性抗菌药物结束时间1\",\n    \"手术预防性使用抗菌药物天数1\", \"是否有使用抗菌药物1\", \"预防性抗菌药物使用时机1\",\n    \"断脐后预防性使用抗菌药物给药时间1\", \"本次住院期间有无重返手术室的计划1\", \"腔镜手术名称1\", \"级别1\", \"愈合1\",\n    \"是否微创手术1\", \"手术次数2\", \"手术操作名称2\", \"手术操作编码2\", \"手术开始时间2\", \"手术结束时间2\",\n    \"择期手术2\", \"麻醉开始时间2\", \"麻醉结束时间2\", \"麻醉方式2\", \"麻醉分级2\", \"切口部位2\", \"切口等级2\",\n    \"NNIS分级2\", \"手术部位感染2\", \"术前住院天数2\", \"手术持续时间2\", \"是否非计划重返手术室病例2\",\n    \"术前使用预防性抗菌药物2\", \"术前预防性抗菌药物给药时间2\", \"是否在术后使用预防性抗菌药物2\",\n    \"术后预防性抗菌药物结束时间2\", \"手术预防性使用抗菌药物天数2\", \"是否有使用抗菌药物2\",\n    \"预防性抗菌药物使用时机2\", \"断脐后预防性使用抗菌药物给药时间2\", \"本次住院期间有无重返手术室的计划2\",\n    \"腔镜手术名称2\", \"级别2\", \"愈合2\", \"是否微创手术2\", \"手术次数3\", \"手术操作名称3\", \"手术操作编码3\", \"手术开始时间3\",\n    \"手术结束时间3\", \"择期手术3\", \"麻醉开始时间3\", \"麻醉结束时间3\", \"麻醉方式3\", \"麻醉分级3\", \"切口部位3\", \"切口等级3\",\n    \"NNIS分级3\", \"手术部位感染3\", \"术前住院天数3\", \"手术持续时间3\", \"4麻醉医师\", \"出生地\", \"籍贯\"\n]\n\n# 删除指定的列\ndf = df.drop(columns=columns_to_drop, errors='ignore')\n\n# 过滤掉 '公安病区'\nif '入院科别' in df.columns and '出院科别' in df.columns:\n    df = df[~df['入院科别'].isin(['公安病区'])]\n    df = df[~df['出院科别'].isin(['公安病区'])]\n\n# 打印随机 10 个样本\nprint(\"随机 10 个样本：\")\nprint(df.sample(10))\n\n# 将处理后的 DataFrame 写入新的 Excel 文件\n# df.to_excel(output_file, index=False)\n\n# print(f\"数据清洗完成，已保存到 {output_file}\")\n\n随机 10 个样本：\n      入院途径  2.4临床诊断项目费   10.其他费  7.2中草药费 性别    总药品费  \\\n45540   门诊       225.0    28.98      0.0  女   22.17   \n27023   门诊      1105.0  9923.46      0.0  男   77.87   \n10102   门诊       178.3  3442.00      0.0  女  168.30   \n29291   门诊       977.5   511.57      0.0  女  626.99   \n18117   门诊       624.0   139.90      0.0  女  526.41   \n48037   门诊       264.9  3286.00      0.0  男   88.97   \n35602   门诊       201.0   336.92      0.0  男  723.32   \n17413   门诊      1278.5   357.29      0.0  女  702.13   \n966     门诊         0.0    24.75      0.0  女    0.00   \n14589   门诊       147.3  4724.00      0.0  女  196.45   \n\n                                                    入院诊断     职业  1.3护理费  \\\n45540                       老年核性白内障|H25.100,翼状胬肉|H11.000     农民    25.0   \n27023              结肠恶性肿瘤个人史|Z85.006,手术后恶性肿瘤化学治疗|Z51.102     农民    75.0   \n10102                       老年性白内障|H25.900,玻璃体混浊|H43.300     农民    50.0   \n29291                           结肠息肉|K63.500,胃息肉|K31.703  自由职业者   196.0   \n18117  大疱性类天疱疮|L12.000,冠状动脉粥样硬化性心脏病|I25.103,心功能Ⅲ级|I50...     居民    85.0   \n48037                                    老年核性白内障|H25.100     农民    50.0   \n35602                       节肢动物咬伤|T63.402,过敏性皮炎|L23.901     农民   200.6   \n17413                                         腹痛|R10.400     居民   125.0   \n966                                      脑外伤后综合征|F07.201      -   156.0   \n14589  老年性白内障|H25.900,翼状胬肉|H11.000,玻璃体混浊|H43.300,特指手术...     农民    50.0   \n\n       1.1一般医疗服务费  ...  婚姻  3.5手术费   年龄  民族 2.2实验室诊断费  住院天数       总费用  \\\n45540        32.0  ...  已婚     0.0  61岁  汉族     372.0     1    716.25   \n27023       105.0  ...  已婚     0.0  29岁  汉族     499.0     3  11888.53   \n10102        52.0  ...  已婚  1976.0  76岁  汉族     387.0     2   6314.60   \n29291       245.0  ...  已婚     0.0  67岁  汉族     589.0     7  11239.16   \n18117       294.0  ...  已婚     0.0  92岁  汉族    1095.0     3   3133.31   \n48037        32.0  ...  已婚  1976.0  77岁  汉族     381.0     1   6164.87   \n35602       140.0  ...  已婚     0.0  56岁  汉族     731.0     4   2475.84   \n17413       160.0  ...  已婚     0.0  60岁  汉族     608.0     5   4195.02   \n966         414.0  ...  未婚     0.0   8岁  汉族       0.0    13   7004.75   \n14589        52.0  ...  已婚  1976.0  78岁  汉族       0.0     2   7166.75   \n\n      2.3影像学诊断费 是否药物过敏  year  \n45540         0      无  2023  \n27023         0      无  2021  \n10102        36      无  2019  \n29291         0      无  2021  \n18117         0      无  2020  \n48037        36      无  2023  \n35602         0      无  2022  \n17413         0      无  2020  \n966           0      无  2018  \n14589         0      无  2020  \n\n[10 rows x 39 columns]",
    "crumbs": [
      "Home",
      "统计软件使用历程",
      "Python",
      "用Python和Stata处理一份卫生费用数据"
    ]
  },
  {
    "objectID": "Guide/Python/2025-02-20-Medical-expenses.html#使用-stata-赋值和分析",
    "href": "Guide/Python/2025-02-20-Medical-expenses.html#使用-stata-赋值和分析",
    "title": "用Python和Stata处理一份卫生费用数据",
    "section": "",
    "text": "因为需要对疾病进行分类与根据诊断信息确定来生成共病信息，根据出院诊断来对疾病进行分类与赋值，这里使用 Stata 来完成。\n**************\n* 1. 清理环境并导入数据\n**************\nclear all\n\n* 读取 Excel 文件，假设第一行为列名\nimport excel \"C:\\Users\\asus\\Desktop\\test\\stata\\data\\allclean.xlsx\", ///\n    firstrow case(lower) clear\n\n* 注意：\n*  - firstrow 表示将第一行作为变量名\n*  - case(lower) 将变量名转换为小写，避免中文或大小写冲突\n*  - 如果您的表格存在中文列名，可能需要手动 rename\n\n************************\n* 2. 处理、提取与分类: 以“出院诊断”列为例\n************************\n\n*------------------\ngen disease = 出院诊断\n*------------------\n\n* 假设您已经将\"出院诊断\"重命名为了 \"disease\"\n* 现在要从 disease 里提取 ICD 编码到 icd10 列。\n* 如果原数据已包含 icd10 这列，可跳过此步。\n* 这里只是示例，具体提取逻辑需根据实际字符串格式做 parsing:\n* 例如： 出院诊断 字符串为 \"急性化脓性阑尾炎|K35.902|有,高血压病|I10.x00|有\"\n\n*（示例）如果 disease 形如 \"XXX|K35.902|有,YYY|I10.x00|有\"\n* 可以先把逗号换成某种分隔，然后再拆分，这里仅给示例逻辑\n* 注意：以下只是思路示例，可能需正则表达式、substr、split 等更复杂处理\n\n// 对disease进行拆分\n* 1. 按 | 分隔 disease 列，生成多个新变量\nsplit disease, parse(\"|\") generate(disease_part)\n \n// 提取第一个 ICD 编码\n* 2. 提取第二部分（part2）作为 icd10，使用正则表达式剔除多余编码\n* 保留 disease_part2 的前7个字符作为 icd10，形如 C15.900\ngen icd10 = substr(disease_part2, 1, 7)\ngen icd_com = substr(disease_part4, 1, 7)\n* 去除前后的空格\nreplace icd10 = trim(icd10)\n\n* 3. 删除所有拆分部分\ndrop disease_part1-disease_part55\n\n* 4. 检查结果\nlist disease icd10 in 1/10\n\n***************************************\n* 按 ICD 数量判断是否共病\n***************************************\ngen comorbidity = 0  // 初始值为 0\nreplace comorbidity = 1 if !missing(icd10) & !missing(icd_com) \n// 如果ICD10和ICD_com都不为空，则赋值为1\n\n// 查看前10行的数据\nlist icd10 icd_com comorbidity in 1/10\n\n***************************************\n* 筛除部分变量\n***************************************\n\ndrop 入院日期 入院科别 出院日期 出院科别 出院诊断 disease 离院方式 病案质量\n\n***************************************\n* 按 ICD 编码生成截取变量\n***************************************\n\n* 如果 icd10 是数值型，转换为字符串型\ntostring icd10, replace  \n\n* 检查并创建 icd_3c 变量\ngen icd_3c = \"\"   // 如果 icd_3c 不存在，创建一个空的字符串变量\n\n* 截取 icd10 的前三位并赋值给 icd_3c\nreplace icd_3c = substr(icd10, 1, 3)  \n\n* 如果 icd_3c 是数值型，转换为字符串型\ntostring icd_3c, replace \n\n* 创建 icd_str1 变量\ngen icd_str1 = \"\"\n\n* icd_str1: ICD 编码首位\nreplace icd_str1 = substr(icd10,1,1)\n\n* 如果 icd_str1 是数值型，转换为字符串型\ntostring icd_str1, replace \n\n* 使用 trim() 来去除空格\nreplace icd_str1 = trim(icd_str1)\n\n* 查看 icd_str1 的数据类型\ndescribe icd_str1\n\n* 查看是否有空值或特殊字符\n* list icd_str1 if missing(icd_str1)\n\n************************\n* 按照ICD编码归为22类\n************************\n\n* 创建icd分类变量：icd_chapter\ngen icd_chapter = \"\" \n\n* 字符转换为数值\ndestring icd_chapter,replace\n\n// 为icd_chapter赋值\n\nreplace icd_chapter=1 if icd_str1==\"A\"|icd_str1==\"B\"\nreplace icd_chapter=2 if icd_str1==\"C\"|(icd_3c&gt;=\"D00\"&icd_3c&lt;=\"D48\")\nreplace icd_chapter=3 if icd_3c&gt;=\"D50\"&icd_3c&lt;=\"D89\"\nreplace icd_chapter=4 if icd_3c&gt;=\"E00\"&icd_3c&lt;=\"E90\"\nreplace icd_chapter=5 if icd_3c&gt;=\"F00\"&icd_3c&lt;=\"F99\"\nreplace icd_chapter=6 if icd_3c&gt;=\"G00\"&icd_3c&lt;=\"G99\"\nreplace icd_chapter=7 if icd_3c&gt;=\"H00\"&icd_3c&lt;=\"H59\"\nreplace icd_chapter=8 if icd_3c&gt;=\"H60\"&icd_3c&lt;=\"H99\"\nreplace icd_chapter=9 if icd_str1==\"I\"\nreplace icd_chapter=10 if icd_str1==\"J\"\nreplace icd_chapter=11 if icd_str1==\"K\"\nreplace icd_chapter=12 if icd_str1==\"L\"\nreplace icd_chapter=13 if icd_str1==\"M\"\nreplace icd_chapter=14 if icd_str1==\"N\"\nreplace icd_chapter=15 if icd_str1==\"O\"\nreplace icd_chapter=16 if icd_str1==\"P\"\nreplace icd_chapter=17 if icd_str1==\"Q\"\nreplace icd_chapter=18 if icd_str1==\"R\"\nreplace icd_chapter=19 if icd_str1==\"S\"| icd_str1==\"T\"\nreplace icd_chapter=20 if icd_str1==\"V\"| icd_str1==\"Y\"\nreplace icd_chapter=21 if icd_str1==\"Z\"\nreplace icd_chapter=22 if icd_str1==\"U\"\nreplace icd_chapter=20 if icd_str1==\"V\"| icd_str1==\"Y\"|icd_str1==\"X\"|icd_str1==\"W\"\nreplace icd_chapter=21 if icd_str1==\"Z\"| substr(trim(icd10),1,2)==\"WW\"\nreplace icd_chapter=22 if icd_str1==\"U\"\n\n***************************************\n* 检查分类缺失\n***************************************\ntab icd_3c if icd_chapter==.\n\n****************************\n* 3. 导出处理后的数据\n****************************\n\n* 导出为 Stata 格式\nsave \"C:\\Users\\asus\\Desktop\\test\\stata\\data\\ICD-result.dta\", replace\n\n\n\n// 数据处理\nclear all\nuse \"C:\\Users\\asus\\Desktop\\test\\stata\\data\\ICD-result.dta\",clear\n\ncapture drop Cost  // 捕获可能发生的错误，如果变量不存在则继续执行\n\n* 创建 id 变量并赋值\ngen id = _n\n\nsort id year\nxtset id year\n\n*- 次均费用，需要查看总费用是否和各项目费用加总一致，此处不一致\n* gen Cost = 总费用 / 次数 \n\n*- 住院天数\ngen Day = 住院天数\n\n*- DIP政策\ngen DIP = .\nreplace DIP = 0 if year == 2018\nreplace DIP = 0 if year == 2019\nreplace DIP = 0 if year == 2020\nreplace DIP = 0 if year == 2021\nreplace DIP = 1 if year == 2022\nreplace DIP = 1 if year == 2023\n\n*- 控制变量序列\n*- 年龄\ngen Age = 年龄\n\n*- 性别（虚拟变量；当受访者性别为女性时，赋值为\"0\"，否则为\"1\"）\ngen Gender = 0 if 性别 == \"女\"\nrecode Gender .= 1\n\n*- 婚姻（虚拟变量；当受访者已婚时，赋值为\"1\"，否则为\"0\"）\ngen Marriage = 1 if 婚姻 == \"已婚\"\nrecode Marriage .= 0\n\n*- 药物过敏\ngen Sensitive = 1 if 是否药物过敏 == \"有\"\nrecode Sensitive .= 0\n\n*- 是否手术\ngen Opera = 1 if 手术费 &gt; 0\nreplace Cmedicine = 0 if 手术费 == 0\n\n*- 职业\ngen Career = 1 if strmatch(职业, \"*农*\")\nreplace Career = 2 if strmatch(职业, \"*职*\")\nreplace Career = 3 if strmatch(职业, \"*无业*\")\nreplace Career = 4 if Career == .\n\n*- 是否共病\ngen Comorbidity = 1 if comorbidity == 1\nreplace Comorbidity = 0 if comorbidity == 0\n\n* 疾病类型按照 ICD-10 划分\ngen Disease = icd_chapter\n\ngen Insurance = 1 if strmatch(医疗付费方式, \"*自费*\")\nreplace Insurance = 2 if strmatch(医疗付费方式, \"*商业*\")\nreplace Insurance = 3 if strmatch(医疗付费方式, \"*城乡居民*\")\nreplace Insurance = 3 if strmatch(医疗付费方式, \"*城镇居民*\")\nreplace Insurance = 4 if strmatch(医疗付费方式, \"*城镇职工*\")\nreplace Insurance = 5 if strmatch(医疗付费方式, \"*贫困救助*\")\nreplace Insurance = 6 if strmatch(医疗付费方式, \"*新型农村合作*\")\nreplace Insurance = 7 if strmatch(医疗付费方式, \"*全公费*\")\nreplace Insurance = 2 if Insurance == .\n\n*- 是否使用中药\ngen Cmedicine = 1 if 中成药费 &gt; 0\nreplace Cmedicine = 1 if 中草药费 &gt; 0\nreplace Cmedicine = 0 if Cmedicine == .\n\n*- 入院途径\ngen category = 1 if 入院途径 == \"门诊\"\nreplace category = 0 if 入院途径 == \"急诊\"\n\n*- 自付金额\ngen SelfCost = 自付金额 / 次数\n\n*- 除去空值变量\ndrop 其他费用 病理诊断费 临床物理治疗费 手术治疗费 康复费 中医治疗费 抗菌药物费用 白蛋白类制品费 球蛋白类制品费 凝血因子类制品费 细胞因子类制品费 检查用一次性医用材料费 治疗用一次性医用材料费 手术用一次性医用材料费\n\n*- 费用变量数据\ngen GService = 一般医疗服务费 / 次数\n* gen GOperate = 一般治疗操作费 / 次数\ngen GSurgery = 手术费 / 次数\ngen GNurse = 护理费 / 次数\ngen GNonoperate = 非手术治疗项目费 / 次数\ngen GNarcosis = 麻醉费 / 次数\ngen GDrug = 西药费 / 次数\ngen GBlood = 血费 / 次数\ngen Others = 其他费 / 次数\n// 计算行总和\negen temp_total_diagnose = rowtotal(实验室诊断费 影像学诊断费 临床诊断项目费)\n\n// 进行除法运算\ngen GDiagnose = temp_total_diagnose / 次数\n\n// 删除临时变量\ndrop temp_total_diagnose\n\n// 计算行总和\negen temp_total_cdrug = rowtotal(中成药费 中草药费)\n\n// 进行除法运算\ngen GCDrug = temp_total_cdrug / 次数\n\n// 删除临时变量\ndrop temp_total_cdrug\n\n*- 次均费用\negen Cost = rowtotal(GService GSurgery GNurse GNonoperate GNarcosis GDrug GBlood GDiagnose GCDrug Others) \n\n*- 对变量进行排序\norder id year Cost SelfCost Day DIP Age Gender Marriage Sensitive Opera Career Disease Comorbidity Insurance Cmedicine category GService GSurgery GNurse GNonoperate GNarcosis GDrug GCDrug GBlood GDiagnose Others",
    "crumbs": [
      "Home",
      "统计软件使用历程",
      "Python",
      "用Python和Stata处理一份卫生费用数据"
    ]
  },
  {
    "objectID": "Guide/Python/2025-02-20-Medical-expenses.html#数据分析",
    "href": "Guide/Python/2025-02-20-Medical-expenses.html#数据分析",
    "title": "用Python和Stata处理一份卫生费用数据",
    "section": "",
    "text": "// 描述性统计 保留小数点后两位\nestpost summarize Cost SelfCost Day DIP Age Gender Marriage Sensitive Opera Career Disease Comorbidity Insurance Cmedicine category GService GSurgery GNurse GNonoperate GNarcosis GDrug GCDrug GBlood GDiagnose, detail\nesttab, cells(\"count mean(fmt(2)) sd(fmt(2)) min(fmt(2)) p50(fmt(2)) max(fmt(2))\") noobs compress replace title(Descriptive statistics)\nesttab using \"C:\\Users\\asus\\Desktop\\test\\stata\\ICD-10\\25.02.09\\analysis-result\\描述性统计0218.rtf\", cells(\"count mean(fmt(2)) sd(fmt(2)) min(fmt(2)) p50(fmt(2)) max(fmt(2))\") noobs compress replace title(Descriptive statistics)\n\n\n// 全样本费用指标\ntabstat Cost SelfCost Day GService GSurgery GNurse GNonoperate GNarcosis GDrug GCDrug GBlood GDiagnose Others, s(mean) by(year)\n\n// 变量指标\ntabstat Cost SelfCost Day DIP Age Gender Marriage Sensitive Opera Career Disease Comorbidity Insurance Cmedicine category, s(mean) by(year)\n\n* 计算所有年份的均值\nsummarize Cost SelfCost Day GService GSurgery GNurse GNonoperate GNarcosis GDrug GCDrug GBlood GDiagnose Others\n\n\n\n为了稳健性，对因变量进行缩尾处理。\n*- 缩尾处理（目的：剔除异常值；剔除的比例根据研究而定）\nwinsor2 Cost Day Age, replace cuts(1, 99)\n\n// 全局暂元\nglobal Control Age Gender Career Marriage category Disease Opera Comorbidity Cmedicine Insurance \n\n// 基准模型\nreg Cost DIP $Control, r\nest store m1\nreg SelfCost DIP $Control, r\nest store m2\nreg Day DIP $Control Sensitive, r // Sensitive 只在Day的模型中出现\nest store m3\nreg Cost DIP $Control Day, r\nest store m4\nreg SelfCost DIP $Control Day, r\nest store m5\n\n* 输出基准模型结果\nesttab m1 m2 m3 m4 m5 using \"C:\\Users\\asus\\Desktop\\test\\stata\\ICD-10\\25.02.09\\analysis-result0218\\基准模型结果.rtf\", replace b(2) t(2) ar2 star(* 0.1 ** 0.05 *** 0.01) nogap\n\n// 调节效应分析\nglobal Control Age Gender Career Marriage Disease Opera Comorbidity Cmedicine Insurance\n\nreg Cost DIP $Control Day if category == 1, r\nest store m1\nreg Cost DIP $Control Day if category == 0, r\nest store m2\n\n\n*- esttab m1 m2 m3 using \nesttab m1 m2 using \"C:\\Users\\asus\\Desktop\\test\\stata\\ICD-10\\25.02.09\\analysis-result0218\\调节效应结果-cost&dip.rtf\", replace b(2) t(2) ar2 star(* 0.1 ** 0.05 *** 0.01) nogap\n\nreg SelfCost DIP $Control Day if category==1, r\nest store m1\nreg SelfCost DIP $Control Day if category==0, r\nest store m2\n\n\nesttab m1 m2 using \"C:\\Users\\asus\\Desktop\\test\\stata\\ICD-10\\25.02.09\\analysis-result0218\\调节效应结果-self&dip.rtf\", replace b(2) t(2) ar2 star(* 0.1 ** 0.05 *** 0.01) nogap\n\nreg Day DIP $Control Sensitive if category==1, r\nest store m1\nreg Day DIP $Control Sensitive if category==0, r\nest store m2\n\n\nesttab m1 m2 using \"C:\\Users\\asus\\Desktop\\test\\stata\\ICD-10\\25.02.09\\analysis-result0218\\调节效应结果-day&dip.rtf\", replace b(2) t(2) ar2 star(* 0.1 ** 0.05 *** 0.01) nogap",
    "crumbs": [
      "Home",
      "统计软件使用历程",
      "Python",
      "用Python和Stata处理一份卫生费用数据"
    ]
  },
  {
    "objectID": "Guide/R/2025-02-22-CLHLS.html",
    "href": "Guide/R/2025-02-22-CLHLS.html",
    "title": "CLHLS Data Analysis by R",
    "section": "",
    "text": "这是一个使用 R 语言对 CLHLS 数据进行清洗和分析的工作文档。\n\n本文数据源来自北大开放研究数据平台。DVN/WBO7LK_2020\n使用 SAS 逐渐让我失去的耐心，极其臃肿和笨重，Vintage Car，交互页面也很糟糕，用起来很令人烦躁，遂改用 R 对数据进行分析。\n2025-03-06 R 也没那么好用，反而觉得 Stata 的简便也是一种优势所在。",
    "crumbs": [
      "Home",
      "统计软件使用历程",
      "R",
      "CLHLS Data Analysis by R"
    ]
  },
  {
    "objectID": "Guide/R/2025-02-22-CLHLS.html#加载必要的包",
    "href": "Guide/R/2025-02-22-CLHLS.html#加载必要的包",
    "title": "CLHLS Data Analysis by R",
    "section": "",
    "text": "本文数据源来自北大开放研究数据平台。DVN/WBO7LK_2020\n使用 SAS 逐渐让我失去的耐心，极其臃肿和笨重，Vintage Car，交互页面也很糟糕，用起来很令人烦躁，遂改用 R 对数据进行分析。\n2025-03-06 R 也没那么好用，反而觉得 Stata 的简便也是一种优势所在。",
    "crumbs": [
      "Home",
      "统计软件使用历程",
      "R",
      "CLHLS Data Analysis by R"
    ]
  },
  {
    "objectID": "Guide/R/2025-02-22-CLHLS.html#数据导出",
    "href": "Guide/R/2025-02-22-CLHLS.html#数据导出",
    "title": "CLHLS Data Analysis by R",
    "section": "\n2.1 数据导出",
    "text": "2.1 数据导出\n\nlibrary(writexl)  \n# 12. 保存描述性统计表格  \nwrite_xlsx(final_summary, \"C:/Users/asus/Desktop/test/CLHLS/Analysis-0214/Rsummary0223.xlsx\")  \n# 13. 保存结果  \nwrite_xlsx(final_data, \"C:/Users/asus/Desktop/test/CLHLS/Analysis-0214/final_data0223.xlsx\")",
    "crumbs": [
      "Home",
      "统计软件使用历程",
      "R",
      "CLHLS Data Analysis by R"
    ]
  },
  {
    "objectID": "Guide/R/2025-02-22-CLHLS.html#描述性统计",
    "href": "Guide/R/2025-02-22-CLHLS.html#描述性统计",
    "title": "CLHLS Data Analysis by R",
    "section": "\n2.2 描述性统计",
    "text": "2.2 描述性统计",
    "crumbs": [
      "Home",
      "统计软件使用历程",
      "R",
      "CLHLS Data Analysis by R"
    ]
  },
  {
    "objectID": "Guide/R/2025-02-22-CLHLS.html#构建logistic回归方程",
    "href": "Guide/R/2025-02-22-CLHLS.html#构建logistic回归方程",
    "title": "CLHLS Data Analysis by R",
    "section": "\n3.1 构建Logistic回归方程",
    "text": "3.1 构建Logistic回归方程",
    "crumbs": [
      "Home",
      "统计软件使用指南",
      "R introduction",
      "CLHLS Data Analysis by R"
    ]
  },
  {
    "objectID": "Guide/R/R-intro.html",
    "href": "Guide/R/R-intro.html",
    "title": "R introduction",
    "section": "",
    "text": "R语言是一种自由软件编程语言与操作环境，主要用于统计分析、绘图以及数据挖掘。R由新西兰奥克兰大学的统计学家罗斯·伊哈卡和罗伯特·杰特曼开发，现在由R核心小组负责开发，同时也有其他用户编写了诸多外挂的软件包。R以S语言为基础，其词法作用域语义来自Scheme。R的后台程序大多由C语言、FORTRAN语言和R自己写成。\nR 语言是为数学研究工作者设计的一种数学编程语言，主要用于统计分析、绘图、数据挖掘。\n如果你是一个计算机程序的初学者并且急切地想了解计算机的通用编程，R 语言不是一个很理想的选择，可以选择 Python、C 或 Java。\nR 语言与 C 语言都是贝尔实验室的研究成果，但两者有不同的侧重领域，R 语言是一种解释型的面向数学理论研究工作者的语言，而 C 语言是为计算机软件工程师设计的。\nR 语言是解释运行的语言（与 C 语言的编译运行不同），它的执行速度比 C 语言慢得多，不利于优化。但它在语法层面提供了更加丰富的数据结构操作并且能够十分方便地输出文字和图形信息，所以它广泛应用于数学尤其是统计学领域https://www.runoob.com/r/r-tutorial.html\n近些年 R 的发展也是极为迅速，在 Rstudio 改名为 Posit 后，R 的生态在快速发展。\n本网站就是其中一个分支的成果： Quarto\n\nAn open-source scientific and technical publishing system\n\n其他的还有诸如：\n\n0.1 Posit Workbench（数据科学家协同开发平台）\n\nJupyter, RStudio, and VS Code environments centrally maintained and ready to use\n\n\n\n0.2 MLOps（机器学习模型部署）\n\nMachine learning operations, or MLOps, is a set of practices to deploy and maintain machine learning models in production reliably and efficiently. The vetiver framework is for MLOps tasks in Python and R.\n\n\n\n0.3 Shiny for python\n\nEffortless Python web applications with the power of reactive programming.",
    "crumbs": [
      "Home",
      "统计软件使用指南",
      "R"
    ]
  },
  {
    "objectID": "Guide/SAS/SAS-install.html",
    "href": "Guide/SAS/SAS-install.html",
    "title": "SAS Install",
    "section": "",
    "text": "SAS Install",
    "crumbs": [
      "Home",
      "统计软件使用指南",
      "SAS introduction",
      "SAS Install"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "医学统计学习笔记",
    "section": "",
    "text": "本书的前身是开始于23年夏天的Rmarkdown笔记的制作，在考研的过程中，一些无聊又不想学习的时间被用来整理这些笔记和制作文档与网页，由于Quarto的出现和发展，感觉到它的强大与便利，遂用Quarto重制。\n现在重制这本学习笔记，按照初步构想，会继续完善卫生/医学统计学部分的内容，从低阶往高阶完善；再就是记录相关程序的使用技巧和学习记录（R、Python、SAS etc.）；还有有一部分的项目分享（如果顺利的话）和读书报告。\nEpidemiologists, in response to a health emergency or as a result of systematic surveillance, first obtain and analyze observed data. They use data, observations, science, and theory as they work at identifying a pathogen (when unknown) behind an observed disease outbreak or as they proceed to plan or implement policies that ameliorates its impact.\n按照大类再细分的话会有如下：\n\n统计学\n\n医学统计学（基础篇）\n贝叶斯统计\n\n统计软件的使用\n\nR\nPython\nSAS\nStata\nQuarto\n\n项目记录\n\nKaggle\n\n读书笔记\n\n\n\n引用格式BibTeX@online{2025,\n  author = {, simonzhou},\n  title = {医学统计学习笔记},\n  date = {2025-04-29},\n  url = {https://github.com/zhoulvbang/Med-Stat-Notes},\n  langid = {zh}\n}\n请按如下格式引用：\nsimonzhou. 2025. “医学统计学习笔记.” April 29, 2025. https://github.com/zhoulvbang/Med-Stat-Notes.",
    "crumbs": [
      "Home",
      "主页"
    ]
  },
  {
    "objectID": "Learn/Basic/01-preview.html",
    "href": "Learn/Basic/01-preview.html",
    "title": "关于卫生统计学",
    "section": "",
    "text": "卫生统计学是一门致力于收集、分析和解释与健康相关的数据的学科。它的目标是通过统计方法来评估和改善人群的健康状况，从而提高公共卫生水平。卫生统计学将统计学原理应用于医学和公共卫生领域，以支持健康决策的制定和实施。\n\n\n\n卫生统计学在以下几个方面发挥着重要作用：\n\n疾病监测与控制： 通过收集和分析疾病发病率、死亡率和流行病学数据，卫生统计学帮助识别疾病的流行趋势，并制定相应的预防和控制策略。\n健康政策制定： 卫生统计学提供了评估不同健康政策和干预措施效果的方法，为政策制定者提供了决策支持。\n卫生服务评估： 通过分析卫生服务的覆盖范围、质量和效率，卫生统计学评估卫生系统的运作情况，并提供改进建议。\n流行病学研究： 卫生统计学在研究人群健康与疾病之间的关系方面发挥着关键作用，帮助揭示疾病的发病机制和影响因素。\n\n\n\n\n随着数据科学和人工智能技术的发展，卫生统计学将迎来新的机遇和挑战：\n\n大数据与人工智能： 大数据技术使得收集、整合和分析海量的健康数据成为可能，而人工智能技术则提供了更高效、精确的数据处理和预测能力，为卫生统计学研究提供了新的方法和工具。\n个性化医疗： 基于个体遗传信息和生活方式数据的个性化医疗将成为未来的发展趋势，卫生统计学将在个体化医疗决策和健康管理中发挥更加重要的作用。\n跨学科合作： 卫生统计学将与流行病学、遗传学、生物信息学等学科交叉融合，形成跨学科合作的新模式，共同解决健康领域的复杂问题。\n公众参与与健康促进： 卫生统计学将更加注重公众参与和社区健康促进，通过社会行为和环境因素的分析，促进健康政策的制定和实施，推动社会健康公平。\n\n随着社会的发展和健康需求的不断变化，卫生统计学将继续发挥着重要的作用，为促进全民健康、预防疾病、改善医疗服务质量和推动卫生政策提供支持和指导。\nend.",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "关于卫生统计学"
    ]
  },
  {
    "objectID": "Learn/Basic/01-preview.html#什么是卫生统计学",
    "href": "Learn/Basic/01-preview.html#什么是卫生统计学",
    "title": "关于卫生统计学",
    "section": "",
    "text": "卫生统计学是一门致力于收集、分析和解释与健康相关的数据的学科。它的目标是通过统计方法来评估和改善人群的健康状况，从而提高公共卫生水平。卫生统计学将统计学原理应用于医学和公共卫生领域，以支持健康决策的制定和实施。",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "关于卫生统计学"
    ]
  },
  {
    "objectID": "Learn/Basic/01-preview.html#卫生统计学的重要性",
    "href": "Learn/Basic/01-preview.html#卫生统计学的重要性",
    "title": "关于卫生统计学",
    "section": "",
    "text": "卫生统计学在以下几个方面发挥着重要作用：\n\n疾病监测与控制： 通过收集和分析疾病发病率、死亡率和流行病学数据，卫生统计学帮助识别疾病的流行趋势，并制定相应的预防和控制策略。\n健康政策制定： 卫生统计学提供了评估不同健康政策和干预措施效果的方法，为政策制定者提供了决策支持。\n卫生服务评估： 通过分析卫生服务的覆盖范围、质量和效率，卫生统计学评估卫生系统的运作情况，并提供改进建议。\n流行病学研究： 卫生统计学在研究人群健康与疾病之间的关系方面发挥着关键作用，帮助揭示疾病的发病机制和影响因素。",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "关于卫生统计学"
    ]
  },
  {
    "objectID": "Learn/Basic/01-preview.html#卫生统计学的未来展望",
    "href": "Learn/Basic/01-preview.html#卫生统计学的未来展望",
    "title": "关于卫生统计学",
    "section": "",
    "text": "随着数据科学和人工智能技术的发展，卫生统计学将迎来新的机遇和挑战：\n\n大数据与人工智能： 大数据技术使得收集、整合和分析海量的健康数据成为可能，而人工智能技术则提供了更高效、精确的数据处理和预测能力，为卫生统计学研究提供了新的方法和工具。\n个性化医疗： 基于个体遗传信息和生活方式数据的个性化医疗将成为未来的发展趋势，卫生统计学将在个体化医疗决策和健康管理中发挥更加重要的作用。\n跨学科合作： 卫生统计学将与流行病学、遗传学、生物信息学等学科交叉融合，形成跨学科合作的新模式，共同解决健康领域的复杂问题。\n公众参与与健康促进： 卫生统计学将更加注重公众参与和社区健康促进，通过社会行为和环境因素的分析，促进健康政策的制定和实施，推动社会健康公平。\n\n随着社会的发展和健康需求的不断变化，卫生统计学将继续发挥着重要的作用，为促进全民健康、预防疾病、改善医疗服务质量和推动卫生政策提供支持和指导。\nend.",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "关于卫生统计学"
    ]
  },
  {
    "objectID": "Learn/Basic/03-Random-events-probabilities.html",
    "href": "Learn/Basic/03-Random-events-probabilities.html",
    "title": "随机事件的概率",
    "section": "",
    "text": "不确定的知识+所含不确定性度量的知识=可用的知识\n\n\n\n确定性现象（deterministic phenomenon）：在一定条件下必然会发生的现象；\n随机现象（random phenomenon）：在同一条件下具有不确定结果的现象。\n\n对随机现象获得一个观察或进行一次测量的过程称为随机试验，简称试验，用\\(E\\)表示。\n用\\(\\omega\\)表示试验\\(E\\)的一个可能的结果，则称\\(\\omega\\)为\\(E\\)的一个基本事件（elementary event）；基本事件是指不能在分解为更简单结果的事件。\n\n\n\n\n包含关系：对任意两事件A和B，如果事件B发生，则事件A必发生，则称事件A包含事件B，记作\\(A\\supseteq B\\)或\\(B\\subseteq A\\)，符号\\(\\supseteq\\)和 \\(\\subseteq\\)分别表示包含与被包含。\n相等关系：如果事件A和事件B满足以下关系：\\(A\\supseteq B 且B\\supseteq A\\)，则称A和B相等，记作\\(A=B\\)\n事件的和：在一次试验中，对任意两事件A和B，“A和B中至少有一个发生”也是一个事件，称此事件为A和B的“和或并”，记作\\(A\\cup B\\)，也可以表示为\\(A+B\\)。\n事件的交：在一次试验中，对任意两事件A和B，“A和B同时发生”也是一个事件，称此事件为A和B的“交”，记作\\(A\\cap B\\)，也可以表示为\\(AB\\)。\n事件的差：在一次试验中，“A发生且B不发生”也是一个事件，称此事件为A和B的“差”，记作\\(A-B\\)。\n互不相容事件：在一次试验中，“A与B不能同时发生”，即\\(A\\cup B=\\emptyset\\)，则称此事件A和事件B为互不相容事件，也称互斥事件。\n对立事件：是一种特殊的互不相容事件，若“事件A与事件B不能同时发生，且他们的和组成样本空间”，即\\(A\\cap B=\\emptyset 且A\\cup B=\\Omega\\)，则称A和B互为对立事件（complementary events）。\n\n\n\n\n\n频率（frequency）：设E为一随机试验，A是其中一事件，在同样条件下把E重复的做n次，以m表示事件A在这n次试验中发生的次数，则称比值\\(m/n\\)为事件A发生的频率，记为F(A)： \\[F(A)=\\frac{m}{n}\\]\n概率（probability）：设在同一条件下，重复进行n次试验，随机事件A发生m次，若试验次数n无限大时，频率\\(m/n\\)将在某一确定值p的附近摆动，则称p为事件A的概率，记为P(A)： \\[P(A)=p \\approx \\frac{m}{n}\\]\n概率有时也被称为相对频率方法；概率是事物固有的属性，不以人的主观意志为转移。\n概率的描述性定义\n概率的公理化定义：\n\n\n非负性:对于任意事件A，有\\(P(A)\\geq 0\\)\n规范性:\\(P(\\Omega)=1\\)\n可加可列性:\\(P(\\bigcup \\limits_{i=1}^{\\infty}A_i)=\\sum \\limits_{i=1}^{\\infty}P(A_i)\\)\n\n\n\n\n若A和B是样本空间\\(\\Omega\\)中两个互不相容的事件，则事件和的概率等于两事件概率之和，即：\n\\[P(A+B)=P(A)+P(B)\\] 这称之为概率的加法公式。此公式要求事件A和事件B互不相容。\n易知，A的对立事件\\(\\bar A\\)的概率\\(P(\\bar A)=1-P(A)\\)，加法公式可自然推广到多个事件的情形。\n对于任意事件A和B，即事件A和不是互不相容，更一般有： \\[P(A+B)=P(A)+P(B)-P(AB)\\] 因为当A和B互不相容时，有\\(P(AB)=0\\)。\n\n\n\n当存在某些可能影响结果的条件时，事件发生的概率可能会改变，我们称这种情况下的概率为条件概率。\n\n条件概率\n\n在已知事件A发生的条件下，事件B发生的概率成为条件概率（conditional probability），记为\\(P(B\\mid A)\\)，公式为： \\[P(B\\mid A)=\\frac{P(AB)}{P(A)},P(A)&gt;0\\] 即条件概率等于事件A和B同时发生的概率除以事件A发生的概率。\n\n概率乘法公式\n\n\\[P(AB)=P(A)P(B\\mid A),P(A)&gt;0\\\\\nP(AB)=P(B)P(A\\mid B),P(B)&gt;0\\]\n\n独立事件\n\n如果事件B发生的概率不受事件A发生概率的影响，即\\(P(B\\mid A)=P(B)\\)，则称事件B对事件A独立。由于两事件间的独立总是相互的，故也有\\(P(A\\mid B)=P(A)\\)。\n根据\\(P(AB)=P(B)P(A\\mid B),P(B)&gt;0\\)，若事件A、B独立，则有 \\[P(AB)=P(A)P(B)\\]\n在医学研究中，可以根据试验条件及生物学知识判断事物之间的独立性。\n\n\n\n\n全概率公式\n\n如果事件组\\(A_1,A_2,\\dots,A_n\\)满足以下两个条件：\n\n\\(A_1,A_2,\\dots,A_n\\)互不相容，且\\(P(A_i)&gt;0(i=1,2,\\dots,n)\\);\n\\(A_1+A_2+\\dots+A_n=\\Omega\\)\n\n那么对于任意事件B，都有\n\\[P(B)=\\sum_\\limits{i=1}^{n}P(A_i)P(B\\mid A_i)\\]\n此公式成为全概率公式（total probability formula），即B的概率可以表示为在给定\\(A_i\\)发生条件下B发生的条件概率的加权平均。\n\nBayes公式\n\n对于n个互不相容的事件\\(A_1,A_2,\\dots,A_n\\)，且他们的和为必然事件，则在时间B发生的前提下事件\\(A_k(k=1,2,\\dots,n)\\)发生的概率为：\n\\[P(A_k\\mid B)=\\frac{P(A_k)P(B\\mid A_k)}{\\sum_\\limits{i=1}^{n}P(A_i)P(B\\mid A_i)},(k=1,2,\\dots,n),P(B)&gt;0\\]\nBayes公式的意义在于，它可以改变条件概率结论的方向，即在知道结果的情况下来推断原因，用式子\\(P(A_k\\mid B)\\)表示，称为后验概率(posterior probability)；而\\(P(A_k)\\)表示各种原因出现可能性的大小，一般是过去经验的总结，称为先验概率(prior probability)。\n\n\n在流行病学领域，研究人员一直在寻找提高分析准确性和可靠性的方法。一种越来越流行的方法是使用贝叶斯方法，该方法为处理复杂数据和整合先验知识提供了独特的视角。\n\n为什么使用贝叶斯方法？\n\n贝叶斯方法允许流行病学家纳入关于该疾病的现有知识或信念或风险因素纳入分析，从而获得更准确、更翔实的结果。\n\n处理复杂模型\n\n贝叶斯方法非常适合分析复杂的流行病学模型具有许多参数和相互作用，因为它们可以解释这些参数的不确定性。\n\n处理缺失数据\n\n贝叶斯方法可以将缺失数据视为另一个需要估计的未知参数来处理，与排除或归咎于缺失数据的传统方法相比，这可以产生更准确的结果。\n\n提供概率解释\n\n贝叶斯方法以概率分布的形式提供结果，比频率学派方法获得的点估计和置信区间更直观、更具信息量。\n\n\n\n在人卫版《流行病学》第8版中，第七章-筛检，关于预测值的计算，该指标反映了筛检试验实际应用到人群筛查后，获得的首医收益大小。\n在医院开展的基于病例-非病例设计的筛查试验研究，病例组和非病例组的构成比不能代表目标人群的现患与未患比例，因此不能直接计算预测值。此时，可以根据灵敏度、特异度、现患率与预测值的关系式（Bayes公式）来估算预测值。\n[PPV=] [NPV=]\n公式中，PPV是阳性预测值，NPV是阴性预测值；SE是灵敏度，SP是特异度，P是患病率。\n流行病学中的贝叶斯方法:简介\nend.",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "随机事件的概率"
    ]
  },
  {
    "objectID": "Learn/Basic/03-Random-events-probabilities.html#随机事件与样本空间",
    "href": "Learn/Basic/03-Random-events-probabilities.html#随机事件与样本空间",
    "title": "随机事件的概率",
    "section": "",
    "text": "确定性现象（deterministic phenomenon）：在一定条件下必然会发生的现象；\n随机现象（random phenomenon）：在同一条件下具有不确定结果的现象。\n\n对随机现象获得一个观察或进行一次测量的过程称为随机试验，简称试验，用\\(E\\)表示。\n用\\(\\omega\\)表示试验\\(E\\)的一个可能的结果，则称\\(\\omega\\)为\\(E\\)的一个基本事件（elementary event）；基本事件是指不能在分解为更简单结果的事件。",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "随机事件的概率"
    ]
  },
  {
    "objectID": "Learn/Basic/03-Random-events-probabilities.html#事件的运算",
    "href": "Learn/Basic/03-Random-events-probabilities.html#事件的运算",
    "title": "随机事件的概率",
    "section": "",
    "text": "包含关系：对任意两事件A和B，如果事件B发生，则事件A必发生，则称事件A包含事件B，记作\\(A\\supseteq B\\)或\\(B\\subseteq A\\)，符号\\(\\supseteq\\)和 \\(\\subseteq\\)分别表示包含与被包含。\n相等关系：如果事件A和事件B满足以下关系：\\(A\\supseteq B 且B\\supseteq A\\)，则称A和B相等，记作\\(A=B\\)\n事件的和：在一次试验中，对任意两事件A和B，“A和B中至少有一个发生”也是一个事件，称此事件为A和B的“和或并”，记作\\(A\\cup B\\)，也可以表示为\\(A+B\\)。\n事件的交：在一次试验中，对任意两事件A和B，“A和B同时发生”也是一个事件，称此事件为A和B的“交”，记作\\(A\\cap B\\)，也可以表示为\\(AB\\)。\n事件的差：在一次试验中，“A发生且B不发生”也是一个事件，称此事件为A和B的“差”，记作\\(A-B\\)。\n互不相容事件：在一次试验中，“A与B不能同时发生”，即\\(A\\cup B=\\emptyset\\)，则称此事件A和事件B为互不相容事件，也称互斥事件。\n对立事件：是一种特殊的互不相容事件，若“事件A与事件B不能同时发生，且他们的和组成样本空间”，即\\(A\\cap B=\\emptyset 且A\\cup B=\\Omega\\)，则称A和B互为对立事件（complementary events）。",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "随机事件的概率"
    ]
  },
  {
    "objectID": "Learn/Basic/03-Random-events-probabilities.html#概率的定义",
    "href": "Learn/Basic/03-Random-events-probabilities.html#概率的定义",
    "title": "随机事件的概率",
    "section": "",
    "text": "频率（frequency）：设E为一随机试验，A是其中一事件，在同样条件下把E重复的做n次，以m表示事件A在这n次试验中发生的次数，则称比值\\(m/n\\)为事件A发生的频率，记为F(A)： \\[F(A)=\\frac{m}{n}\\]\n概率（probability）：设在同一条件下，重复进行n次试验，随机事件A发生m次，若试验次数n无限大时，频率\\(m/n\\)将在某一确定值p的附近摆动，则称p为事件A的概率，记为P(A)： \\[P(A)=p \\approx \\frac{m}{n}\\]\n概率有时也被称为相对频率方法；概率是事物固有的属性，不以人的主观意志为转移。\n概率的描述性定义\n概率的公理化定义：\n\n\n非负性:对于任意事件A，有\\(P(A)\\geq 0\\)\n规范性:\\(P(\\Omega)=1\\)\n可加可列性:\\(P(\\bigcup \\limits_{i=1}^{\\infty}A_i)=\\sum \\limits_{i=1}^{\\infty}P(A_i)\\)",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "随机事件的概率"
    ]
  },
  {
    "objectID": "Learn/Basic/03-Random-events-probabilities.html#概率的加法公式",
    "href": "Learn/Basic/03-Random-events-probabilities.html#概率的加法公式",
    "title": "随机事件的概率",
    "section": "",
    "text": "若A和B是样本空间\\(\\Omega\\)中两个互不相容的事件，则事件和的概率等于两事件概率之和，即：\n\\[P(A+B)=P(A)+P(B)\\] 这称之为概率的加法公式。此公式要求事件A和事件B互不相容。\n易知，A的对立事件\\(\\bar A\\)的概率\\(P(\\bar A)=1-P(A)\\)，加法公式可自然推广到多个事件的情形。\n对于任意事件A和B，即事件A和不是互不相容，更一般有： \\[P(A+B)=P(A)+P(B)-P(AB)\\] 因为当A和B互不相容时，有\\(P(AB)=0\\)。",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "随机事件的概率"
    ]
  },
  {
    "objectID": "Learn/Basic/03-Random-events-probabilities.html#概率的乘法公式",
    "href": "Learn/Basic/03-Random-events-probabilities.html#概率的乘法公式",
    "title": "随机事件的概率",
    "section": "",
    "text": "当存在某些可能影响结果的条件时，事件发生的概率可能会改变，我们称这种情况下的概率为条件概率。\n\n条件概率\n\n在已知事件A发生的条件下，事件B发生的概率成为条件概率（conditional probability），记为\\(P(B\\mid A)\\)，公式为： \\[P(B\\mid A)=\\frac{P(AB)}{P(A)},P(A)&gt;0\\] 即条件概率等于事件A和B同时发生的概率除以事件A发生的概率。\n\n概率乘法公式\n\n\\[P(AB)=P(A)P(B\\mid A),P(A)&gt;0\\\\\nP(AB)=P(B)P(A\\mid B),P(B)&gt;0\\]\n\n独立事件\n\n如果事件B发生的概率不受事件A发生概率的影响，即\\(P(B\\mid A)=P(B)\\)，则称事件B对事件A独立。由于两事件间的独立总是相互的，故也有\\(P(A\\mid B)=P(A)\\)。\n根据\\(P(AB)=P(B)P(A\\mid B),P(B)&gt;0\\)，若事件A、B独立，则有 \\[P(AB)=P(A)P(B)\\]\n在医学研究中，可以根据试验条件及生物学知识判断事物之间的独立性。",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "随机事件的概率"
    ]
  },
  {
    "objectID": "Learn/Basic/03-Random-events-probabilities.html#全概率公式与bayes公式",
    "href": "Learn/Basic/03-Random-events-probabilities.html#全概率公式与bayes公式",
    "title": "随机事件的概率",
    "section": "",
    "text": "全概率公式\n\n如果事件组\\(A_1,A_2,\\dots,A_n\\)满足以下两个条件：\n\n\\(A_1,A_2,\\dots,A_n\\)互不相容，且\\(P(A_i)&gt;0(i=1,2,\\dots,n)\\);\n\\(A_1+A_2+\\dots+A_n=\\Omega\\)\n\n那么对于任意事件B，都有\n\\[P(B)=\\sum_\\limits{i=1}^{n}P(A_i)P(B\\mid A_i)\\]\n此公式成为全概率公式（total probability formula），即B的概率可以表示为在给定\\(A_i\\)发生条件下B发生的条件概率的加权平均。\n\nBayes公式\n\n对于n个互不相容的事件\\(A_1,A_2,\\dots,A_n\\)，且他们的和为必然事件，则在时间B发生的前提下事件\\(A_k(k=1,2,\\dots,n)\\)发生的概率为：\n\\[P(A_k\\mid B)=\\frac{P(A_k)P(B\\mid A_k)}{\\sum_\\limits{i=1}^{n}P(A_i)P(B\\mid A_i)},(k=1,2,\\dots,n),P(B)&gt;0\\]\nBayes公式的意义在于，它可以改变条件概率结论的方向，即在知道结果的情况下来推断原因，用式子\\(P(A_k\\mid B)\\)表示，称为后验概率(posterior probability)；而\\(P(A_k)\\)表示各种原因出现可能性的大小，一般是过去经验的总结，称为先验概率(prior probability)。\n\n\n在流行病学领域，研究人员一直在寻找提高分析准确性和可靠性的方法。一种越来越流行的方法是使用贝叶斯方法，该方法为处理复杂数据和整合先验知识提供了独特的视角。\n\n为什么使用贝叶斯方法？\n\n贝叶斯方法允许流行病学家纳入关于该疾病的现有知识或信念或风险因素纳入分析，从而获得更准确、更翔实的结果。\n\n处理复杂模型\n\n贝叶斯方法非常适合分析复杂的流行病学模型具有许多参数和相互作用，因为它们可以解释这些参数的不确定性。\n\n处理缺失数据\n\n贝叶斯方法可以将缺失数据视为另一个需要估计的未知参数来处理，与排除或归咎于缺失数据的传统方法相比，这可以产生更准确的结果。\n\n提供概率解释\n\n贝叶斯方法以概率分布的形式提供结果，比频率学派方法获得的点估计和置信区间更直观、更具信息量。\n\n\n\n在人卫版《流行病学》第8版中，第七章-筛检，关于预测值的计算，该指标反映了筛检试验实际应用到人群筛查后，获得的首医收益大小。\n在医院开展的基于病例-非病例设计的筛查试验研究，病例组和非病例组的构成比不能代表目标人群的现患与未患比例，因此不能直接计算预测值。此时，可以根据灵敏度、特异度、现患率与预测值的关系式（Bayes公式）来估算预测值。\n[PPV=] [NPV=]\n公式中，PPV是阳性预测值，NPV是阴性预测值；SE是灵敏度，SP是特异度，P是患病率。\n流行病学中的贝叶斯方法:简介\nend.",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "随机事件的概率"
    ]
  },
  {
    "objectID": "Learn/Basic/05-random-variable-of-continuous-type.html",
    "href": "Learn/Basic/05-random-variable-of-continuous-type.html",
    "title": "连续型随机变量的概率分布",
    "section": "",
    "text": "若随机变量X的密度函数是\n\\[f(x)=\\frac{1}{\\sqrt{2\\pi\\sigma}}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}, (-\\infty&lt;x&lt;+\\infty)\\] 则称X服从正态分布，记为\\(X\\sim N(\\mu,\\sigma^2)\\)。\n\n\n\n\nNormal Curve comparsion\n\n\n\n\n正态分布(Normal Distribution)：正态分布是最重要的连续型分布，随机变量\\(X\\)服从均数为\\(\\mu\\)，标准差为\\(\\sigma\\)的正态分布，记为\\(X\\sim N(\\mu,\\sigma^{2})\\)。\n正态曲线（Normal curve）：即正态分布曲线，\\(\\mu\\)和\\(\\sigma\\)是正态分布的两个参数。\n\n\n\n\n\nNormal Curve\n\n\n\n\n性质\n\n\n正态曲线在横轴上方均数处最高\n\n正态分布以均数为中心，左右对称\n\n正态分布有两个参数，即位置参数\\(\\mu\\)和形态参数\\(\\sigma\\)\n\n固定\\(\\sigma\\)，改变\\(\\mu\\)值，形态不变，曲线沿着\\(X\\)轴平行移动\n固定\\(\\mu\\)，改变\\(\\sigma\\)值，中心在\\(X\\)轴的位置不变\n\n\n\\(\\sigma\\)越小，曲线越陡峭\\(\\to\\)瘦高\n\n\\(\\sigma\\)越大，曲线越低平\\(\\to\\)矮胖\n\n\n正态分布的可加性，当随机变量X服从正态分布\\(N(\\mu_1,\\sigma_1^2)\\)，Y服从正态分布\\(N(\\mu_2,\\sigma_2^2)\\)，X与Y独立，则\\(X-Y\\)服从\\(N(\\mu_1-\\mu_2,\\sigma_1^2+\\sigma_2^2)\\)的正态分布\n\n\n\n\n\n\n\nDifferent Normal Curve\n\n\n\n\n标准正态随机变量U的密度函数用\\(\\varphi(u)\\)表示，为： \\[\\varphi(u)=\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{u^2}{2}},(-\\infty&lt;x&lt;+\\infty)\\]\n\n标准正态分布（Standard normal distribution）：是一种特殊的正态分布，通常用\\(U\\)或\\(Z\\)表示服从标准正态分布的变量，此时称随机变量\\(X\\)服从均数为0，标准差为1的标准正态分布，记为\\(X \\sim N(0,1)\\)\n\n\n\n正态分布：一簇曲线\n标准正态分布：一条曲线\n\n\n标准正态变换：Z变换、U变换\n\n\n疑难1：Z值到底表达什么意思？\n\n个体值到均值的距离，有多少个标准差 \\(Z = \\frac{X-\\mu}{\\sigma}\\)\n\n只有正态分布的资料才能通过Z变换变成标准正态分布\n\n\n疑难2：标准化变换的公式如何理解？\n\n个体值减去均值，除以标准差，均数和标准差由\\(\\mu,\\sigma\\)变为\\(0,1\\)\n\n\n\n\n\n\nTableGrob (1 x 2) \"arrange\": 2 grobs\n  z     cells    name           grob\n1 1 (1-1,1-1) arrange gtable[layout]\n2 2 (1-1,2-2) arrange gtable[layout]\n\n\n\n\nNormalized Transformation\n\n\n\n\n\n正态分布的68-95-99.7法则\n\n\n\n\n\nNormal\n\n\n\n\n标准化转换，涉及到以下两个互逆计算\n\n\n估计某个随机变量在一定取值范围内的观测值个数占全部观测值数量的百分比\n通过已知的百分比，估计总体变量值的分布范围（本质同医学参考值范围的计算）\n\n\n运用正态近似法计算医学参考值范围\n\n\n\nMedical reference range\n\n\n运用正态近似法计算置信区间\n正态分布是很多统计学分析方法的理论基础\n\nnotice:\n\n正态曲线上的拐点所对应的横坐标为\\(\\mu ±\\sigma\\)。\n设随机变量\\(X\\)的概率密度曲线为\\(f(x)=\\frac{1}{2\\sqrt{p}}e^{\\frac{(x+2)^2}{4}}\\)，若要将\\(X\\)转化为服从标准正态分布的变量\\(\\mu\\)，则所采用的标准化变换为：\\(\\frac{X-2}{\\sqrt{2}}\\)（其原式为：\\(f(x)=\\frac{1}{\\sigma \\sqrt{2\\pi}}e^{\\frac{-(x-\\mu)^2}{2\\sigma^2}}\\)，题目和原式中：\\(p=\\pi\\)）\n\n\n\n\n\nSkewed Curves\n\n\n\nnotice：\n\n左偏，左边尾长，平均数靠近左侧，平均数小于中位数小于众数，负偏态；\n右偏，右边尾长，平均数靠近右侧，平均数大于中位数大于众数，正偏态。\n\n\n\nconversion relationship",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "连续型随机变量的概率分布"
    ]
  },
  {
    "objectID": "Learn/Basic/05-random-variable-of-continuous-type.html#正态分布normal-distribution",
    "href": "Learn/Basic/05-random-variable-of-continuous-type.html#正态分布normal-distribution",
    "title": "连续型随机变量的概率分布",
    "section": "",
    "text": "若随机变量X的密度函数是\n\\[f(x)=\\frac{1}{\\sqrt{2\\pi\\sigma}}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}, (-\\infty&lt;x&lt;+\\infty)\\] 则称X服从正态分布，记为\\(X\\sim N(\\mu,\\sigma^2)\\)。\n\n\n\n\nNormal Curve comparsion\n\n\n\n\n正态分布(Normal Distribution)：正态分布是最重要的连续型分布，随机变量\\(X\\)服从均数为\\(\\mu\\)，标准差为\\(\\sigma\\)的正态分布，记为\\(X\\sim N(\\mu,\\sigma^{2})\\)。\n正态曲线（Normal curve）：即正态分布曲线，\\(\\mu\\)和\\(\\sigma\\)是正态分布的两个参数。\n\n\n\n\n\nNormal Curve\n\n\n\n\n性质\n\n\n正态曲线在横轴上方均数处最高\n\n正态分布以均数为中心，左右对称\n\n正态分布有两个参数，即位置参数\\(\\mu\\)和形态参数\\(\\sigma\\)\n\n固定\\(\\sigma\\)，改变\\(\\mu\\)值，形态不变，曲线沿着\\(X\\)轴平行移动\n固定\\(\\mu\\)，改变\\(\\sigma\\)值，中心在\\(X\\)轴的位置不变\n\n\n\\(\\sigma\\)越小，曲线越陡峭\\(\\to\\)瘦高\n\n\\(\\sigma\\)越大，曲线越低平\\(\\to\\)矮胖\n\n\n正态分布的可加性，当随机变量X服从正态分布\\(N(\\mu_1,\\sigma_1^2)\\)，Y服从正态分布\\(N(\\mu_2,\\sigma_2^2)\\)，X与Y独立，则\\(X-Y\\)服从\\(N(\\mu_1-\\mu_2,\\sigma_1^2+\\sigma_2^2)\\)的正态分布\n\n\n\n\n\n\n\nDifferent Normal Curve",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "连续型随机变量的概率分布"
    ]
  },
  {
    "objectID": "Learn/Basic/05-random-variable-of-continuous-type.html#标准正态分布",
    "href": "Learn/Basic/05-random-variable-of-continuous-type.html#标准正态分布",
    "title": "连续型随机变量的概率分布",
    "section": "",
    "text": "标准正态随机变量U的密度函数用\\(\\varphi(u)\\)表示，为： \\[\\varphi(u)=\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{u^2}{2}},(-\\infty&lt;x&lt;+\\infty)\\]\n\n标准正态分布（Standard normal distribution）：是一种特殊的正态分布，通常用\\(U\\)或\\(Z\\)表示服从标准正态分布的变量，此时称随机变量\\(X\\)服从均数为0，标准差为1的标准正态分布，记为\\(X \\sim N(0,1)\\)\n\n\n\n正态分布：一簇曲线\n标准正态分布：一条曲线\n\n\n标准正态变换：Z变换、U变换\n\n\n疑难1：Z值到底表达什么意思？\n\n个体值到均值的距离，有多少个标准差 \\(Z = \\frac{X-\\mu}{\\sigma}\\)\n\n只有正态分布的资料才能通过Z变换变成标准正态分布\n\n\n疑难2：标准化变换的公式如何理解？\n\n个体值减去均值，除以标准差，均数和标准差由\\(\\mu,\\sigma\\)变为\\(0,1\\)\n\n\n\n\n\n\nTableGrob (1 x 2) \"arrange\": 2 grobs\n  z     cells    name           grob\n1 1 (1-1,1-1) arrange gtable[layout]\n2 2 (1-1,2-2) arrange gtable[layout]\n\n\n\n\nNormalized Transformation\n\n\n\n\n\n正态分布的68-95-99.7法则\n\n\n\n\n\nNormal\n\n\n\n\n标准化转换，涉及到以下两个互逆计算\n\n\n估计某个随机变量在一定取值范围内的观测值个数占全部观测值数量的百分比\n通过已知的百分比，估计总体变量值的分布范围（本质同医学参考值范围的计算）\n\n\n运用正态近似法计算医学参考值范围\n\n\n\nMedical reference range\n\n\n运用正态近似法计算置信区间\n正态分布是很多统计学分析方法的理论基础\n\nnotice:\n\n正态曲线上的拐点所对应的横坐标为\\(\\mu ±\\sigma\\)。\n设随机变量\\(X\\)的概率密度曲线为\\(f(x)=\\frac{1}{2\\sqrt{p}}e^{\\frac{(x+2)^2}{4}}\\)，若要将\\(X\\)转化为服从标准正态分布的变量\\(\\mu\\)，则所采用的标准化变换为：\\(\\frac{X-2}{\\sqrt{2}}\\)（其原式为：\\(f(x)=\\frac{1}{\\sigma \\sqrt{2\\pi}}e^{\\frac{-(x-\\mu)^2}{2\\sigma^2}}\\)，题目和原式中：\\(p=\\pi\\)）\n\n\n\n\n\nSkewed Curves\n\n\n\nnotice：\n\n左偏，左边尾长，平均数靠近左侧，平均数小于中位数小于众数，负偏态；\n右偏，右边尾长，平均数靠近右侧，平均数大于中位数大于众数，正偏态。",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "连续型随机变量的概率分布"
    ]
  },
  {
    "objectID": "Learn/Basic/05-random-variable-of-continuous-type.html#小结",
    "href": "Learn/Basic/05-random-variable-of-continuous-type.html#小结",
    "title": "连续型随机变量的概率分布",
    "section": "",
    "text": "conversion relationship",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "连续型随机变量的概率分布"
    ]
  },
  {
    "objectID": "Learn/Basic/05-random-variable-of-continuous-type.html#t分布",
    "href": "Learn/Basic/05-random-variable-of-continuous-type.html#t分布",
    "title": "连续型随机变量的概率分布",
    "section": "\n2.1 t分布",
    "text": "2.1 t分布\n说起t分布，首先要提一句u分布，正态分布（Normal Distribution）是许多统计方法的理论基础。\n正态分布的两个参数\\(\\mu\\)和\\(\\sigma\\)决定了正态分布的位置和形态。为了应用方便，常将一般的正态变量X通过u变换\\([(X-\\mu)/\\sigma]\\)转化成标准正态变量u，以使原来各种形态的正态分布都转换为\\(\\mu=0,\\sigma=1\\)的标准正态分布(Standard Normal Distribution)，亦称u分布。\n根据中心极限定理，通过抽样模拟试验表明，在正态分布总体中以固定 n 抽取若干个样本时，样本均数的分布仍服从正态分布，即\\(N(\\mu,\\sigma)\\)。所以，对样本均数的分布进行u变换，也可变换为标准正态分布\\(N(0,1)\\)。\n由于在实际工作中，往往\\(\\sigma^2\\)(总体方差)是未知的，常用\\(s^2\\)(样本方差)作为\\(\\sigma^2\\)的估计值，为了与u变换区别，称为 t 变换，统计量 t 值的分布称为 t 分布。\n\n\n\n\nt-distribution Curves\n\n\n\n\nt 分布是英国统计学家 W.S. Gosset 在 1908 年以笔名 Student发表的论文中提出的, 故后人称为 “学生氏 (Student) 分布” 或 “t 分 布”。",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "连续型随机变量的概率分布"
    ]
  },
  {
    "objectID": "Learn/Basic/05-random-variable-of-continuous-type.html#f分布",
    "href": "Learn/Basic/05-random-variable-of-continuous-type.html#f分布",
    "title": "连续型随机变量的概率分布",
    "section": "\n2.2 F分布",
    "text": "2.2 F分布\n\n\n\n\nF-distribution Curves\n\n\n\n\n2.2.1 F分布的应用\n\n方差的同质性检验 组与组之间的差异称组间变异（variation between classes），反映在各组的平均数不同。同一组内部被试（个体）之间的差异称组内变异（variation within class），反映在每一个个体之间的差异。\n总变异的分解：\n\n\n总变异 = 组间变异+组内变异\n组间变异 = 实验条件 + 随机误差\n组内变异 = 个体差异 + 实验误差 。组内误差都是随机误差。",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "连续型随机变量的概率分布"
    ]
  },
  {
    "objectID": "Learn/Basic/05-random-variable-of-continuous-type.html#chi2分布",
    "href": "Learn/Basic/05-random-variable-of-continuous-type.html#chi2分布",
    "title": "连续型随机变量的概率分布",
    "section": "\n2.3 \\(\\chi^2\\)分布",
    "text": "2.3 \\(\\chi^2\\)分布\n\n\n\n\nChi-square Distribution Curves\n\n\n\n\n2.3.1 卡方检验应用\n\n检验连续变量的分布是否与某种理论分布一致。\n检验某个分类变量各类的出现概率是否等于指定概率。\n检验某两种方法的结果是否一致。",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "连续型随机变量的概率分布"
    ]
  },
  {
    "objectID": "Learn/Basic/07-parameter-test.html",
    "href": "Learn/Basic/07-parameter-test.html",
    "title": "参数检验",
    "section": "",
    "text": "维度\n参数检验（Parameter test）\n非参数检验（Non-parameter tests）\n\n\n\n定义\n以特定的总体分布为前提\\(\\rightarrow\\)?\n不依赖于总体分布特征\\(\\rightarrow\\)?\n\n\n举例\n\n\\(Z\\)检验、\\(t\\)分布、\\(F\\)检验\n秩和检验（Rank sum test）、卡方检验\n\n\n优点\n1. 直接利用原始观测值计算统计量，检验效能高；2.可对总体参数做出估计\n1. 适用范围广、收集资料方便；2. 多数非参数检验方法比较简便、易于掌握\n\n\n缺点\n对数据分布有特定要求，适用范围窄\n1. 没有充分利用原始数据，检验效能低；2. 不能对总体参数做出推断\n\n\n适用范围\n必须符合相应的要求，如两样本t检验要求：独立、正态、方差齐\n1. 总体分布形式未知、分布类型不明确、偏态分布数据；2. 等级资料；3. 不满足参数检验条件的数据；4. 数据一段或两端为无法测量的数值等。\n\n\n选用原则\n1. 如果数据符合参数检验条件，或经过变换后符合参数检验的条件，最好用参数检验；2. 参数检验误用为非参数检验，会导致检验效能降低。\n\n\n\n\n\n\n\n\n\n\n类目\n\n\\(t\\)分布\n\n\n\n概念\n设从正态分布\\(N(\\mu,\\sigma^2)\\)随机抽取含量为n的样本，样本均数为\\(\\bar x\\)、标准差为\\(s\\)、则\\(t=\\frac{\\bar x-\\mu}{s_{\\bar x}}=\\frac{\\bar x-\\mu}{s/\\sqrt{n}}\\)，自由度为\\(n-1\\)。\n\n\n图形特点\n一簇以0为中心，左右对称的单峰曲线； 但随着自由度的增加，\\(t\\)分布曲线将越来越接近于标准正态分布曲线\n\n\n统计量值\n\n\\(t\\)的取值范围\\(-\\infty \\sim +\\infty\\)\n\n\n\n自由度\n\\(v=n-1\\)\n\n\n\n\n\n\n\nt-Distribution Curves vs. Standard Normal Curve\n\n\n\n\n\n\n\n\n正态（或正态近似法）\nt分布法\n\n\n\n\n样本均数的中心极限定理。从任意均数等于\\(\\mu\\)，方差等于\\(\\sigma^2\\)的一个总体中抽取样本量为\\(n\\)的简单随机样本，当样本量\\(n\\)很大时，无论总体分布形态如何，样本均数的抽样分布近似服从正态分布。\n样本率的中心极限定理。从“成功”率为\\(\\pi\\)的总体中随机抽取样本量为\\(n\\)的样本，其样本“成功”率用\\(p\\)表示，当\\(n\\pi&gt;5\\)且\\(n(1-\\pi)&gt;5\\)时，样本率\\(p\\)近似服从正态分布。",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "参数检验"
    ]
  },
  {
    "objectID": "Learn/Basic/07-parameter-test.html#参数检验和非参数检验的区别",
    "href": "Learn/Basic/07-parameter-test.html#参数检验和非参数检验的区别",
    "title": "参数检验",
    "section": "",
    "text": "维度\n参数检验（Parameter test）\n非参数检验（Non-parameter tests）\n\n\n\n定义\n以特定的总体分布为前提\\(\\rightarrow\\)?\n不依赖于总体分布特征\\(\\rightarrow\\)?\n\n\n举例\n\n\\(Z\\)检验、\\(t\\)分布、\\(F\\)检验\n秩和检验（Rank sum test）、卡方检验\n\n\n优点\n1. 直接利用原始观测值计算统计量，检验效能高；2.可对总体参数做出估计\n1. 适用范围广、收集资料方便；2. 多数非参数检验方法比较简便、易于掌握\n\n\n缺点\n对数据分布有特定要求，适用范围窄\n1. 没有充分利用原始数据，检验效能低；2. 不能对总体参数做出推断\n\n\n适用范围\n必须符合相应的要求，如两样本t检验要求：独立、正态、方差齐\n1. 总体分布形式未知、分布类型不明确、偏态分布数据；2. 等级资料；3. 不满足参数检验条件的数据；4. 数据一段或两端为无法测量的数值等。\n\n\n选用原则\n1. 如果数据符合参数检验条件，或经过变换后符合参数检验的条件，最好用参数检验；2. 参数检验误用为非参数检验，会导致检验效能降低。",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "参数检验"
    ]
  },
  {
    "objectID": "Learn/Basic/07-parameter-test.html#t分布",
    "href": "Learn/Basic/07-parameter-test.html#t分布",
    "title": "参数检验",
    "section": "",
    "text": "类目\n\n\\(t\\)分布\n\n\n\n概念\n设从正态分布\\(N(\\mu,\\sigma^2)\\)随机抽取含量为n的样本，样本均数为\\(\\bar x\\)、标准差为\\(s\\)、则\\(t=\\frac{\\bar x-\\mu}{s_{\\bar x}}=\\frac{\\bar x-\\mu}{s/\\sqrt{n}}\\)，自由度为\\(n-1\\)。\n\n\n图形特点\n一簇以0为中心，左右对称的单峰曲线； 但随着自由度的增加，\\(t\\)分布曲线将越来越接近于标准正态分布曲线\n\n\n统计量值\n\n\\(t\\)的取值范围\\(-\\infty \\sim +\\infty\\)\n\n\n\n自由度\n\\(v=n-1\\)\n\n\n\n\n\n\n\nt-Distribution Curves vs. Standard Normal Curve",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "参数检验"
    ]
  },
  {
    "objectID": "Learn/Basic/07-parameter-test.html#一个正态总体参数的估计",
    "href": "Learn/Basic/07-parameter-test.html#一个正态总体参数的估计",
    "title": "参数检验",
    "section": "",
    "text": "正态（或正态近似法）\nt分布法",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "参数检验"
    ]
  },
  {
    "objectID": "Learn/Basic/07-parameter-test.html#小结",
    "href": "Learn/Basic/07-parameter-test.html#小结",
    "title": "参数检验",
    "section": "",
    "text": "样本均数的中心极限定理。从任意均数等于\\(\\mu\\)，方差等于\\(\\sigma^2\\)的一个总体中抽取样本量为\\(n\\)的简单随机样本，当样本量\\(n\\)很大时，无论总体分布形态如何，样本均数的抽样分布近似服从正态分布。\n样本率的中心极限定理。从“成功”率为\\(\\pi\\)的总体中随机抽取样本量为\\(n\\)的样本，其样本“成功”率用\\(p\\)表示，当\\(n\\pi&gt;5\\)且\\(n(1-\\pi)&gt;5\\)时，样本率\\(p\\)近似服从正态分布。",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "参数检验"
    ]
  },
  {
    "objectID": "Learn/Basic/09-non-parameter-test.html",
    "href": "Learn/Basic/09-non-parameter-test.html",
    "title": "非参数检验",
    "section": "",
    "text": "资料特征\n数据特征\n\n完全随机设计\n\n配对设计\n随机区组\n\n\n\n\n\n\n单组\n两组\n多组\n\n\n\n\n分类资料\n无序分类资料\n二项分布直接计算概率法、正态近似法（Z检验）、率的正态近似\n独立四格表\\(\\chi^2\\)检验、Fisher确切概率法\nR×C交叉表\\(\\chi^2\\)检验、Fisher确切概率法\n配对四格表\\(\\chi^2\\)检验，配对R×R列联表\\(\\chi^2\\)检验\n/\n\n\n\n等级资料\nWilcoxon符合秩和检验\nwilcoxon秩和检验\nKruskal-Wallis H检验\nWilcoxon符合秩和检验\nFriedman M秩和检验\n\n\n\n\n\n\n\n\n\n\n\n\n\n方法\n内容\n\n\n\n\n确切概率法\n1. 适用情形：样本量较小或\\(\\pi_0\\)不靠近0.5时作单侧检验的情形。2. 计算公式：(1)最多有k例阳性的概率：\\(Pr(X\\le k)\\)(2)最少有k例阳性的概率：\\(Pr(X\\ge k)\\)\n\n\n正态近似法\n1. 适用情形：样本量较大时，\\(n\\pi,n(1-\\pi)\\)均大于5；2. 计算公式：分子为\\(p-\\pi_0\\)，分母为率的标准误\n\n\n\nnotice：上式中p为样本率，\\(\\pi_0\\)为给的总体率（常为理论值或标准值），n为样本含量。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n方法\n情形\n计算公式\n\n\n\n\n独立四格表卡方检验\n\\(n\\ge 40\\)且所有的\\(T\\ge 5\\)\\(n\\ge 40\\)且任一理论频数有\\(1\\le T&lt; 5\\)当\\(n&lt;40\\)，或任一一个格子理论频数\\(T&lt;1\\)时\n卡方基本公式、独立四格表专用公式同上、但是需要校正用四格表资料的Fisher确切概率法\n\n\n正态近似法\n\\(n_1p_1,n_1(1-p_1),n_2p_2,n_2(1-p_2)\\)均大于5\n分子为样本率之差，分母为样本率差的标准误\\(S_{p1-p2}\\)为两个样本率之差的标准误，\\(p_c=\\frac{x_1+x_2}{n_1+n_2}\\)为两样本的合并率\n\n\n校正样本率的正态近似法\n当\\(n_1p_1,n_1(1-p_1),n_2p_2,n_2(1-p_2)\\)不太大时\n同上，但是需要对样本率实施“分子+2、分母+4”的校正\n\n\n\nnotice：\n\n正态近似法与卡方检验结果是很接近的。在日常计算时，因为计算简便，故常用卡方检验公式。\n四格表的自由度为1。\n四格表实际频数变动时，若周边合计数保持不变，则理论频数将不会产生变化。\n用\\(n_R\\)和\\(n_C\\)和n分别表示行合计、列合计和总合计，则计算每格理论数的公式为：\\(T_{RC}=\\frac{n_R×n_C}{n}\\)。\n\\(\\chi^2\\)检验的基本公式：\\(\\chi^2=\\sum \\frac{(A-T)^2}{T}\\)。\n校正的\\(\\chi^2\\)检验的基本公式：\\(\\chi^2=\\sum \\frac{(|A-T|-0.5)^2}{T}\\)。\n\n\n\n\n\n\n\n\n\n\n\n\n方法\n情形\n计算公式\n\n\n\n\n配对四格表卡方检验\n当\\((b+c)\\ge 40\\)时当\\((b+c)&lt;40\\)时\n配对卡方检验专用公式校正配对卡方检验专用公式\n\n\n配对R×R交叉表数据的\\(\\chi^2\\)检验\nR（\\(R\\ge2\\)）\n\\(T=\\frac{k-1}{k}\\sum_{i=1}^{k}\\frac{(n_i-m_i)^2}{n_i+m_i-2A_{ii}}\\)\n\n\n\nnotice：\n\n配对\\(\\chi^2\\)检验的基本公式：\\(\\chi^2=\\sum \\frac{(A-T)^2}{T}=\\frac{(b-c)^2}{b+c}\\)。\n若b+c&lt;40,使用校正的配对\\(\\chi^2\\)检验的基本公式：\\(\\chi^2=\\sum \\frac{(|b-c|-1)^2}{b+c}\\)。\n\n\n\n\n\n\n\n\n建立假设检验，确定检验水准 \\(H_0\\):两变量之间相互独立 \\(H_1\\):两变量之间相互独立 \\(\\alpha=0.05\\)\n计算检验统计量 [^2=_{i,j} ]\n确定P值，做出推断\n关联系数的计算 [r=]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n类目\n内容\n\n\n\n\n假设检验\n\\(H_0\\)：各组总体率（或构成比）相同。\\(H_1\\)：各组总体率（或构成比）不同（不全相同）。\n\n\n计算公式\n卡方检验基本公式，自由度为：\\(v=(R-1)(C-1)\\)\n\n\n数据要求\n1. 应用条件：不能有理论频数小于1的格子，或者不能有1/5以上的理论频数大于等于1且小于5 2. 不能进行卡方检验时的解决办法：①增加样本量；②合并或删除理论频数比较小的行或列；③采用Fisher确切概率法\n\n\n卡方分割\n多个率或多个频率分布比较的卡方检验，当结论为拒绝\\(H_0\\)时，仅表示多组之间是有差别的。若需要明确研究是那两组之间存在差别，可做率的多重比较，将R×C表分割为若干个小的四格表进行检验，并且需要根据比较的次数合理地修正检验水准\\(\\alpha\\)，否则将人为地增大犯第一类错误的概率\n\n\n\nnotice:\n\n多个独立样本率的比较，根据R个独立样本的频率分布，是检验R个二项分布总体的概率是否相同，。假设对四个样本率进行比较，进行\\(\\chi^2\\)检验，则它的行数为4，列数为2，其自由度为\\(v=(R-1)×(C-1)=(4-1)(2-1)=3\\)。\n针对行列表资料的\\(\\chi^2\\)检验，若有\\(1/5\\)格子以上的理论频数小于5，即\\(1\\le T\\le5\\)时，应考虑增加样本量，或结合专业知识对行或列进行合并。",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "非参数检验"
    ]
  },
  {
    "objectID": "Learn/Basic/09-non-parameter-test.html#卡方检验",
    "href": "Learn/Basic/09-non-parameter-test.html#卡方检验",
    "title": "非参数检验",
    "section": "",
    "text": "资料特征\n数据特征\n\n完全随机设计\n\n配对设计\n随机区组\n\n\n\n\n\n\n单组\n两组\n多组\n\n\n\n\n分类资料\n无序分类资料\n二项分布直接计算概率法、正态近似法（Z检验）、率的正态近似\n独立四格表\\(\\chi^2\\)检验、Fisher确切概率法\nR×C交叉表\\(\\chi^2\\)检验、Fisher确切概率法\n配对四格表\\(\\chi^2\\)检验，配对R×R列联表\\(\\chi^2\\)检验\n/\n\n\n\n等级资料\nWilcoxon符合秩和检验\nwilcoxon秩和检验\nKruskal-Wallis H检验\nWilcoxon符合秩和检验\nFriedman M秩和检验\n\n\n\n\n\n\n\n\n\n\n\n\n\n方法\n内容\n\n\n\n\n确切概率法\n1. 适用情形：样本量较小或\\(\\pi_0\\)不靠近0.5时作单侧检验的情形。2. 计算公式：(1)最多有k例阳性的概率：\\(Pr(X\\le k)\\)(2)最少有k例阳性的概率：\\(Pr(X\\ge k)\\)\n\n\n正态近似法\n1. 适用情形：样本量较大时，\\(n\\pi,n(1-\\pi)\\)均大于5；2. 计算公式：分子为\\(p-\\pi_0\\)，分母为率的标准误\n\n\n\nnotice：上式中p为样本率，\\(\\pi_0\\)为给的总体率（常为理论值或标准值），n为样本含量。",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "非参数检验"
    ]
  },
  {
    "objectID": "Learn/Basic/09-non-parameter-test.html#率的比较",
    "href": "Learn/Basic/09-non-parameter-test.html#率的比较",
    "title": "非参数检验",
    "section": "",
    "text": "方法\n情形\n计算公式\n\n\n\n\n独立四格表卡方检验\n\\(n\\ge 40\\)且所有的\\(T\\ge 5\\)\\(n\\ge 40\\)且任一理论频数有\\(1\\le T&lt; 5\\)当\\(n&lt;40\\)，或任一一个格子理论频数\\(T&lt;1\\)时\n卡方基本公式、独立四格表专用公式同上、但是需要校正用四格表资料的Fisher确切概率法\n\n\n正态近似法\n\\(n_1p_1,n_1(1-p_1),n_2p_2,n_2(1-p_2)\\)均大于5\n分子为样本率之差，分母为样本率差的标准误\\(S_{p1-p2}\\)为两个样本率之差的标准误，\\(p_c=\\frac{x_1+x_2}{n_1+n_2}\\)为两样本的合并率\n\n\n校正样本率的正态近似法\n当\\(n_1p_1,n_1(1-p_1),n_2p_2,n_2(1-p_2)\\)不太大时\n同上，但是需要对样本率实施“分子+2、分母+4”的校正\n\n\n\nnotice：\n\n正态近似法与卡方检验结果是很接近的。在日常计算时，因为计算简便，故常用卡方检验公式。\n四格表的自由度为1。\n四格表实际频数变动时，若周边合计数保持不变，则理论频数将不会产生变化。\n用\\(n_R\\)和\\(n_C\\)和n分别表示行合计、列合计和总合计，则计算每格理论数的公式为：\\(T_{RC}=\\frac{n_R×n_C}{n}\\)。\n\\(\\chi^2\\)检验的基本公式：\\(\\chi^2=\\sum \\frac{(A-T)^2}{T}\\)。\n校正的\\(\\chi^2\\)检验的基本公式：\\(\\chi^2=\\sum \\frac{(|A-T|-0.5)^2}{T}\\)。\n\n\n\n\n\n\n\n\n\n\n\n\n方法\n情形\n计算公式\n\n\n\n\n配对四格表卡方检验\n当\\((b+c)\\ge 40\\)时当\\((b+c)&lt;40\\)时\n配对卡方检验专用公式校正配对卡方检验专用公式\n\n\n配对R×R交叉表数据的\\(\\chi^2\\)检验\nR（\\(R\\ge2\\)）\n\\(T=\\frac{k-1}{k}\\sum_{i=1}^{k}\\frac{(n_i-m_i)^2}{n_i+m_i-2A_{ii}}\\)\n\n\n\nnotice：\n\n配对\\(\\chi^2\\)检验的基本公式：\\(\\chi^2=\\sum \\frac{(A-T)^2}{T}=\\frac{(b-c)^2}{b+c}\\)。\n若b+c&lt;40,使用校正的配对\\(\\chi^2\\)检验的基本公式：\\(\\chi^2=\\sum \\frac{(|b-c|-1)^2}{b+c}\\)。",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "非参数检验"
    ]
  },
  {
    "objectID": "Learn/Basic/09-non-parameter-test.html#独立性检验",
    "href": "Learn/Basic/09-non-parameter-test.html#独立性检验",
    "title": "非参数检验",
    "section": "",
    "text": "建立假设检验，确定检验水准 \\(H_0\\):两变量之间相互独立 \\(H_1\\):两变量之间相互独立 \\(\\alpha=0.05\\)\n计算检验统计量 [^2=_{i,j} ]\n确定P值，做出推断\n关联系数的计算 [r=]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n类目\n内容\n\n\n\n\n假设检验\n\\(H_0\\)：各组总体率（或构成比）相同。\\(H_1\\)：各组总体率（或构成比）不同（不全相同）。\n\n\n计算公式\n卡方检验基本公式，自由度为：\\(v=(R-1)(C-1)\\)\n\n\n数据要求\n1. 应用条件：不能有理论频数小于1的格子，或者不能有1/5以上的理论频数大于等于1且小于5 2. 不能进行卡方检验时的解决办法：①增加样本量；②合并或删除理论频数比较小的行或列；③采用Fisher确切概率法\n\n\n卡方分割\n多个率或多个频率分布比较的卡方检验，当结论为拒绝\\(H_0\\)时，仅表示多组之间是有差别的。若需要明确研究是那两组之间存在差别，可做率的多重比较，将R×C表分割为若干个小的四格表进行检验，并且需要根据比较的次数合理地修正检验水准\\(\\alpha\\)，否则将人为地增大犯第一类错误的概率\n\n\n\nnotice:\n\n多个独立样本率的比较，根据R个独立样本的频率分布，是检验R个二项分布总体的概率是否相同，。假设对四个样本率进行比较，进行\\(\\chi^2\\)检验，则它的行数为4，列数为2，其自由度为\\(v=(R-1)×(C-1)=(4-1)(2-1)=3\\)。\n针对行列表资料的\\(\\chi^2\\)检验，若有\\(1/5\\)格子以上的理论频数小于5，即\\(1\\le T\\le5\\)时，应考虑增加样本量，或结合专业知识对行或列进行合并。",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "非参数检验"
    ]
  },
  {
    "objectID": "Learn/Basic/09-non-parameter-test.html#秩和检验",
    "href": "Learn/Basic/09-non-parameter-test.html#秩和检验",
    "title": "非参数检验",
    "section": "2.1 秩和检验",
    "text": "2.1 秩和检验\n秩和检验（Rank-Sum Test）是一种非参数检验方法，用于比较两个独立样本的分布是否存在显著差异。它无需对数据分布作正态性假设，适用于数据偏离正态分布、样本量较小或数据为序数型变量的场景。\n常见的秩和检验包括：\n\nMann-Whitney U 检验（也称Wilcoxon秩和检验）：用于比较两个独立样本的中位数是否相等。\nWilcoxon 符号秩检验：用于两个配对样本的比较（类似配对t检验，但无需正态性假设）。\n\n\n2.1.1 秩和检验的公式\n\nMann-Whitney U 检验公式\n\n假设两组独立样本分别为 \\(X\\) 和 \\(Y\\)，样本量分别为 \\(n_1\\) 和 \\(n_2\\)。\n对两组样本合并并按大小排序，赋予秩次。计算两组的秩次和 \\(R_1\\) 和 \\(R_2\\)（分别为 $ X$ 和 \\(Y\\) 的秩次总和）。\n\n确定统计量T值：\n\n假设两组样本量 \\(n_1&lt;n_2\\)，一般情况下以样本量较小者\\(n_1\\)对应的秩和\\(T_1\\)为检验统计量\\(T\\)，当样本相等时可以选择任一组的秩和为\\(T\\)。1\n当两组中样本量较小者不低于10时，在\\(H_0\\)成立假设下，统计量\\(T\\)的抽样分布近似于正态分布，有\n\\[T\\approx N\\left(\\frac{n_1(n+1)}{2},\\frac{n_1 n_2(n+1)}{12} \\right)\\] 此时，Wilcoxon 秩和统计量在\\(H_0\\)下关于\\(\\mu=\\frac{n_1(n+1)}{2}\\)对称。\n如果没有或存在较少的“结”，将\\(T\\)标准化后为：\n\\[U=\\frac{T-\\frac{n_1(n+1)}{2}+C}{\\sqrt{\\frac{n_1 n_2(n+1)}{12}}}\\approx N(0,1)\\]\n其中，C为连续性校正系数，当\\(T&gt;\\frac{n(n+1)}{4}\\)时，\\(C=-0.5\\)，当\\(T&lt;\\frac{n(n+1)}{4}\\)时，\\(C=0.5\\)，当\\(T=\\frac{n(n+1)}{4}\\)时，\\(C=0\\)。\n若“结”的比例较多（&gt;25%），则用以下公式校正：\n\\[U_c=\\frac{T-\\frac{n_1(n+1)}{2}+C}{\\sqrt{\\frac{n_1 n_2}{12}[(n+1)-\\sum_\\limits{i=1}^{g}\\frac{t_i^3-t_i}{n(n-1)}]}}\\approx N(0,1)\\]\n\nWilcoxon 符号秩检验公式\n\n对配对样本 \\((X_i, Y_i)\\)，计算差值 \\(D_i = X_i - Y_i\\)，取非零差值的绝对值并排序（若差值为0则舍去不计，且减去相应的个数），赋予秩次 \\(R_i\\)。再根据差值的符号计算符号秩次和 \\(W\\)：\n\\[W = \\sum R_i \\cdot \\text{sign}(D_i)\\]\n检验统计量 \\(T\\) 是 \\(W\\) 的绝对值，依据表或正态分布计算显著性。\n正态近似法：\n当\\(n\\ge 30\\)时，有中心极限定理可知，当\\(H_0\\)成立时统计量\\(T\\)的抽样分布近似正态分布，有\n\\[T\\approx N \\left(\\frac{n(n+1)}{4},\\frac{n(n+1)(2n+1)}{24}\\right)\\] 其中，均数\\(\\mu=\\frac{n(n+1)}{4}\\)，方差\\(\\sigma^2=\\frac{n(n+1)(2n+1)}{24}\\)。 将T标准化后，近似服从标准正态分布，有\n\\[U=\\frac{T-\\frac{n(n+1)}{4}+C}{\\sqrt{\\frac{n(n+1)(2n+1)}{24}}}\\approx N(0,1)\\] 其中，n是差值不为0的对子数，C为连续性校正系数，当\\(T&gt;\\frac{n(n+1)}{4}\\)时，\\(C=-0.5\\)，当\\(T&lt;\\frac{n(n+1)}{4}\\)时，\\(C=0.5\\)，当\\(T=\\frac{n(n+1)}{4}\\)时，\\(C=0\\)。\n当N较大时，样本中可能存在较多的“结”，（如“结”所占比例大于25%），此时需要使用校正公式：\n\\[U=\\frac{T-\\frac{n(n+1)}{4}+C}{\\sqrt{\\frac{n(n+1)(2n+1)}{24}-\\frac{\\sum_\\limits{i=1}^g(t_i^3-t_i)}{48}}}\\approx N(0,1)\\] 其中，\\(t_i\\)为\\(i\\)个“结”中有相同秩次的个数，\\(g\\)是“结”的个数。\nWilcoxon符号秩检验的前提条件为数据是连续的且差值分布是对称的。\nnotice：秩和秩和的区别：秩是指全部观察值按某种顺序排列的位序，在一定程度上反映了等级的高低；而秩和则表示同组秩次之和，在一定程度上反映了等级的分布。2\n\n\n2.1.2 应用场景\n\nMann-Whitney U 检验：\n\n比较两个独立样本的中位数是否存在显著差异。\n\n适用于非正态分布数据或含有极端值的样本。\n\n示例：比较两种治疗方法的疗效（不同受试者组）。\n\nWilcoxon 符号秩检验：\n\n比较两个配对样本的中位数差异。\n\n适用于重复测量数据或实验设计中存在配对关系的场景。\n\n示例：同一批受试者在治疗前后血压的变化。\n\n\n\n\n2.1.3 注意事项\n\n秩和检验是非参数方法，对数据分布假设少，但效率可能低于参数方法（如t检验）在满足条件时的效果，如果满足参数检验的条件，应优先考虑使用参数检验的方法，否则会增加犯二类错误的概率。\n数据需要满足独立性假设，否则检验结果可能不准确。\n\nend.",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "非参数检验"
    ]
  },
  {
    "objectID": "Learn/Basic/09-non-parameter-test.html#footnotes",
    "href": "Learn/Basic/09-non-parameter-test.html#footnotes",
    "title": "非参数检验",
    "section": "脚注",
    "text": "脚注\n\n\n不是说一定要选择样本量较小者对应的秩和作为检验统计量，只是长期的使用习惯，造成了这一惯例。如果取较小的秩和计算后得到的\\(U&lt;u_{\\alpha/2}\\)，则表示拒绝\\(H_0\\)；相反，如果取较大的秩和计算后得到的\\(U&gt;u_{1-\\alpha/2}\\)，也会表示拒绝\\(H_0\\)，他们都表示检验统计量落在了拒绝域中。↩︎\n尽管非参数方法对总体分布形式未做要求，但如果我们知道总体的一些性质而不去利用，就会浪费许多有用的信息，最常见的就是分布的对称性，配对设计的 Wilcoxon 符号秩检验充分利用了差值分布对称性这一信息，这与尽可能地采用有效方法，利用尽可能多的信息进行统计分析的大原则相一致。↩︎",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "非参数检验"
    ]
  },
  {
    "objectID": "Learn/Bayes/00-About-Bayes.html",
    "href": "Learn/Bayes/00-About-Bayes.html",
    "title": "贝叶斯与概率推理",
    "section": "",
    "text": "Bayes系列的笔记主要基于Learning-Probabilistic-Graphical-Models-in-R.\n皮埃尔-西蒙·拉普拉斯(Pierre-Simon Laplace,1749-1827)，法国数学家，也是有史以来最伟大的科学家之被认为是第一批理解数据收集重要性的人:他发现了数 -，不据不可靠，有不确定性，也就是今天说的有噪声。他也是第一个研究使用概率来处理不确定性等问题，并表示事件或信息信念度的人。\n在他的论文《概率的哲学》​（Essai philosophique sur lesprobabilités,1814）中，拉普拉斯给出了最初的支持新老数据推理的数学系统，其中的用户信念会在新数据可用的时候得到更新和改进。\n概率是表示和处理不确定性的严密的数学方法。\n概率是一种量化常识推理和信念程度的工具。\n概率图模型，从数学的角度看，是一种表示几个变量概率分布的方法，也叫作联合概率分布。换句话说，它是一种表示几个变量共同出现的数值信念的工具。基于这种理解，虽然概率图模型看起来很简单，但是概率图模型强调的是对于许多变量概率分布的表示。",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "贝叶斯与概率推理"
    ]
  },
  {
    "objectID": "Learn/Bayes/00-About-Bayes.html#联合概率分布",
    "href": "Learn/Bayes/00-About-Bayes.html#联合概率分布",
    "title": "贝叶斯与概率推理",
    "section": "\n1 联合概率分布",
    "text": "1 联合概率分布\n当我们同时考虑两个试验（投掷硬币2次和投掷一个骰子）的时候，我们对同时获得0、1或2的概率以及1、2、3、4、5或6的点数概率更感兴趣。这两个同时考虑的随机变量的概率分布写作 \\(P(N, D)\\) ，称作联合概率分布。\n一个概率图模型就是一个联合概率分布。除此之外，别无他物。\n联合概率分布的最后一个重要概念是边缘化（marginalization）。\n联合分布\\(P(X,Y)\\)的边缘分布\\(P(X)\\)可以通过下列操作获得：\n\\[P(X)=\\sum_y P(X,Y)\\]\n当Y值是连续值是，边缘化可以写作：\n\\(P(X)=\\int_{y} P(X,y) \\mathrm{d}y\\)。",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "贝叶斯与概率推理"
    ]
  },
  {
    "objectID": "Learn/Bayes/00-About-Bayes.html#贝叶斯规则",
    "href": "Learn/Bayes/00-About-Bayes.html#贝叶斯规则",
    "title": "贝叶斯与概率推理",
    "section": "\n2 贝叶斯规则",
    "text": "2 贝叶斯规则\n\n2.1 条件概率\n条件概率是指在知道其他时间发生的条件下当前事件的概率。很明显，两个事件必须某种程度的依赖，否则一个事件的发生不会影响另一个事件。\n条件概率转化为公式如下：\n\\(P(X|Y)=\\frac{P(X,Y)}{P(Y)}\\)和\\(P(Y|X)=\\frac{P(X,Y)}{P(X)}\\)\n\n2.2 贝叶斯公式\n从上述两个公式推导出贝叶斯公式：\n\\(P(X|Y)=\\frac{{P(Y|X)}·P(X)}{P(Y)}\\)\n在这个公式中，我们把 \\(P(X|Y)\\) 叫做是给定\\(Y\\)下\\(X\\)的后验分布，因此，\\(P(X)\\) 叫做后验分布。",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "贝叶斯与概率推理"
    ]
  },
  {
    "objectID": "Learn/Bayes/00-About-Bayes.html#例子机器与灯泡",
    "href": "Learn/Bayes/00-About-Bayes.html#例子机器与灯泡",
    "title": "贝叶斯与概率推理",
    "section": "\n3 例子：机器与灯泡",
    "text": "3 例子：机器与灯泡\n在构建贝叶斯统计的时候，我们总是需要建立两个部件：\n\n先验分布\n似然率\n\n先验分布使我们关于机器工作状态的初试信念。我们确定了第一个刻画机器状态的随机变量 \\(M\\) 。这个随机变量有两个状态 \\({working,broken}\\) 。我们相信机器是好的，是可以正常工作的，所以先验分布如下：\n\n\\(P(M=working)=0.99\\)\n\\(P(M=broken)=0.01\\)\n\n\n3.1 R代码的实现\n先验分布、似然率和数据序列\n\nprior &lt;- c(working=0.99, broken=0.01) \nlikelihood &lt;- rbind( \n    working = c(good = 0.99, bad = 0.01),broken = c(good = 0.6, bad = 0.4) \n) \ndata &lt;- c(\"bad\", \"bad\", \"bad\", \"bad\") \n\n贝叶斯更新函数\n\nbayes &lt;-function(prior, likelihood, data)\n{\nposterior &lt;-matrix(0, nrow =length(data), ncol =length(prior))\ndimnames(posterior) &lt;-list(data, names(prior))\ninitial_prior &lt;-prior\nfor (i in 1:length(data))\n{\nposterior[i, ] &lt;-\nprior *likelihood[, data[i]]/\nsum(prior *likelihood[, data[i]])\nprior &lt;-posterior[i, ]\n}\nreturn(rbind(initial_prior, posterior))\n}\n\n\n创建一个矩阵，存储后验分布的连续计算结果。\n然后对于每一个数据，给定当前先验概率计算后验概率：和之前的一样，你可以看到贝叶斯公式的R代码。\n最后，新的先验概率是当前的后验概率，而且同样的过程可以迭代。\n分布的演化情况\n\nmatplot(bayes(prior, likelihood, data), t ='b', \n        lty =1, pch =20,\n        col =c(3, 2))\n\n\n\n\n\n\n\n随着坏灯泡的增多，机器正常的概率快速下降（绿色线）。\n如果我们换一个先验分布，假设我们不知道机器是否可以正常工作，即好坏参半，我们给定如下概率：\n\nprior &lt;- c(working = 0.5, broken = 0.5)\nmatplot(bayes(prior, likelihood, data), t ='b', \n        lty =1, pch =20,\n        col =c(3, 2))\n\n\n\n\n\n\n\n这个曲线快速收敛，机器有问题的概率很高。\n再对数据变换一下，假设机器正常工作的概率是99%，我们观察10个灯泡，其中一个灯泡是坏的：\n\nprior =c(working =0.99, broken =0.01)\ndata =c(\"bad\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\",\"good\", \"good\", \"good\")\nmatplot(bayes(prior, likelihood, data), t ='b', pch =20, col =c(3, 2))\n\n\n\n\n\n\n\n算法在第一个灯泡处犹豫了一下，因为这么好的机器不太可能生产出一个坏灯泡。然后它又收敛到很高的概率，因为好灯泡的序列不会预示任何问题。\nend.",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "贝叶斯与概率推理"
    ]
  },
  {
    "objectID": "navbar/book.html",
    "href": "navbar/book.html",
    "title": "公共卫生相关的书籍",
    "section": "",
    "text": "读的书有点乱，主要都在微信读书看，部分是纸质书，介绍主要以我看过或在看的书为主。\n\n1 Maybe you will be interested\n对于刚接触统计的朋友，可以先看看《女士品茶：统计学如何变革了科学和生活》这本书，也会他能激发你的一些对于统计学（家们）的兴趣，通过一些有趣的小故事，带你走进统计学的世界。\n2025-03-30，出于对 THE LADY TASTING TEA 的兴趣，后续将会整理一下出现的主要统计学家和他的主要成果（公式）。\n\n\n2 Basic\n考研的话，除了人卫第八版是一个通用教材，其他的院校各有不同，比如说赵耐青、方积乾和贺佳，根据院校给的参考书目来选择，这几个人的书都买了看过一下，个人主要用过人卫版和姜晶梅的《医学统计学》，各有见长。\n\n\n3 Advance\n提升部分可以看看 Springer 出版的 Mathematical Models in Epidemiology ，2023年科学出版社出版了中文版 《流行病学中的数学模型》\n\nThe book is a comprehensive, self-contained introduction to the mathematical modeling and analysis of disease transmission models. It includes (i) an introduction to the main concepts of compartmental models including models with heterogeneous mixing of individuals and models for vector-transmitted diseases, (ii) a detailed analysis of models for important specific diseases, including tuberculosis, HIV/AIDS, influenza, Ebola virus disease, malaria, dengue fever and the Zika virus, (iii) an introduction to more advanced mathematical topics, including age structure, spatial structure, and mobility, and (iv) some challenges and opportunities for the future.\nThere are exercises of varying degrees of difficulty, and projects leading to new research directions. For the benefit of public health professionals whose contact with mathematics may not be recent, there is an appendix covering the necessary mathematical background. There are indications which sections require a strong mathematical background so that the book can be useful for both mathematical modelers and public health professionals.\n\nend."
  },
  {
    "objectID": "Quarto/quarto-intro.html",
    "href": "Quarto/quarto-intro.html",
    "title": "Quarto introduction",
    "section": "",
    "text": "Quarto introduction\n\nAn open-source scientific and technical publishing system\n\nAuthor using Jupyter notebooks or with plain text markdown in your favorite editor.\nCreate dynamic content with Python, R, Julia, and Observable.\nPublish reproducible, production quality articles, presentations, dashboards, websites, blogs, and books in HTML, PDF, MS Word, ePub, and more.\nShare knowledge and insights organization-wide by publishing to Posit Connect, Confluence, or other publishing systems.\nWrite using Pandoc markdown, including equations, citations, crossrefs, figure panels, callouts, advanced layout, and more.\n\n\n\nAnalyze. Share. Reproduce. You have a story to tell with data—tell it with Quarto.\nFrom https://quarto.org/\nend.",
    "crumbs": [
      "Home",
      "Quarto introduction"
    ]
  },
  {
    "objectID": "Guide/R/2025-02-22-CLHLS.html#构建logistic回归模型",
    "href": "Guide/R/2025-02-22-CLHLS.html#构建logistic回归模型",
    "title": "CLHLS Data Analysis by R",
    "section": "\n3.1 构建Logistic回归模型",
    "text": "3.1 构建Logistic回归模型\nLogistic 回归分析最大的一个优势可能就是广泛涉及优势比（？），在这里介绍一下优势比的概念。\n\n3.1.1 优势比\n优势（Odds）是指某事件的发生概率 \\(\\pi\\) 与该事件不发生的概率 \\(1-\\pi\\) 之比，亦称为比，记为 Odds ，某事件在两种不同条件下的优势之比称为优势比（Odds Ratio，OR）。优势比在流行病学中的病例对照研究中被普遍应用（当然不仅限于病例对照研究）。\n设某事件的两种不同暴露的发生概率分别为 \\(\\pi_1\\) 和 \\(\\pi_0\\) ，对应的 \\(Odds_1= \\pi_1 /（1-\\pi_1）\\)，\\(Odds_0 =\\pi_0 /（1-\\pi_0）\\) ，两个 \\(Odds\\) 之比定义为 \\(OR=Odds_1/Odds_0\\)。\n由于 \\(Odds=\\pi /(1-\\pi)=(\\pi-1+1)/(1-\\pi)=－1+1 /(1-\\pi)\\) 以及 \\(0＜ \\pi ＜1\\)，所以 \\(\\pi\\) 越大，\\(Odds\\) 就越大，反之 \\(\\pi\\) 越小，\\(Odds\\) 就越小，特別当 \\(\\pi\\) 越接近 0时，\\(Odds\\) 也越接近 0，因此优势和优势比具有下列性质。\n\n如果 \\(\\pi_1 = \\pi_0\\)。，对应有 \\(Odds_1=Odds_0\\) , \\(OR=1\\) 。\n如果 \\(\\pi_1&gt;\\pi_0\\) ，则 \\(Odds_1&gt;Odds_o\\) ，相应有 $ OR&gt;1$ 。同理如果 \\(\\pi_1&lt;\\pi_0\\)，则 \\(Odds_1&lt;Odds_0\\) ，相应有 \\(OR &lt; 1\\)。\n\n由于概率 \\(\\pi_1\\) 也可以用 \\(Odds\\) 表示，\\(\\pi=\\frac{Odds}{1+Odds}\\) ，所以也可以通过比较 \\(Odds_1\\) 与 \\(Odds_0\\) 的大小来推断 \\(\\pi_1\\) 和 \\(\\pi_0\\) 的大小关系，即可以用 \\(OR&gt;1\\), \\(OR=1\\) 或 \\(OR&lt;1\\) 推断 \\(\\pi_1\\) 和 \\(\\pi_0\\) 的大小关系。\n\n3.1.2 Logistic 回归模型\nLogistic 回归模型的因变量必须为分类变量，主要有三种：二分类 Logistic 回归模型、有序分类 Logistic 回归模型、无序分类 Logistic 回归模型。其中二分类 Logistic 回归模型最为常用。自变量则无要求，可以是定量变量、有序分类变量和无序分类变量。\n假如研究所关注的事件（如死亡或痊愈等）是否发生用因变量 \\(Y\\) 表示，\\(Y=1\\) 表示该结局事件发生，反之，\\(Y=0\\) 表示该结局事件未发生。\n那么可构建如下方程式：\n\\[logit(\\pi(Y=1))=ln\\frac{\\pi(Y=1)}{\\pi(Y=0)}=ln\\frac{\\pi(Y=1)}{1-\\pi(Y=1)}=\\beta_0 + \\beta_1 X_1 + \\cdot \\beta_p X_p\\]\n\n3.1.3 共线性检验\n共线性(Colinearity)指的是自变量之间存在高度相关性。这种情况会导致回归系数的不稳定，并使得对模型参数 的估计变得不可靠。在 Logistic 回归中，严重的共线性可能导致模型性能下降，甚至可能导致预测结果难以解释\n方差膨胀因子是统计学中用于衡量多元线性回归模型中自变量之间共线性程度的指标，提供了一种定量的方式来评估自变量之间的共线性。\n方差膨胀因子的解释标准通常如下：如果VIF值小于5，表示自变量之间的共线性程度较低，可以接受。如果VIF值在5到10之间， 表示自变量之间存在一定程度的共线性，但尚可接受。如果VIF值大于10，表示自变量之间存在严重的共线性问题， 需要考虑进行变量选择或者采取其他方法来处理共线性。\n自评健康作为 因变量 ，自变量是 经济支持、生活支持和情绪支持，在前序的处理过程，只有原始的的经济支持变量（加总金额）是定量变量，其他两个都是做的二分类变量处理，如何做共线性检验，看起来并不明朗，因为三个变量看起来没有太多的关系，但是控制变量有些可能存在相关性，但是，是否有对控制变量做共线性检验的必要？\n\n3.1.4 2025-03-07 共线性检验\n使用car包对共线性进行检验。\n理论上，共线性检验较为简单，但是在处理此数据时，碰壁较多。\n首先核查数据的完整性，删除全NA和单一值变量，再将分类变量转换为因子类型，经济变量这里也是用“经济分组”这一变量处理，即所有的变量都是分类变量。（全部为分类变量在这里处理其实可能有些问题，我暂未找到合适的处理办法，寻找相关的信息也没有较为清晰地答案）\n\n# library(car)\n# 数据完整性检查，删除全NA和单一值变量\nvalid_vars &lt;- all_predictors[sapply(final_data[, all_predictors, drop = FALSE], function(x) !(all(is.na(x)) || length(unique(na.omit(x))) == 1))]\nfinal_data &lt;- final_data[, c(outcome, valid_vars)]\n\n# 仅将二分类变量转换为因子类型\nbinary_vars &lt;- valid_vars[sapply(final_data[, valid_vars], function(x) length(unique(na.omit(x))) == 2)]\nfinal_data &lt;- final_data %&gt;% mutate(across(all_of(binary_vars), as.factor))\n\n# VIF计算\nif (length(valid_vars) &gt; 1) {\n  formula_vif &lt;- as.formula(paste(outcome, \"~\", paste(valid_vars, collapse = \" + \")))\n  lm_model &lt;- lm(formula_vif, data = final_data)\n  vif_values &lt;- vif(lm_model)\n  \n  vif_df &lt;- data.frame(\n    Variable = names(vif_values),\n    VIF = round(vif_values, 3)\n  )\n  mean_vif &lt;- mean(vif_values, na.rm = TRUE)\n  # 结果保留两位小数\n  mean_vif &lt;- round(mean_vif, 3)\n  \n  # 保存结果\n  writeLines(c(\"=== 多重共线性检验 (VIF Results) ===\", \n               paste(\"平均 VIF 值:\", round(mean_vif, 3)), \"\",\n               capture.output(print(vif_df))), con = output_vif_file)\n  \n  write_xlsx(list(VIF_Results = vif_df, Mean_VIF = data.frame(Statistic = \"平均 VIF 值\", Value = round(mean_vif, 3))), \n             output_vif_excel)\n  \n  cat(\"VIF 检验完成，结果已保存至:\", output_vif_file, \"和\", output_vif_excel, \"\\n\")\n} else {\n  cat(\"错误：自变量数量不足，无法计算 VIF\\n\")\n}\n\n\n3.1.5 logistic 回归\n\n# 5. Logistic 回归分析\nlogistic_results &lt;- list()\n\nfor (outcome in outcomes) {\n  formula &lt;- as.formula(\n    paste(outcome, \"~\", paste(independents, collapse = \" + \"), \"+\", paste(controls, collapse = \" + \"))\n  )\n  \n  model &lt;- glm(formula, data = final_data, family = binomial(link = \"logit\"))\n  \n  # 提取回归结果，保留三位小数\n  model_summary &lt;- summary(model)\n  coef_table &lt;- as.data.frame(coef(model_summary)) %&gt;%\n    mutate(\n      Variable = rownames(.),\n      OR = round(exp(Estimate), 3),\n      OR_Lower = round(exp(Estimate - 1.96 * `Std. Error`), 3),\n      OR_Upper = round(exp(Estimate + 1.96 * `Std. Error`), 3),\n      `Wald χ²` = round((Estimate / `Std. Error`)^2, 3),\n      df = 1\n    ) %&gt;%\n    select(Variable, df, Estimate, `Std. Error`, `Wald χ²`, `Pr(&gt;|z|)`, OR, OR_Lower, OR_Upper) %&gt;%\n    rename(\n      `回归系数` = Estimate,\n      `标准误` = `Std. Error`,\n      `P 值` = `Pr(&gt;|z|)`\n    ) %&gt;%\n    mutate(across(c(`回归系数`, `标准误`, `P 值`), ~ round(.x, 3)))\n  \n  logistic_results[[outcome]] &lt;- coef_table\n}\n\n# 6. 生成 Word 文档\ndoc &lt;- read_docx()\n\nfor (outcome in outcomes) {\n  doc &lt;- doc %&gt;%\n    body_add_par(value = paste(\"Logistic 回归分析结果：因变量 =\", outcome), style = \"heading 1\") %&gt;%\n    body_add_flextable(flextable(logistic_results[[outcome]]) %&gt;%\n                         set_table_properties(width = 1, layout = \"autofit\"))\n}\n\nprint(doc, target = output_logistic_file)\ncat(\"Logistic 回归分析结果已保存至:\", output_logistic_file, \"\\n\")",
    "crumbs": [
      "Home",
      "统计软件使用历程",
      "R",
      "CLHLS Data Analysis by R"
    ]
  },
  {
    "objectID": "Guide/Python/25-03-09-cos-reg.html",
    "href": "Guide/Python/25-03-09-cos-reg.html",
    "title": "用Python做生存分析和COX回归",
    "section": "",
    "text": "生存分析（survival analysis）是一种统计方法，用于分析时间数据， 主要研究生存时间和结局的分布及其影响因素的统计方法。在生存分析中，每个研究对象的结局变量由 “time”（生存时间） 和 “status”（生存状态）组成。生存时间是指从某个特定时间点开始，到某个事件的节点时，事件数据是指某个事件是否发生。 生存时间是一个非负实数，生存状态是一个二元变量，通常用1表示事件发生，0表示事件未发生。\n生存分析的主要应用领域是医学、生物学、工程学、经济学等。\n\n\n生存函数（survival function）是生存分析的基本概念之一，它是一个函数，用于刻画研究对象在某个时刻 t 内存存活的概率。 生存函数通常用 \\(S(t)\\) 表示。\n风险函数（hazard function）是生存分析的另一个基本概念，用于刻画研究对象在某个时刻 t 还存活但是极短的时间内死亡的风险。 风险函数通常用 \\(h(t)\\) 表示。\n如果记寿命分布的密度为 \\(f(t)\\)，则有： \\(h(t) = f(t) / S(t)\\) 。\n\n\n\n这里使用 R 语言 survival 包中的 ovarian 数据集，该数据集来自一项比较卵巢癌患者在两种治疗方式下的生存率比较的随机对照试验。\n首先找到 ovarian 数据集，你可以从互联网上寻找相关资源；或者从 R 的 survival 包中导出这一数据集，操作如下：\n# install.packages(\"survival\")\nlibrary(survival)\novarian\ndata(cancer, package=\"survival\")\n\ndf &lt;- ovarian\nwrite.csv(df, \"your-file-path\\\\ovarian.csv\", row.names = FALSE)\n将数据集下载到你的工作目录，然后使用 Pandas 导入与读取：\n\nimport pandas as pd\novarian = pd.read_csv(r\"C:\\Users\\asus\\Desktop\\R\\quarto\\Med-Stat-Notes\\Data\\ovarian.csv\")\novarian.head()\n\n\n\n\n\n\n\n\nfutime\nfustat\nage\nresid.ds\nrx\necog.ps\n\n\n\n\n0\n59\n1\n72.3315\n2\n1\n1\n\n\n1\n115\n1\n74.4932\n2\n1\n1\n\n\n2\n156\n1\n66.4658\n2\n1\n2\n\n\n3\n421\n0\n53.3644\n2\n2\n1\n\n\n4\n431\n1\n50.3397\n2\n1\n1\n\n\n\n\n\n\n\n数据集包括 26 个观测值，6 个变量。变量如下：futime（随访时间），fustat（研究结束时的状态：0 表示存活，1表示死亡），age（患者的年龄），resid.ds（疾病残留情况：1 表示有残留，2 表示没有残留），rx（治疗方式：1 表示环磷酰胺，2 表示环磷酰胺+阿霉素）和 ecog.ps（患者的 ECOG 评分：1 表示较好，2 表示较差）。\n对年龄进行分组，分为 &lt;50 和 &gt;50 两组，并将其他三个变量的各水平加上相应的标签。\n\n# 查看 ovarian(DataFrame)的变量名，因为不同的渠道下载的 Dataset 可能会有区别\nprint(ovarian.columns)\n\n# 将 age 列转换为数值类型\novarian['age'] = pd.to_numeric(ovarian['age'], errors='coerce')\n\novarian.age = pd.cut(ovarian.age, [0,50,75], labels = ['&lt;=50','&gt;50'])\n\novarian['resid.ds'] = ovarian['resid.ds'].map({1: \"NO\", 2: \"Yes\"})\novarian['rx'] = ovarian['rx'].map({1: \"A\", 2: \"B\"})\novarian['ecog.ps'] = ovarian['ecog.ps'].map({1: \"Good\", 2: \"Bad\"})\n\nIndex(['futime', 'fustat', 'age', 'resid.ds', 'rx', 'ecog.ps'], dtype='object')\n\n\n\n\n\n生存率的 Kaplan-Meier 估计的计算可以调用 lifelines 库中的 KaplanMeierFitter 函数实现。\npip 安装：pip install lifelines\nconda 安装： conda install lifelines\n拟合 fit :\n\nfrom lifelines import KaplanMeierFitter\nkmf = KaplanMeierFitter()\nfit = kmf.fit(ovarian.futime,ovarian.fustat)\nfit\n\n&lt;lifelines.KaplanMeierFitter:\"KM_estimate\", fitted with 26 total observations, 14 right-censored observations&gt;\n\n\n拟合结果 fit 包含了很多属性，我们可以通过点操作符单独提取其中的属性。例如，查看中位生存时间：\n\nfit.median_survival_time_\n\n638.0\n\n\n中位数生存时间表示，有 50% 的患者生存时间达到了 638 天。还可以提取寿命表和生存函数等属性，通过以下方式实现合并查看：\n\npd.concat([fit.event_table,fit.survival_function_], axis = 1)\n\n\n\n\n\n\n\n\nremoved\nobserved\ncensored\nentrance\nat_risk\nKM_estimate\n\n\n\n\n0.0\n0\n0\n0\n26\n26\n1.000000\n\n\n59.0\n1\n1\n0\n0\n26\n0.961538\n\n\n115.0\n1\n1\n0\n0\n25\n0.923077\n\n\n156.0\n1\n1\n0\n0\n24\n0.884615\n\n\n268.0\n1\n1\n0\n0\n23\n0.846154\n\n\n329.0\n1\n1\n0\n0\n22\n0.807692\n\n\n353.0\n1\n1\n0\n0\n21\n0.769231\n\n\n365.0\n1\n1\n0\n0\n20\n0.730769\n\n\n377.0\n1\n0\n1\n0\n19\n0.730769\n\n\n421.0\n1\n0\n1\n0\n18\n0.730769\n\n\n431.0\n1\n1\n0\n0\n17\n0.687783\n\n\n448.0\n1\n0\n1\n0\n16\n0.687783\n\n\n464.0\n1\n1\n0\n0\n15\n0.641931\n\n\n475.0\n1\n1\n0\n0\n14\n0.596078\n\n\n477.0\n1\n0\n1\n0\n13\n0.596078\n\n\n563.0\n1\n1\n0\n0\n12\n0.546405\n\n\n638.0\n1\n1\n0\n0\n11\n0.496732\n\n\n744.0\n1\n0\n1\n0\n10\n0.496732\n\n\n769.0\n1\n0\n1\n0\n9\n0.496732\n\n\n770.0\n1\n0\n1\n0\n8\n0.496732\n\n\n803.0\n1\n0\n1\n0\n7\n0.496732\n\n\n855.0\n1\n0\n1\n0\n6\n0.496732\n\n\n1040.0\n1\n0\n1\n0\n5\n0.496732\n\n\n1106.0\n1\n0\n1\n0\n4\n0.496732\n\n\n1129.0\n1\n0\n1\n0\n3\n0.496732\n\n\n1206.0\n1\n0\n1\n0\n2\n0.496732\n\n\n1227.0\n1\n0\n1\n0\n1\n0.496732\n\n\n\n\n\n\n\n\n\nKaplan-Meier 法估计的生存率是一个阶梯状的函数，其阶梯跳跃点是给定的时间点，我们可以通过调用 plot 方法绘制生存曲线，如图所示：\n\nimport matplotlib.pyplot as plt\nfit.plot(show_censors = True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n在生存分析中，经常需要比较不同情形下的生存率。在本例中，想要比较不同治疗方式下生存率，可以输入下面的命令：\n\ng1 = ovarian.rx == \"A\"\ng2 = ovarian.rx == \"B\"\nkmf_A = KaplanMeierFitter()\nkmf_A.fit(ovarian.futime[g1],ovarian.fustat[g1],label = \"Treatmeat A\")\nkmf_B = KaplanMeierFitter()\nkmf_B.fit(ovarian.futime[g2],ovarian.fustat[g2],label = \"Treatmeat B\")\n\n&lt;lifelines.KaplanMeierFitter:\"Treatmeat B\", fitted with 13 total observations, 8 right-censored observations&gt;\n\n\n\n\n可以单独提取两组的生存函数进行比较，但在同一个图中显示多条生存曲线更有助于生存率的比较。\n\nfig, axes = plt.subplots()\nkmf_A.plot(ax = axes,show_censors = True)\nkmf_B.plot(ax = axes,show_censors = True)\nplt.show()\n\n\n\n\n\n\n\n\n从上图中可以看出，治疗方式 “B” 的生存率高于治疗方式 “A” 的生存率，但是这种差异是由随机误差引起还是真是的治疗方式的不同所造成的差异，需要做进一步的统计学检验。\n\n\n\n因果关联的推断步骤\n\n\n\n\n\n生存分析中常用的统计学检验是 时序检验（log rank test），其基本思想是先计算出不同时间两种治疗方式的暴露人数和死亡人数，并由此在两种治疗方式效果相同的假设下计算出预期死亡人数，如果不拒绝零假设（ \\(H_0\\) ：两种治疗方式的效果相同，即预期死亡人数一致），则实际观测值和期望值的差异不会很大，如果差异过大则不能认为该差异是由随机误差引起的。\n对此，用 \\(\\chi^2\\) 检验做判断。时序检验可以用 lifetimes 库的函数 logrank_test 实现。\n\nfrom lifelines.statistics import logrank_test\nlr = logrank_test(ovarian.futime[g1], ovarian.futime[g2],\n                  ovarian.fustat[g1], ovarian.fustat[g2])\nlr.p_value\n\n0.3025911169890923\n\n\n这里得到的结果为 \\(P&gt;0.05\\) ，在一般情况下，我们会认为这是没有统计学意义的，即无法排除差异是由随机误差引起的。\n这种结果不显著的情况下，我们可以做一些思考，即是否有其他因素干预了结果的显著性，以及是否是样本量过小，导致差异不显著。（样本量的大小会影响检验效能，如果检验效能太低，即使有差异，也很难被检验方法发现）\n这里我们无法改变样本量的大小，但是可以考虑其他混杂因素的影响，并且使用更全面的模型进行检验。",
    "crumbs": [
      "Home",
      "统计软件使用指南",
      "Python",
      "用Python做生存分析和COX回归"
    ]
  },
  {
    "objectID": "Guide/Python/25-03-09-cos-reg.html#生存函数",
    "href": "Guide/Python/25-03-09-cos-reg.html#生存函数",
    "title": "用Python做生存分析和COX回归",
    "section": "",
    "text": "生存函数（survival function）是生存分析的基本概念之一，它是一个函数，用于刻画研究对象在某个时刻 t 内存存活的概率。 生存函数通常用 \\(S(t)\\) 表示。\n风险函数（hazard function）是生存分析的另一个基本概念，用于刻画研究对象在某个时刻 t 还存活但是极短的时间内死亡的风险。 风险函数通常用 \\(h(t)\\) 表示。\n如果记寿命分布的密度为 \\(f(t)\\)，则有： \\(h(t) = f(t) / S(t)\\) 。",
    "crumbs": [
      "Home",
      "统计软件使用指南",
      "Python",
      "用Python做生存分析和COX回归"
    ]
  },
  {
    "objectID": "Guide/Python/25-03-09-cos-reg.html#数据集及来源",
    "href": "Guide/Python/25-03-09-cos-reg.html#数据集及来源",
    "title": "用Python做生存分析和COX回归",
    "section": "",
    "text": "这里使用 R 语言 survival 包中的 ovarian 数据集，该数据集来自一项比较卵巢癌患者在两种治疗方式下的生存率比较的随机对照试验。\n首先找到 ovarian 数据集，你可以从互联网上寻找相关资源；或者从 R 的 survival 包中导出这一数据集，操作如下：\n# install.packages(\"survival\")\nlibrary(survival)\novarian\ndata(cancer, package=\"survival\")\n\ndf &lt;- ovarian\nwrite.csv(df, \"your-file-path\\\\ovarian.csv\", row.names = FALSE)\n将数据集下载到你的工作目录，然后使用 Pandas 导入与读取：\n\nimport pandas as pd\novarian = pd.read_csv(r\"C:\\Users\\asus\\Desktop\\R\\quarto\\Med-Stat-Notes\\Data\\ovarian.csv\")\novarian.head()\n\n\n\n\n\n\n\n\nfutime\nfustat\nage\nresid.ds\nrx\necog.ps\n\n\n\n\n0\n59\n1\n72.3315\n2\n1\n1\n\n\n1\n115\n1\n74.4932\n2\n1\n1\n\n\n2\n156\n1\n66.4658\n2\n1\n2\n\n\n3\n421\n0\n53.3644\n2\n2\n1\n\n\n4\n431\n1\n50.3397\n2\n1\n1\n\n\n\n\n\n\n\n数据集包括 26 个观测值，6 个变量。变量如下：futime（随访时间），fustat（研究结束时的状态：0 表示存活，1表示死亡），age（患者的年龄），resid.ds（疾病残留情况：1 表示有残留，2 表示没有残留），rx（治疗方式：1 表示环磷酰胺，2 表示环磷酰胺+阿霉素）和 ecog.ps（患者的 ECOG 评分：1 表示较好，2 表示较差）。\n对年龄进行分组，分为 &lt;50 和 &gt;50 两组，并将其他三个变量的各水平加上相应的标签。\n\n# 查看 ovarian(DataFrame)的变量名，因为不同的渠道下载的 Dataset 可能会有区别\nprint(ovarian.columns)\n\n# 将 age 列转换为数值类型\novarian['age'] = pd.to_numeric(ovarian['age'], errors='coerce')\n\novarian.age = pd.cut(ovarian.age, [0,50,75], labels = ['&lt;=50','&gt;50'])\n\novarian['resid.ds'] = ovarian['resid.ds'].map({1: \"NO\", 2: \"Yes\"})\novarian['rx'] = ovarian['rx'].map({1: \"A\", 2: \"B\"})\novarian['ecog.ps'] = ovarian['ecog.ps'].map({1: \"Good\", 2: \"Bad\"})\n\nIndex(['futime', 'fustat', 'age', 'resid.ds', 'rx', 'ecog.ps'], dtype='object')",
    "crumbs": [
      "Home",
      "统计软件使用指南",
      "Python",
      "用Python做生存分析和COX回归"
    ]
  },
  {
    "objectID": "Guide/Python/25-03-09-cos-reg.html#生存率的-kaplan-meier-估计",
    "href": "Guide/Python/25-03-09-cos-reg.html#生存率的-kaplan-meier-估计",
    "title": "用Python做生存分析和COX回归",
    "section": "",
    "text": "生存率的 Kaplan-Meier 估计的计算可以调用 lifelines 库中的 KaplanMeierFitter 函数实现。\npip 安装：pip install lifelines\nconda 安装： conda install lifelines\n拟合 fit :\n\nfrom lifelines import KaplanMeierFitter\nkmf = KaplanMeierFitter()\nfit = kmf.fit(ovarian.futime,ovarian.fustat)\nfit\n\n&lt;lifelines.KaplanMeierFitter:\"KM_estimate\", fitted with 26 total observations, 14 right-censored observations&gt;\n\n\n拟合结果 fit 包含了很多属性，我们可以通过点操作符单独提取其中的属性。例如，查看中位生存时间：\n\nfit.median_survival_time_\n\n638.0\n\n\n中位数生存时间表示，有 50% 的患者生存时间达到了 638 天。还可以提取寿命表和生存函数等属性，通过以下方式实现合并查看：\n\npd.concat([fit.event_table,fit.survival_function_], axis = 1)\n\n\n\n\n\n\n\n\nremoved\nobserved\ncensored\nentrance\nat_risk\nKM_estimate\n\n\n\n\n0.0\n0\n0\n0\n26\n26\n1.000000\n\n\n59.0\n1\n1\n0\n0\n26\n0.961538\n\n\n115.0\n1\n1\n0\n0\n25\n0.923077\n\n\n156.0\n1\n1\n0\n0\n24\n0.884615\n\n\n268.0\n1\n1\n0\n0\n23\n0.846154\n\n\n329.0\n1\n1\n0\n0\n22\n0.807692\n\n\n353.0\n1\n1\n0\n0\n21\n0.769231\n\n\n365.0\n1\n1\n0\n0\n20\n0.730769\n\n\n377.0\n1\n0\n1\n0\n19\n0.730769\n\n\n421.0\n1\n0\n1\n0\n18\n0.730769\n\n\n431.0\n1\n1\n0\n0\n17\n0.687783\n\n\n448.0\n1\n0\n1\n0\n16\n0.687783\n\n\n464.0\n1\n1\n0\n0\n15\n0.641931\n\n\n475.0\n1\n1\n0\n0\n14\n0.596078\n\n\n477.0\n1\n0\n1\n0\n13\n0.596078\n\n\n563.0\n1\n1\n0\n0\n12\n0.546405\n\n\n638.0\n1\n1\n0\n0\n11\n0.496732\n\n\n744.0\n1\n0\n1\n0\n10\n0.496732\n\n\n769.0\n1\n0\n1\n0\n9\n0.496732\n\n\n770.0\n1\n0\n1\n0\n8\n0.496732\n\n\n803.0\n1\n0\n1\n0\n7\n0.496732\n\n\n855.0\n1\n0\n1\n0\n6\n0.496732\n\n\n1040.0\n1\n0\n1\n0\n5\n0.496732\n\n\n1106.0\n1\n0\n1\n0\n4\n0.496732\n\n\n1129.0\n1\n0\n1\n0\n3\n0.496732\n\n\n1206.0\n1\n0\n1\n0\n2\n0.496732\n\n\n1227.0\n1\n0\n1\n0\n1\n0.496732\n\n\n\n\n\n\n\n\n\nKaplan-Meier 法估计的生存率是一个阶梯状的函数，其阶梯跳跃点是给定的时间点，我们可以通过调用 plot 方法绘制生存曲线，如图所示：\n\nimport matplotlib.pyplot as plt\nfit.plot(show_censors = True)\nplt.show()",
    "crumbs": [
      "Home",
      "统计软件使用指南",
      "Python",
      "用Python做生存分析和COX回归"
    ]
  },
  {
    "objectID": "Guide/Python/25-03-09-cos-reg.html#生存率的比较",
    "href": "Guide/Python/25-03-09-cos-reg.html#生存率的比较",
    "title": "用Python做生存分析和COX回归",
    "section": "",
    "text": "在生存分析中，经常需要比较不同情形下的生存率。在本例中，想要比较不同治疗方式下生存率，可以输入下面的命令：\n\ng1 = ovarian.rx == \"A\"\ng2 = ovarian.rx == \"B\"\nkmf_A = KaplanMeierFitter()\nkmf_A.fit(ovarian.futime[g1],ovarian.fustat[g1],label = \"Treatmeat A\")\nkmf_B = KaplanMeierFitter()\nkmf_B.fit(ovarian.futime[g2],ovarian.fustat[g2],label = \"Treatmeat B\")\n\n&lt;lifelines.KaplanMeierFitter:\"Treatmeat B\", fitted with 13 total observations, 8 right-censored observations&gt;\n\n\n\n\n可以单独提取两组的生存函数进行比较，但在同一个图中显示多条生存曲线更有助于生存率的比较。\n\nfig, axes = plt.subplots()\nkmf_A.plot(ax = axes,show_censors = True)\nkmf_B.plot(ax = axes,show_censors = True)\nplt.show()\n\n\n\n\n\n\n\n\n从上图中可以看出，治疗方式 “B” 的生存率高于治疗方式 “A” 的生存率，但是这种差异是由随机误差引起还是真是的治疗方式的不同所造成的差异，需要做进一步的统计学检验。\n\n\n\n因果关联的推断步骤\n\n\n\n\n\n生存分析中常用的统计学检验是 时序检验（log rank test），其基本思想是先计算出不同时间两种治疗方式的暴露人数和死亡人数，并由此在两种治疗方式效果相同的假设下计算出预期死亡人数，如果不拒绝零假设（ \\(H_0\\) ：两种治疗方式的效果相同，即预期死亡人数一致），则实际观测值和期望值的差异不会很大，如果差异过大则不能认为该差异是由随机误差引起的。\n对此，用 \\(\\chi^2\\) 检验做判断。时序检验可以用 lifetimes 库的函数 logrank_test 实现。\n\nfrom lifelines.statistics import logrank_test\nlr = logrank_test(ovarian.futime[g1], ovarian.futime[g2],\n                  ovarian.fustat[g1], ovarian.fustat[g2])\nlr.p_value\n\n0.3025911169890923\n\n\n这里得到的结果为 \\(P&gt;0.05\\) ，在一般情况下，我们会认为这是没有统计学意义的，即无法排除差异是由随机误差引起的。\n这种结果不显著的情况下，我们可以做一些思考，即是否有其他因素干预了结果的显著性，以及是否是样本量过小，导致差异不显著。（样本量的大小会影响检验效能，如果检验效能太低，即使有差异，也很难被检验方法发现）\n这里我们无法改变样本量的大小，但是可以考虑其他混杂因素的影响，并且使用更全面的模型进行检验。",
    "crumbs": [
      "Home",
      "统计软件使用指南",
      "Python",
      "用Python做生存分析和COX回归"
    ]
  },
  {
    "objectID": "Guide/Python/25-03-09-cos-reg.html#建立模型",
    "href": "Guide/Python/25-03-09-cos-reg.html#建立模型",
    "title": "用Python做生存分析和COX回归",
    "section": "2.1 建立模型",
    "text": "2.1 建立模型\n在建立模型前，需要对分类变量进行哑变量处理：\n\ndf_dummy = pd.get_dummies(ovarian,drop_first = True)\ndf_dummy.head()\n\n\n\n\n\n\n\n\nfutime\nfustat\nage_&gt;50\nresid.ds_Yes\nrx_B\necog.ps_Good\n\n\n\n\n0\n59\n1\nTrue\nTrue\nFalse\nTrue\n\n\n1\n115\n1\nTrue\nTrue\nFalse\nTrue\n\n\n2\n156\n1\nTrue\nTrue\nFalse\nFalse\n\n\n3\n421\n0\nTrue\nTrue\nTrue\nTrue\n\n\n4\n431\n1\nTrue\nTrue\nFalse\nTrue\n\n\n\n\n\n\n\n使用 drop_first = True 参数是为了去掉各个参考类别。\n下面将所有的协变量都纳入，建立 Cox 回归模型：\n\nfrom lifelines import CoxPHFitter\ncox = CoxPHFitter()\ncox.fit(df_dummy,duration_col = 'futime', event_col = 'fustat')\ncox.print_summary()\n\n\n\n\n\n\n\nmodel\nlifelines.CoxPHFitter\n\n\nduration col\n'futime'\n\n\nevent col\n'fustat'\n\n\nbaseline estimation\nbreslow\n\n\nnumber of observations\n26\n\n\nnumber of events observed\n12\n\n\npartial log-likelihood\n-28.89\n\n\ntime fit was run\n2025-03-10 05:46:54 UTC\n\n\n\n\n\n\n\n\n\ncoef\nexp(coef)\nse(coef)\ncoef lower 95%\ncoef upper 95%\nexp(coef) lower 95%\nexp(coef) upper 95%\ncmp to\nz\np\n-log2(p)\n\n\n\n\nage_&gt;50\n2.20\n9.04\n1.11\n0.03\n4.37\n1.03\n79.10\n0.00\n1.99\n0.05\n4.42\n\n\nresid.ds_Yes\n1.45\n4.25\n0.73\n0.02\n2.88\n1.02\n17.75\n0.00\n1.98\n0.05\n4.40\n\n\nrx_B\n-1.38\n0.25\n0.64\n-2.65\n-0.12\n0.07\n0.89\n0.00\n-2.14\n0.03\n4.96\n\n\necog.ps_Good\n-0.59\n0.56\n0.63\n-1.83\n0.65\n0.16\n1.92\n0.00\n-0.93\n0.35\n1.50\n\n\n\n\n\n\n\n\n\nConcordance\n0.79\n\n\nPartial AIC\n65.78\n\n\nlog-likelihood ratio test\n12.19 on 4 df\n\n\n-log2(p) of ll-ratio test\n5.97\n\n\n\n\n\n\n\n结果显示，在调整了协变量后，两种治疗方式的死亡风险的差异具有统计学意义（P&lt;0.05）。\n模型的回归系数及其置信区间可以通过 plot 方法进行直观展示：\n\ncox.plot()\n\n\n\n\n\n\n\n\nCox 回归是一种半参数回归模型，也像多元线性回归一样，存在变量选择的问题。通常可以用 AIC 进行变量选择。1\n查看当前模型的 AIC 值：\n\ncox.AIC_partial_\n\n65.77513405570859\n\n\n根据前序的结果，变量 ecog.ps 对应的 P 值最大，对其进行剔除后再次拟合模型：\n\ncox1 = CoxPHFitter()\ndf_dummy_sub = df_dummy.drop('ecog.ps_Good', axis = 1)\ncox1.fit(df_dummy_sub, duration_col = 'futime', event_col = 'fustat')\ncox1.print_summary()\ncox1.AIC_partial_\n\n\n\n\n\n\n\nmodel\nlifelines.CoxPHFitter\n\n\nduration col\n'futime'\n\n\nevent col\n'fustat'\n\n\nbaseline estimation\nbreslow\n\n\nnumber of observations\n26\n\n\nnumber of events observed\n12\n\n\npartial log-likelihood\n-29.33\n\n\ntime fit was run\n2025-03-10 05:46:54 UTC\n\n\n\n\n\n\n\n\n\ncoef\nexp(coef)\nse(coef)\ncoef lower 95%\ncoef upper 95%\nexp(coef) lower 95%\nexp(coef) upper 95%\ncmp to\nz\np\n-log2(p)\n\n\n\n\nage_&gt;50\n2.11\n8.29\n1.09\n-0.02\n4.25\n0.98\n70.32\n0.00\n1.94\n0.05\n4.25\n\n\nresid.ds_Yes\n1.25\n3.50\n0.69\n-0.10\n2.61\n0.90\n13.58\n0.00\n1.81\n0.07\n3.83\n\n\nrx_B\n-1.28\n0.28\n0.62\n-2.50\n-0.06\n0.08\n0.94\n0.00\n-2.06\n0.04\n4.67\n\n\n\n\n\n\n\n\n\nConcordance\n0.77\n\n\nPartial AIC\n64.66\n\n\nlog-likelihood ratio test\n11.31 on 3 df\n\n\n-log2(p) of ll-ratio test\n6.62\n\n\n\n\n\n\n\n64.65793573545281\n\n\n剔除 ecog_ps 后的模型， AIC 值有所下降，但是不多（谨慎对待），能认为新模型优于原有模型。",
    "crumbs": [
      "Home",
      "统计软件使用指南",
      "Python",
      "用Python做生存分析和COX回归"
    ]
  },
  {
    "objectID": "Guide/Python/25-03-09-cos-reg.html#footnotes",
    "href": "Guide/Python/25-03-09-cos-reg.html#footnotes",
    "title": "用Python做生存分析和COX回归",
    "section": "脚注",
    "text": "脚注\n\n\n赤池信息量准则，即Akaike information criterion，简称AIC，是衡量统计模型拟合优良性的一种标准，是由日本统计学家赤池弘次创立和发展的。赤池信息量准则建立在熵的概念基础上。\nAIC越小，模型越好，通常选择AIC最小的模型↩︎",
    "crumbs": [
      "Home",
      "统计软件使用指南",
      "Python",
      "用Python做生存分析和COX回归"
    ]
  },
  {
    "objectID": "Guide/Stata/Stata-intro.html",
    "href": "Guide/Stata/Stata-intro.html",
    "title": "Stata",
    "section": "",
    "text": "关于 Stata 大二上统计学课的时候，老师在课上提了一嘴，说：“等你们以后读研了，就不用 SPSS 这种工具了，就会开始用 Stata、R 这些工具了“。也确实，本科期间确实就是一个 SPSS 管了四年，因为实在脱离他的应用场景，加之，老师就只会 SPSS ，那就没办法咯。\n想起那时候，专业两个班的 SPSS 软件基本上都是我去装的，老师弄不会，同学们更不会，我比较喜欢摸索，所以摸索出了这些，找到了安装包和密钥，然后拷在 U盘 里，课前课后课中就是给他们装软件，有时候，有些系统还装不上，某为就是，同学的某为一直装不上，当时看是因为缺 Java 环境，但是装了 Java JDK 还是不行，遂放弃。\n等到毕业的时候，想着看能不能用 Stata 做一下毕业论文的数据分析，最后太忙，没时间也没精力，用了 SPSS 结束。\n老师也是到了我大四的时候在哪里自学 Stata ，不过要说的是，在 AI 成熟以前，没有 AI 的辅助情况下，从0开始去学一门技能或程序，没有捷径，耗时耗力。现在逐渐理解，因为自己当时抱着 Python 的几本书，看了两三年也没有啥进展，等到 AI 出来了，不懂的就问 AI，节省了很多时间和精力；也和理解力的提升有关，进展迅速。\n回归正题，Stata 是一款用于数据科学的统计软件，其功能强大，但是对比 Python、R、MATLAB等程序或软件，还是略显不足，但是对于一般情况的数据分析，Stata 是够用的，其主要的优点是语法简洁和有诸多可以拿来即用的包，同时作为一款商业软件，其价格相较于 SAS 是很低的（但是换算RMB仍然很高），其支持相较于 R 等也可以说是较为丰富的（庞大的社区），还有跨平台使用等优势，这里不一一列举。\nStata 的安装很简单，互联网上有很多教程，但是关键的一点是获得 Key (许可证和激活秘钥)，当然互联网亦有诸多的资源可供选择。\n然后根据研究目的，选择合适的模型，找到前人写的代码，拿来增删改查，AI 大法，跑通，分析。",
    "crumbs": [
      "Home",
      "统计软件",
      "Stata"
    ]
  },
  {
    "objectID": "Guide/Stata/25-03-11-ITSA.html",
    "href": "Guide/Stata/25-03-11-ITSA.html",
    "title": "Stata 做 ITSA 分析",
    "section": "",
    "text": "Interrupted Time Series Analysis (ITSA) 是一种常用的时间序列分析方法，用于评估某个干预措施对某个事件或趋势的影响。\n\n\nITSA 模型的基本形式如下：\n\\[\nY_t = \\beta_0 + \\beta_1 \\cdot T_t + \\beta_2 \\cdot X_t + \\beta_3 \\cdot T_t \\cdot X_t + \\epsilon_t\n\\]\n公式中各代码的含义分别为：\n\n\\(Y_t\\)：因变量，时间序列的观测值\n\\(T_t\\)：时间变量（序列），表示时间点 \\(t\\) 距离干预前的时间长度\n\\(X_t\\)：干预变量（哑变量），表示干预措施的状态，通常为 0 或 1\n\\(\\beta_0\\)：截距，即常数项\n\\(\\beta_1\\)：时间变量的系数，表示时间的趋势（改革前的变化趋势）\n\\(\\beta_2\\)：干预变量的系数，表示干预的效应\n\\(\\beta_3\\)：交互项系数，表示改革后与改革前斜率的差值，故改革后的斜率值为 \\(\\beta_1 + \\beta_3\\)\n\\(\\epsilon_t\\)：误差项\n\n\n\n\n这里使用 Stata 中的 nlswork 数据集，该数据集包含了 1987 年和 1988 年的 个体数据。 首先找到 nlswork 数据集，你可以从互联网上寻找相关资源；或者从 Stata 的 nlswork 包中导出这一数据集，操作如下：\nsysuse nlswork, clear\nsave \"your-file-path\\nlswork.dta\", replace\n\n\n\n\n\nssc install itsa\nssc install actest\n\n\n\n\n需要分析的变量很多，但是我们可以首先从次均住院费用开始，这是最直接的一组数据，根据 DIP政策 实施的时间点来划分时间段。\n这里是2018-2023年六年的费用数据，我们首先对其按年进行处理，得到一个费用均数，实际上大多数论文都是按照月份进行处理，这样更合理也更详细一些，这里也可以按月份来，但是需要重新清洗数据，还是按照年份先试一下。\n但是也有个问题就是，2022年开始DIP改革，数据只截止到2023，因此2022-2023无法进行回归，只能用截距代替一下（数据不稳定，谨慎对待）。\n操作代码如下：\nclear all\nuse \"C:\\Users\\asus\\ITSA\\ITSA-PRE.dta\", replace\n\n// 按年份聚合数据，取平均值\ncollapse (mean) Cost, by(year)\n\n// 设置时间变量\ntsset year\n\n// 定义时间变量和干预变量\ngen time = year - 2017\ngen DIP = (year &gt;= 2022) // 2022年及以后为1，之前为0\ngen time_post = (time - 5) * DIP // 干预后时间变量\n\n// 计算政策前的趋势（2018-2021）\nregress Cost time if year &lt;= 2021\nlocal beta0 = _b[_cons]\nlocal beta1 = _b[time]\n\n// 计算 2022 年的预测值\nlocal cost_2022_pred = `beta0' + `beta1' * 5\ngen Cost_pred_2022 = `cost_2022_pred' if year == 2022\n\n// 计算政策前趋势线（2018-2022）\ngenerate Cost_pred_2018_2022 = `beta0' + `beta1' * time if year &lt;= 2022\n\n// 计算 2022 和 2023 年的真实值\ngen cost_2022_actual = Cost if year == 2022\ngen cost_2023_actual = Cost if year == 2023\negen cost_2022_real = max(cost_2022_actual)\negen cost_2023_real = max(cost_2023_actual)\nlocal cost_2022_actual = cost_2022_real\nlocal cost_2023_actual = cost_2023_real\n\n// 计算政策后趋势斜率\nlocal beta_post_1 = (`cost_2023_actual' - `cost_2022_actual') / (6 - 5)\n\n// 计算政策后趋势线（从 2022 真实值开始）\ngenerate Cost_pred_post = `cost_2022_actual' + `beta_post_1' * (time - 5) if year &gt;= 2022\n\n// 显示关键信息\ndisplay \"政策前趋势 β1: `beta1'\"\ndisplay \"2022 预测值: `cost_2022_pred'\"\ndisplay \"2022 真实值: `cost_2022_actual'\"\ndisplay \"2023 真实值: `cost_2023_actual'\"\ndisplay \"政策后斜率 β_post_1: `beta_post_1'\"\n\n// 画图\ntwoway (scatter Cost year, msize(small)) /// 观察值\n       (line Cost_pred_2018_2022 year if year &lt;= 2022, lcolor(blue)) /// 政策前趋势\n       (line Cost_pred_post year if year &gt;= 2022, lcolor(red)) /// 政策后趋势\n       (scatter Cost_pred_2022 year if year == 2022, mcolor(green) msize(medium)) /// 2022预测值\n       (pcarrow Cost_pred_2022 year Cost year if year == 2022, lcolor(green) mcolor(green)), /// \n       xline(2022, lpattern(dash)) ///\n       title(\"Cost Time Series Analysis\") ///\n       subtitle(\"Intervention at 2022\") ///\n       xlabel(2018(1)2023) ///\n       legend(label(1 \"Observed\") label(2 \"Pre-intervention trend\") ///\n              label(3 \"Post-intervention trend\") label(4 \"2022 Prediction\") label(5 \"Level change at 2022\"))\n\n// 保存图形\ngraph save \"C:\\Users\\asus\\test\\cost_time_series_graph.gph\", replace\n\n// 计算回归系数表\nregress Cost time DIP time_post\noutreg2 using \"C:\\Users\\asus\\test\\itsa_results.doc\", replace word\n这里用\n\n2018年的数据作为起始数据（ITSA方程的截距，即 \\(\\beta_0\\) ）；\n2018-2021年的数据拟合政策前 次均费用 随时间变化的趋势，即 \\(\\beta_1\\) ；\n然后用 \\(\\beta_1\\) 计算2022年的预测值(\\(cost_{2022pred} = \\beta_0 +\\beta_1 * 5\\) )；\n2022年到2023年的数据直接使用真实值，得到政策后的趋势直线，如果数据足够多（≥3），则可以对政策后的数据进行回归得到 \\(\\beta_3\\)；\n使用2022年的真实值减去2022年的预测值，得到政策变化对 cost 造成的水平影响，即 \\(\\beta_2\\) 。\n\n\n\n\n上述代码运行后输出 中断时间序列分析 趋势图：\n\n\n\nITSA-TREND\n\n\n\n\n\n代码的最后，做回归系数表，得到如下结果：\n\n\n\n回归系数表\n\n\n\n政策前的时间趋势为：\\(\\beta_1=331.6185\\)；\n政策实施时的瞬时变化为：\\(\\beta_2=-219.9033\\);\n政策实施后的变化趋势为：\\(\\beta_3=-1628.044\\) 。\n\n其他变量也就可以按照此种模式进行一一计算，当然也可以用循环的模式计算，以后再论。",
    "crumbs": [
      "Home",
      "统计软件使用指南",
      "Stata",
      "Stata 做 ITSA 分析"
    ]
  },
  {
    "objectID": "Guide/Stata/25-03-11-ITSA.html#stsa-公式",
    "href": "Guide/Stata/25-03-11-ITSA.html#stsa-公式",
    "title": "Stata 做 ITSA 分析",
    "section": "",
    "text": "ITSA 模型的基本形式如下：\n\\[\nY_t = \\beta_0 + \\beta_1 \\cdot T_t + \\beta_2 \\cdot X_t + \\beta_3 \\cdot T_t \\cdot X_t + \\epsilon_t\n\\]\n公式中各代码的含义分别为：\n\n\\(Y_t\\)：因变量，时间序列的观测值\n\\(T_t\\)：时间变量（序列），表示时间点 \\(t\\) 距离干预前的时间长度\n\\(X_t\\)：干预变量（哑变量），表示干预措施的状态，通常为 0 或 1\n\\(\\beta_0\\)：截距，即常数项\n\\(\\beta_1\\)：时间变量的系数，表示时间的趋势（改革前的变化趋势）\n\\(\\beta_2\\)：干预变量的系数，表示干预的效应\n\\(\\beta_3\\)：交互项系数，表示改革后与改革前斜率的差值，故改革后的斜率值为 \\(\\beta_1 + \\beta_3\\)\n\\(\\epsilon_t\\)：误差项",
    "crumbs": [
      "Home",
      "统计软件使用指南",
      "Stata",
      "Stata 做 ITSA 分析"
    ]
  },
  {
    "objectID": "Guide/Stata/25-03-11-ITSA.html#数据集及来源",
    "href": "Guide/Stata/25-03-11-ITSA.html#数据集及来源",
    "title": "Stata 做 ITSA 分析",
    "section": "",
    "text": "这里使用 Stata 中的 nlswork 数据集，该数据集包含了 1987 年和 1988 年的 个体数据。 首先找到 nlswork 数据集，你可以从互联网上寻找相关资源；或者从 Stata 的 nlswork 包中导出这一数据集，操作如下：\nsysuse nlswork, clear\nsave \"your-file-path\\nlswork.dta\", replace",
    "crumbs": [
      "Home",
      "统计软件使用指南",
      "Stata",
      "Stata 做 ITSA 分析"
    ]
  },
  {
    "objectID": "Guide/Stata/25-03-11-ITSA.html#stata-准备",
    "href": "Guide/Stata/25-03-11-ITSA.html#stata-准备",
    "title": "Stata 做 ITSA 分析",
    "section": "",
    "text": "ssc install itsa\nssc install actest",
    "crumbs": [
      "Home",
      "统计软件使用指南",
      "Stata",
      "Stata 做 ITSA 分析"
    ]
  },
  {
    "objectID": "Guide/Stata/25-03-11-ITSA.html#对次均住院费用进行分析",
    "href": "Guide/Stata/25-03-11-ITSA.html#对次均住院费用进行分析",
    "title": "Stata 做 ITSA 分析",
    "section": "",
    "text": "需要分析的变量很多，但是我们可以首先从次均住院费用开始，这是最直接的一组数据，根据 DIP政策 实施的时间点来划分时间段。\n这里是2018-2023年六年的费用数据，我们首先对其按年进行处理，得到一个费用均数，实际上大多数论文都是按照月份进行处理，这样更合理也更详细一些，这里也可以按月份来，但是需要重新清洗数据，还是按照年份先试一下。\n但是也有个问题就是，2022年开始DIP改革，数据只截止到2023，因此2022-2023无法进行回归，只能用截距代替一下（数据不稳定，谨慎对待）。\n操作代码如下：\nclear all\nuse \"C:\\Users\\asus\\ITSA\\ITSA-PRE.dta\", replace\n\n// 按年份聚合数据，取平均值\ncollapse (mean) Cost, by(year)\n\n// 设置时间变量\ntsset year\n\n// 定义时间变量和干预变量\ngen time = year - 2017\ngen DIP = (year &gt;= 2022) // 2022年及以后为1，之前为0\ngen time_post = (time - 5) * DIP // 干预后时间变量\n\n// 计算政策前的趋势（2018-2021）\nregress Cost time if year &lt;= 2021\nlocal beta0 = _b[_cons]\nlocal beta1 = _b[time]\n\n// 计算 2022 年的预测值\nlocal cost_2022_pred = `beta0' + `beta1' * 5\ngen Cost_pred_2022 = `cost_2022_pred' if year == 2022\n\n// 计算政策前趋势线（2018-2022）\ngenerate Cost_pred_2018_2022 = `beta0' + `beta1' * time if year &lt;= 2022\n\n// 计算 2022 和 2023 年的真实值\ngen cost_2022_actual = Cost if year == 2022\ngen cost_2023_actual = Cost if year == 2023\negen cost_2022_real = max(cost_2022_actual)\negen cost_2023_real = max(cost_2023_actual)\nlocal cost_2022_actual = cost_2022_real\nlocal cost_2023_actual = cost_2023_real\n\n// 计算政策后趋势斜率\nlocal beta_post_1 = (`cost_2023_actual' - `cost_2022_actual') / (6 - 5)\n\n// 计算政策后趋势线（从 2022 真实值开始）\ngenerate Cost_pred_post = `cost_2022_actual' + `beta_post_1' * (time - 5) if year &gt;= 2022\n\n// 显示关键信息\ndisplay \"政策前趋势 β1: `beta1'\"\ndisplay \"2022 预测值: `cost_2022_pred'\"\ndisplay \"2022 真实值: `cost_2022_actual'\"\ndisplay \"2023 真实值: `cost_2023_actual'\"\ndisplay \"政策后斜率 β_post_1: `beta_post_1'\"\n\n// 画图\ntwoway (scatter Cost year, msize(small)) /// 观察值\n       (line Cost_pred_2018_2022 year if year &lt;= 2022, lcolor(blue)) /// 政策前趋势\n       (line Cost_pred_post year if year &gt;= 2022, lcolor(red)) /// 政策后趋势\n       (scatter Cost_pred_2022 year if year == 2022, mcolor(green) msize(medium)) /// 2022预测值\n       (pcarrow Cost_pred_2022 year Cost year if year == 2022, lcolor(green) mcolor(green)), /// \n       xline(2022, lpattern(dash)) ///\n       title(\"Cost Time Series Analysis\") ///\n       subtitle(\"Intervention at 2022\") ///\n       xlabel(2018(1)2023) ///\n       legend(label(1 \"Observed\") label(2 \"Pre-intervention trend\") ///\n              label(3 \"Post-intervention trend\") label(4 \"2022 Prediction\") label(5 \"Level change at 2022\"))\n\n// 保存图形\ngraph save \"C:\\Users\\asus\\test\\cost_time_series_graph.gph\", replace\n\n// 计算回归系数表\nregress Cost time DIP time_post\noutreg2 using \"C:\\Users\\asus\\test\\itsa_results.doc\", replace word\n这里用\n\n2018年的数据作为起始数据（ITSA方程的截距，即 \\(\\beta_0\\) ）；\n2018-2021年的数据拟合政策前 次均费用 随时间变化的趋势，即 \\(\\beta_1\\) ；\n然后用 \\(\\beta_1\\) 计算2022年的预测值(\\(cost_{2022pred} = \\beta_0 +\\beta_1 * 5\\) )；\n2022年到2023年的数据直接使用真实值，得到政策后的趋势直线，如果数据足够多（≥3），则可以对政策后的数据进行回归得到 \\(\\beta_3\\)；\n使用2022年的真实值减去2022年的预测值，得到政策变化对 cost 造成的水平影响，即 \\(\\beta_2\\) 。",
    "crumbs": [
      "Home",
      "统计软件使用指南",
      "Stata",
      "Stata 做 ITSA 分析"
    ]
  },
  {
    "objectID": "Guide/Stata/25-03-11-ITSA.html#绘制itsa趋势图",
    "href": "Guide/Stata/25-03-11-ITSA.html#绘制itsa趋势图",
    "title": "Stata 做 ITSA 分析",
    "section": "",
    "text": "上述代码运行后输出 中断时间序列分析 趋势图：\n\n\n\nITSA-TREND",
    "crumbs": [
      "Home",
      "统计软件使用指南",
      "Stata",
      "Stata 做 ITSA 分析"
    ]
  },
  {
    "objectID": "Guide/Stata/25-03-11-ITSA.html#输出统计结果",
    "href": "Guide/Stata/25-03-11-ITSA.html#输出统计结果",
    "title": "Stata 做 ITSA 分析",
    "section": "",
    "text": "代码的最后，做回归系数表，得到如下结果：\n\n\n\n回归系数表\n\n\n\n政策前的时间趋势为：\\(\\beta_1=331.6185\\)；\n政策实施时的瞬时变化为：\\(\\beta_2=-219.9033\\);\n政策实施后的变化趋势为：\\(\\beta_3=-1628.044\\) 。\n\n其他变量也就可以按照此种模式进行一一计算，当然也可以用循环的模式计算，以后再论。",
    "crumbs": [
      "Home",
      "统计软件使用指南",
      "Stata",
      "Stata 做 ITSA 分析"
    ]
  },
  {
    "objectID": "Guide/Python/25-03-14-Sankey-diagram.html",
    "href": "Guide/Python/25-03-14-Sankey-diagram.html",
    "title": "用Python做桑基图",
    "section": "",
    "text": "桑基图（Sankey diagram），即桑基能量分流图，也叫桑基能量平衡图。它是一种特定类型的流程图，概述图中延伸的分支的宽度对应数据流量的大小，通常应用于能源、材料成分、金融等数据的可视化分析。因1898年Matthew Henry Phineas Riall Sankey绘制的“蒸汽机的能源效率图”而闻名，此后便以其名字命名为“桑基图”。\nSankey diagrams are a data visualisation technique or flow diagram that emphasizes flow/movement/change from one state to another or one time to another, in which the width of the arrows is proportional to the flow rate of the depicted extensive property. The arrows being connected are called nodes and the connections are called links.\nSankey diagrams can also visualize the energy accounts, material flow accounts on a regional or national level, and cost breakdowns.The diagrams are often used in the visualization of material flow analysis.\nSankey diagrams emphasize the major transfers or flows within a system. They help locate the most important contributions to a flow. They often show conserved quantities within defined system boundaries.(Wikipedia contributors 2025)\n\n\n桑基图常用于可持续能源、物流、人口流动、资源分配等领域的数据可视化。它可以帮助用户直观地理解和分析复杂的流动和关系，从而支持决策和策划过程。\n\n\n\n\n节点：桑基图由一系列节点组成，每个节点代表一个特定的实体或类别。例如，节点可以代表不同的时间、地点和部门等。\n箭头：箭头表示流动的路径，从一个节点流向另一个节点。箭头的宽度通常表示流量或数量的大小。\n流量量级：桑基图可以显示不同节点之间的流量量级，通过箭头的宽度来表示。宽度越大，表示流量或数量越大。\n路径：桑基图可以显示多个节点之间的复杂路径，通过连接不同的节点和箭头来表示。\n颜色编码：桑基图可以使用颜色来编码不同的节点或流动路径，以帮助用户更好地理解和区分不同的实体或类别。\n\n\n\n\n在设计桑基图图表时，以下是一些需要注意的事项：\n\n数据准备：确保数据准备充分，包括节点和流量的数据。节点应该清晰明确，流量数据应该准确可靠。\n简洁明了：桑基图应该保持简洁明了，避免过多的节点和复杂的路径。过多的节点和路径可能会导致图表混乱不清晰，难以理解。\n良好的布局：选择合适的布局方式，使得节点和箭头的排列有一定的逻辑性。可以按照流动的方向或重要性进行布局。\n色彩选择：选择合适的色彩来区分不同的节点和流动路径。颜色应该鲜明对比，以便用户能够清晰地区分不同的实体或类别。\n箭头宽度控制：根据流量的大小，合理调整箭头的宽度。宽度应该能够直观地反映流量的差异，但也不能过于夸张。",
    "crumbs": [
      "Home",
      "统计软件使用历程",
      "Python",
      "用Python做桑基图"
    ]
  },
  {
    "objectID": "Guide/Python/25-03-14-Sankey-diagram.html#桑基图的主要应用场景",
    "href": "Guide/Python/25-03-14-Sankey-diagram.html#桑基图的主要应用场景",
    "title": "用Python做桑基图",
    "section": "",
    "text": "桑基图常用于可持续能源、物流、人口流动、资源分配等领域的数据可视化。它可以帮助用户直观地理解和分析复杂的流动和关系，从而支持决策和策划过程。",
    "crumbs": [
      "Home",
      "统计软件使用历程",
      "Python",
      "用Python做桑基图"
    ]
  },
  {
    "objectID": "Guide/Python/25-03-14-Sankey-diagram.html#桑基图的特点",
    "href": "Guide/Python/25-03-14-Sankey-diagram.html#桑基图的特点",
    "title": "用Python做桑基图",
    "section": "",
    "text": "节点：桑基图由一系列节点组成，每个节点代表一个特定的实体或类别。例如，节点可以代表不同的时间、地点和部门等。\n箭头：箭头表示流动的路径，从一个节点流向另一个节点。箭头的宽度通常表示流量或数量的大小。\n流量量级：桑基图可以显示不同节点之间的流量量级，通过箭头的宽度来表示。宽度越大，表示流量或数量越大。\n路径：桑基图可以显示多个节点之间的复杂路径，通过连接不同的节点和箭头来表示。\n颜色编码：桑基图可以使用颜色来编码不同的节点或流动路径，以帮助用户更好地理解和区分不同的实体或类别。",
    "crumbs": [
      "Home",
      "统计软件使用历程",
      "Python",
      "用Python做桑基图"
    ]
  },
  {
    "objectID": "Guide/Python/25-03-14-Sankey-diagram.html#设计的注意事项",
    "href": "Guide/Python/25-03-14-Sankey-diagram.html#设计的注意事项",
    "title": "用Python做桑基图",
    "section": "",
    "text": "在设计桑基图图表时，以下是一些需要注意的事项：\n\n数据准备：确保数据准备充分，包括节点和流量的数据。节点应该清晰明确，流量数据应该准确可靠。\n简洁明了：桑基图应该保持简洁明了，避免过多的节点和复杂的路径。过多的节点和路径可能会导致图表混乱不清晰，难以理解。\n良好的布局：选择合适的布局方式，使得节点和箭头的排列有一定的逻辑性。可以按照流动的方向或重要性进行布局。\n色彩选择：选择合适的色彩来区分不同的节点和流动路径。颜色应该鲜明对比，以便用户能够清晰地区分不同的实体或类别。\n箭头宽度控制：根据流量的大小，合理调整箭头的宽度。宽度应该能够直观地反映流量的差异，但也不能过于夸张。",
    "crumbs": [
      "Home",
      "统计软件使用历程",
      "Python",
      "用Python做桑基图"
    ]
  },
  {
    "objectID": "Guide/Python/25-03-14-Sankey-diagram.html#本地python",
    "href": "Guide/Python/25-03-14-Sankey-diagram.html#本地python",
    "title": "用Python做桑基图",
    "section": "2.1 本地Python",
    "text": "2.1 本地Python\n安装相关的包和库：\n\npip install dash\npip install numpy\n\n\n2.1.1 本地运行示例\n在 Python 终端或编辑器运行后，可以在浏览器中输入 http://127.0.0.1:8051/ 进行查看。\n\n# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Fri Mar 14 17:07:53 2025\n\n@author: asus\n\"\"\"\n\nimport dash\nfrom dash import html, dcc, Input, Output\nimport plotly.graph_objects as go\nimport dash_bootstrap_components as dbc\nimport numpy as np\nimport plotly.express as px\n \n \ndef create_complex_sankey():\n    # 示例数据\n    labels = [\"能源\", \"电力\", \"运输\", \"工业\", \"住宅\", \"商业\", \"损失\", \"可再生\", \"化石燃料\", \"核能\"]\n    sources = [0, 0, 0, 1, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6]\n    targets = [1, 2, 3, 4, 5, 6, 4, 5, 6, 7, 7, 8, 8, 9, 9, 7]\n    values = [8, 4, 2, 8, 4, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1]\n \n    # 创建桑基图\n    sankey_fig = go.Figure(data=[go.Sankey(\n        node=dict(\n            pad=15,\n            thickness=20,\n            line=dict(color=\"black\", width=0.5),\n            label=labels,\n            color=[\"#FF9999\", \"#66B3FF\", \"#99FF99\", \"#FFCC99\", \"#FF6666\", \"#66FF66\", \"#6666FF\", \"#FF66FF\", \"#66FFFF\", \"#FFFF66\"]\n        ),\n        link=dict(\n            source=sources,\n            target=targets,\n            value=values,\n            color=[\"rgba(255, 153, 153, 0.6)\", \"rgba(102, 179, 255, 0.6)\", \"rgba(153, 255, 153, 0.6)\", \"rgba(255, 204, 153, 0.6)\",\n                   \"rgba(255, 102, 102, 0.6)\", \"rgba(102, 255, 102, 0.6)\", \"rgba(102, 102, 255, 0.6)\", \"rgba(255, 102, 255, 0.6)\",\n                   \"rgba(102, 255, 255, 0.6)\", \"rgba(255, 255, 102, 0.6)\", \"rgba(255, 153, 153, 0.6)\", \"rgba(102, 179, 255, 0.6)\",\n                   \"rgba(153, 255, 153, 0.6)\", \"rgba(255, 204, 153, 0.6)\", \"rgba(255, 102, 102, 0.6)\", \"rgba(102, 255, 102, 0.6)\"]\n        )\n    )])\n \n    # 更新布局\n    sankey_fig.update_layout(\n        title='复杂桑基图示例',\n        font_size=10,\n        template='plotly_white'\n    )\n \n    return sankey_fig\n \napp = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n \napp.layout = html.Div([\n    html.H3(\"桑基图展示\", className=\"text-center mt-4 mb-3\"),\n    dcc.Graph(figure=create_complex_sankey())\n])\n \nif __name__ == \"__main__\":\n    app.run_server(debug=True, port=8051)",
    "crumbs": [
      "Home",
      "统计软件使用历程",
      "Python",
      "用Python做桑基图"
    ]
  },
  {
    "objectID": "Guide/Python/25-03-14-Sankey-diagram.html#jupyter-实现",
    "href": "Guide/Python/25-03-14-Sankey-diagram.html#jupyter-实现",
    "title": "用Python做桑基图",
    "section": "2.2 Jupyter 实现",
    "text": "2.2 Jupyter 实现\n为了能在本网页中显示桑基图，需要在 jupyter 中运行该程序，那么除了相关的 jupyter 包需要被安装外，需要更换 dash 包为 jupyter-dash 。\n\n2.2.1 安装 jupyter-dash\n\npip install jupyter-dash\n\n\n\n2.2.2 运行程序\n\n# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Fri Mar 14 17:07:53 2025\n\n@author: asus\n\"\"\"\n\nfrom jupyter_dash import JupyterDash  # 替换 dash\nfrom dash import html, dcc, Input, Output\nimport plotly.graph_objects as go\nimport dash_bootstrap_components as dbc\nimport numpy as np\nimport plotly.express as px\n\ndef create_complex_sankey():\n    labels = [\"能源\", \"电力\", \"运输\", \"工业\", \"住宅\", \"商业\", \"损失\", \"可再生\", \"化石燃料\", \"核能\"]\n    sources = [0, 0, 0, 1, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6]\n    targets = [1, 2, 3, 4, 5, 6, 4, 5, 6, 7, 7, 8, 8, 9, 9, 7]\n    values = [8, 4, 2, 8, 4, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1]\n\n    sankey_fig = go.Figure(data=[go.Sankey(\n        node=dict(\n            pad=15,\n            thickness=20,\n            line=dict(color=\"black\", width=0.5),\n            label=labels,\n            color=[\"#FF9999\", \"#66B3FF\", \"#99FF99\", \"#FFCC99\", \"#FF6666\", \"#66FF66\", \"#6666FF\", \"#FF66FF\", \"#66FFFF\", \"#FFFF66\"]\n        ),\n        link=dict(\n            source=sources,\n            target=targets,\n            value=values,\n            color=[\"rgba(255, 153, 153, 0.6)\", \"rgba(102, 179, 255, 0.6)\", \"rgba(153, 255, 153, 0.6)\", \"rgba(255, 204, 153, 0.6)\",\n                   \"rgba(255, 102, 102, 0.6)\", \"rgba(102, 255, 102, 0.6)\", \"rgba(102, 102, 255, 0.6)\", \"rgba(255, 102, 255, 0.6)\",\n                   \"rgba(102, 255, 255, 0.6)\", \"rgba(255, 255, 102, 0.6)\", \"rgba(255, 153, 153, 0.6)\", \"rgba(102, 179, 255, 0.6)\",\n                   \"rgba(153, 255, 153, 0.6)\", \"rgba(255, 204, 153, 0.6)\", \"rgba(255, 102, 102, 0.6)\", \"rgba(102, 255, 102, 0.6)\"]\n        )\n    )])\n\n    sankey_fig.update_layout(\n        title='复杂桑基图示例',\n        font_size=10,\n        template='plotly_white'\n    )\n\n    return sankey_fig\n\n# 使用 JupyterDash 替代 Dash\napp = JupyterDash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n\napp.layout = html.Div([\n    html.H3(\"桑基图展示\", className=\"text-center mt-4 mb-3\"),\n    dcc.Graph(figure=create_complex_sankey())\n])\n\n# 在 Jupyter 中运行，mode='inline' 将图形嵌入笔记本\napp.run_server(mode='inline')\n\n\n        \n        \n\n\n\n        \n        \n\n\n\n\n2.2.3 网页无法正确显示\n因为 GitHub 只支持静态网页，但是 桑基图 是一个通过 Flask 生成的动态 Web 应用，因为当本地生成后托管到 GitHub 后，是无法正确显示该图形。\n解决办法：\n\n将网页托管到支持动态图像的服务器上，如 Render 等\n改用静态图形\n\n\nimport plotly.graph_objects as go\n\ndef create_complex_sankey():\n    labels = [\"能源\", \"电力\", \"运输\", \"工业\", \"住宅\", \"商业\", \"损失\", \"可再生\", \"化石燃料\", \"核能\"]\n    sources = [0, 0, 0, 1, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6]\n    targets = [1, 2, 3, 4, 5, 6, 4, 5, 6, 7, 7, 8, 8, 9, 9, 7]\n    values = [8, 4, 2, 8, 4, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1]\n    sankey_fig = go.Figure(data=[go.Sankey(\n        node=dict(pad=15, thickness=20, line=dict(color=\"black\", width=0.5), label=labels),\n        link=dict(source=sources, target=targets, value=values)\n    )])\n    sankey_fig.update_layout(title='复杂桑基图示例', font_size=10, template='plotly_white')\n    return sankey_fig\n\n# 保存为静态 HTML 文件\nfig = create_complex_sankey()\nfig.write_html(\"sankey.html\", include_plotlyjs='cdn')",
    "crumbs": [
      "Home",
      "统计软件使用历程",
      "Python",
      "用Python做桑基图"
    ]
  },
  {
    "objectID": "Learn/Basic/10-regression-correlation.html#假设检验",
    "href": "Learn/Basic/10-regression-correlation.html#假设检验",
    "title": "简单线性相关和回归",
    "section": "\n2.1 假设检验",
    "text": "2.1 假设检验\n\n2.1.1 F检验\n\\(y_i\\)的总离均差平方和为：\n\\[SS_{yy}=\\sum_{i}(y_i-\\bar y)^2\\] 对其做分解，得到等式：\n\\[SS_{yy}=\\sum_{i}^{n}(\\hat y_i-\\bar y)^2+\\sum_{i}^{n}(y_i-\\hat y_i)^2\\] \\(\\sum_{i}^{n}(\\hat y_i-\\bar y)^2\\)为回归平方和（regression sum of squares），记为\\(SS_R\\)，表示回归估计值\\(\\hat y_i\\)与均数\\(\\bar y\\)的离差平方和，其公式为：\n\\[\n\\begin{align}\nSS_{yy} &= \\sum_{i=1}^{n}(\\hat y_i - \\bar y)^2 \\\\\n        &= \\sum_{i=1}^{n}[a + bx_i - (a + b\\bar x)]^2 \\\\\n        &= SS_{xx}b^2 \\\\\n        &= SS_{xy}b\n\\end{align}\n\\] 显然，回归平方和\\(SS_{R}\\)反映的是在y的总变异中由x与y的直线回归关系解释的那部分变异。\\(SS_R\\)值越大，说明回归直线的拟合效果就越好。\n\\(\\sum_{i}^{n}(y_i-\\hat y_i)^2\\)为残差平方和（residual sum of squares），记为\\(SS_E\\)，表示观测值\\(y_i\\)与回归估计值\\(\\hat y_i\\)的离差平方和，其公式为： \\[SS_E=\\sum_{i=1}^{n}(y_i-\\hat y_i)^2\\] \\(SS_E\\)反映了在总变异中扣除自变量x对因变量y的线性影响以后的其他因素（包括x对y的非线性影响和随机误差等）对y变异的影响，也就是在总平方和中无法用y和x线性回归关系解释的部分。\\(SS_E\\)值越小，说明回归直线的拟合效果就越好。\n对公式进行简化： \\[\\begin{align}\nSS_{yy}=&\\sum_{i}^{n}(\\hat y_i-\\bar y)^2+\\sum_{i}^{n}(y_i-\\hat y_i)^2\\\\\n=&SS_R+SS_E\n\\end{align}\\] 上述三个平方和，各有其相应的自由度\\(v\\)，并有如下关系： \\[v_{yy}=v_R+v_E\\\\\nv_{yy}=n-1,v_R=1,v_E=n-2\\]\n在\\(H_0\\)成立的条件下，有： \\[\\frac{SS_R}{\\sigma^2}\\sim \\chi^2(v_R),\\frac{SS_E}{\\sigma^2}\\sim \\chi^2(v_E)\\] 且\\(SS_R\\)和\\(SS_E\\)相互独立。\n检验统计量：\n\\[F=\\frac{SS_R/v_R}{SS_E/v_E}\\] 服从自由度\\(v_R=1,v_E=n-2\\)的F分布。如果y和x确实存在直线回归关系，那么回归所解释的变异\\(SS_R\\)应大于其他因素所解释的变异\\(SS_E\\)。由此可见，F检验正是建立在这个基础上的。\n对于给定的检验水准\\(\\alpha\\)， 如果\\(F&gt;F_{(v_R,v_E),1-\\alpha}\\)，则拒绝\\(H_0\\)，认为直线回归方程有统计学显著性；\n如果\\(F\\leq F_{(v_R,v_E),1-\\alpha}\\)，则不拒绝\\(H_0\\)，尚不能认为直线回归方程有统计学显著性。\n\n2.1.2 t检验法\n回归直线方程的稳定性程度取决于 \\(b\\) 的波动大小，即 \\(S_b\\) 的大小，这里的 \\(S_b\\) 为样本回归系数 \\(b\\) 的标准误的估计值。由于统计量 \\(b\\) 来自正态总体，故可从 \\(b\\) 的抽样分布出发构造 \\(t\\) 统计量对其进行假设检验。\n当 \\(H_0\\) ：\\(\\beta = 0\\) 成立时，检验统计量服从自由度 \\(v_E=n-2\\) 的 \\(t\\) 分布。\n\\[\nt=\\frac{b-0}{S_b}\\sim t(v_E)\n\\]\n其中：\n\\[\nS_b=\\frac{S_{yx}}{\\sqrt{SS_{xx}}}=\\sqrt{\\frac{S_{yx}/(n-2)}{SS_{xx}}}\n\\]\n\\(S_{yx}=\\sqrt{SS_E/(n-2)}\\) 为剩余标准差（residual standard deviation），是指扣除 \\(x\\) 对 \\(y\\) 的线性影响后，衡量观测值 \\(y\\) 对回归直线的平均离散程度，即回归直线 \\(\\hat y\\) 估计的精度。",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "简单线性相关和回归"
    ]
  },
  {
    "objectID": "Learn/Basic/10-regression-correlation.html#直线回归方程的区间估计",
    "href": "Learn/Basic/10-regression-correlation.html#直线回归方程的区间估计",
    "title": "简单线性相关和回归",
    "section": "\n2.2 直线回归方程的区间估计",
    "text": "2.2 直线回归方程的区间估计\n\n2.2.1 总体回归系数的置信区间\n\\[\nt = \\frac{b-\\beta}{S_b}\\sim t(v_E)\n\\]",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "简单线性相关和回归"
    ]
  },
  {
    "objectID": "Learn/Basic/10-regression-correlation.html#数学定义",
    "href": "Learn/Basic/10-regression-correlation.html#数学定义",
    "title": "简单线性相关和回归",
    "section": "\n3.1 数学定义",
    "text": "3.1 数学定义\n均值向量：对于双元正态变量 \\((X, Y)\\)，均值向量为：\n\\[\\mu = \\begin{pmatrix}\n\\mu_X \\\\\n\\mu_Y\n\\end{pmatrix}\\]\n其中 \\(\\mu_X\\) 和 \\(\\mu_Y\\) 分别是随机变量 \\(X\\) 和 \\(Y\\) 的均值。 2. 协方差矩阵：协方差矩阵为：\n\\[\\Sigma = \\begin{pmatrix}\n\\sigma_X^2 & \\sigma_{XY} \\\\\n\\sigma_{XY} & \\sigma_Y^2\n\\end{pmatrix}\\]\n其中 \\(\\sigma_X^2\\) 和 \\(\\sigma_Y^2\\) 是 \\(X\\) 和 \\(Y\\) 的方差，\\(\\sigma_{XY}\\) 是它们之间的协方差。",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "简单线性相关和回归"
    ]
  },
  {
    "objectID": "Learn/Basic/10-regression-correlation.html#性质",
    "href": "Learn/Basic/10-regression-correlation.html#性质",
    "title": "简单线性相关和回归",
    "section": "\n3.2 性质",
    "text": "3.2 性质\n\n边缘分布：\\(X\\) 和 \\(Y\\) 的边缘分布也是正态分布。\n条件分布：给定 \\(X\\) 的值，\\(Y\\) 的条件分布也是正态分布。\n相关性：协方差矩阵的值可以用来判断 X 和 Y 之间的相关性。如果 \\(\\sigma_{XY} &gt; 0\\)，则两者正相关；如果 \\(\\sigma_{XY} &lt; 0\\)，则负相关。",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "简单线性相关和回归"
    ]
  },
  {
    "objectID": "Learn/Basic/10-regression-correlation.html#示例",
    "href": "Learn/Basic/10-regression-correlation.html#示例",
    "title": "简单线性相关和回归",
    "section": "\n3.3 示例",
    "text": "3.3 示例\n假设有一组数据描述学生的身高 \\(X\\) 和体重 \\(Y\\)，并且假设 \\((X, Y)\\) 服从双元正态分布：\n\n3.3.1 均值向量：\n\\[\\mu = \\begin{pmatrix}\n170 \\\\\n65\n\\end{pmatrix}\\]\n表示身高的均值为 170 厘米，体重的均值为 65 千克。 •\n\n3.3.2 协方差矩阵：\n\\[\\Sigma = \\begin{pmatrix}\n100 & 20 \\\\\n20 & 25\n\\end{pmatrix}\\]\n这里，身高的方差为 100，体重的方差为 25，协方差为 20，表示身高和体重之间存在正相关关系。\n在这个示例中，如果我们知道某个学生的身高为 180 厘米，我们可以利用条件分布来预测他的体重，这个体重的预测值也是正态分布。\n我们用一个图形来展示：\n\n## 安装和加载所需的包\n#install.packages(\"plotly\")\n#install.packages(\"mvtnorm\")\nlibrary(plotly)\nlibrary(mvtnorm)\nlibrary(webshot2)\n\n# 创建网格数据\nx &lt;- seq(150, 190, length.out = 100)\n#身高150-190，等距的100个值\ny &lt;- seq(50, 80, length.out = 100)\n#体重50-80，等距的100个值\ngrid &lt;- expand.grid(X = x, Y = y)\n#生成 x 和 y 的所有组合，用于构建一个网格数据框，以便计算多元正态分布的概率密度。\n\n# 设置均值和协方差矩阵\nmu &lt;- c(170, 65)\n#设置双元正态分布的均值向量，表示均值分别为身高 170 cm 和体重 65 kg\n\nsigma &lt;- matrix(c(100, 20, 20, 25), nrow = 2)\n#设置协方差矩阵，表示身高的方差为 100，体重的方差为 25，身高和体重之间的协方差为 20\n\n# 计算概率密度\nz &lt;- dmvnorm(as.matrix(grid), mean = mu, sigma = sigma)\n#计算每个网格点上双元正态分布的概率密度。\n\n# 将概率密度矩阵转换为适合绘图的形状\nz_matrix &lt;- matrix(z, nrow = 100, ncol = 100)\n\n# 绘制三维表面图\nplot_ly(x = x, y = y, z = z_matrix, type = \"surface\") %&gt;%\n  layout(title = list(text = \"双元正态分布的三维概率密度图\", y=0.95),\n         scene = list(xaxis = list(title = \"身高 (cm)\"),\n                      yaxis = list(title = \"体重 (kg)\"),\n                      zaxis = list(title = \"概率密度\")))\n\n\nBinary normal distribution\n\n\n注：上述图像在被转换为PDF文件时，会发生报错：Quarto 文档中包含了一些生成 HTML 输出的函数（比如交互式图表或其他 HTML 小部件），但你当前的目标输出格式是 PDF。由于 PDF 是静态格式，无法直接渲染 HTML 内容，Quarto 会报错并停止执行。\n解决方案，此章节不转换为PDF格式，或者：\n如果你仍想输出 PDF，但希望将 HTML 小部件作为静态截图嵌入，可以安装 R 的 webshot 或 webshot2 包。Quarto 会利用它们将 HTML 内容转换为图片。\n需要安装：\n\ninstall.packages(\"webshot2\")\n\n然后在这段程序的前部导入该包：library(webshot2)。\nend.",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "简单线性相关和回归"
    ]
  },
  {
    "objectID": "Learn/Basic/10-non-parameter-test.html",
    "href": "Learn/Basic/10-non-parameter-test.html",
    "title": "非参数检验",
    "section": "",
    "text": "秩和检验（Rank-Sum Test）是一种非参数检验方法，用于比较两个独立样本的分布是否存在显著差异。它无需对数据分布作正态性假设，适用于数据偏离正态分布、样本量较小或数据为序数型变量的场景。\n常见的秩和检验包括：\n\nMann-Whitney U 检验（也称Wilcoxon秩和检验）：用于比较两个独立样本的中位数是否相等。\nWilcoxon 符号秩检验：用于两个配对样本的比较（类似配对t检验，但无需正态性假设）。\n\n\n\n\nMann-Whitney U 检验公式\n\n假设两组独立样本分别为 \\(X\\) 和 \\(Y\\)，样本量分别为 \\(n_1\\) 和 \\(n_2\\)。\n对两组样本合并并按大小排序，赋予秩次。计算两组的秩次和 \\(R_1\\) 和 \\(R_2\\)（分别为 $ X$ 和 \\(Y\\) 的秩次总和）。\n\n确定统计量T值：\n\n假设两组样本量 \\(n_1&lt;n_2\\)，一般情况下以样本量较小者\\(n_1\\)对应的秩和\\(T_1\\)为检验统计量\\(T\\)，当样本相等时可以选择任一组的秩和为\\(T\\)。1\n当两组中样本量较小者不低于10时，在\\(H_0\\)成立假设下，统计量\\(T\\)的抽样分布近似于正态分布，有\n\\[T\\approx N\\left(\\frac{n_1(n+1)}{2},\\frac{n_1 n_2(n+1)}{12} \\right)\\] 此时，Wilcoxon 秩和统计量在\\(H_0\\)下关于\\(\\mu=\\frac{n_1(n+1)}{2}\\)对称。\n如果没有或存在较少的“结”，将\\(T\\)标准化后为：\n\\[U=\\frac{T-\\frac{n_1(n+1)}{2}+C}{\\sqrt{\\frac{n_1 n_2(n+1)}{12}}}\\approx N(0,1)\\]\n其中，C为连续性校正系数，当\\(T&gt;\\frac{n(n+1)}{4}\\)时，\\(C=-0.5\\)，当\\(T&lt;\\frac{n(n+1)}{4}\\)时，\\(C=0.5\\)，当\\(T=\\frac{n(n+1)}{4}\\)时，\\(C=0\\)。\n若“结”的比例较多（&gt;25%），则用以下公式校正：\n\\[U_c=\\frac{T-\\frac{n_1(n+1)}{2}+C}{\\sqrt{\\frac{n_1 n_2}{12}[(n+1)-\\sum_\\limits{i=1}^{g}\\frac{t_i^3-t_i}{n(n-1)}]}}\\approx N(0,1)\\]\n\nWilcoxon 符号秩检验公式\n\n对配对样本 \\((X_i, Y_i)\\)，计算差值 \\(D_i = X_i - Y_i\\)，取非零差值的绝对值并排序（若差值为0则舍去不计，且减去相应的个数），赋予秩次 \\(R_i\\)。再根据差值的符号计算符号秩次和 \\(W\\)：\n\\[W = \\sum R_i \\cdot \\text{sign}(D_i)\\]\n检验统计量 \\(T\\) 是 \\(W\\) 的绝对值，依据表或正态分布计算显著性。\n正态近似法：\n当\\(n\\ge 30\\)时，有中心极限定理可知，当\\(H_0\\)成立时统计量\\(T\\)的抽样分布近似正态分布，有\n\\[T\\approx N \\left(\\frac{n(n+1)}{4},\\frac{n(n+1)(2n+1)}{24}\\right)\\] 其中，均数\\(\\mu=\\frac{n(n+1)}{4}\\)，方差\\(\\sigma^2=\\frac{n(n+1)(2n+1)}{24}\\)。 将T标准化后，近似服从标准正态分布，有\n\\[U=\\frac{T-\\frac{n(n+1)}{4}+C}{\\sqrt{\\frac{n(n+1)(2n+1)}{24}}}\\approx N(0,1)\\] 其中，n是差值不为0的对子数，C为连续性校正系数，当\\(T&gt;\\frac{n(n+1)}{4}\\)时，\\(C=-0.5\\)，当\\(T&lt;\\frac{n(n+1)}{4}\\)时，\\(C=0.5\\)，当\\(T=\\frac{n(n+1)}{4}\\)时，\\(C=0\\)。\n当N较大时，样本中可能存在较多的“结”，（如“结”所占比例大于25%），此时需要使用校正公式：\n\\[U=\\frac{T-\\frac{n(n+1)}{4}+C}{\\sqrt{\\frac{n(n+1)(2n+1)}{24}-\\frac{\\sum_\\limits{i=1}^g(t_i^3-t_i)}{48}}}\\approx N(0,1)\\] 其中，\\(t_i\\)为\\(i\\)个“结”中有相同秩次的个数，\\(g\\)是“结”的个数。\nWilcoxon符号秩检验的前提条件为数据是连续的且差值分布是对称的。\nnotice：秩和秩和的区别：秩是指全部观察值按某种顺序排列的位序，在一定程度上反映了等级的高低；而秩和则表示同组秩次之和，在一定程度上反映了等级的分布。2\n\n\n\n\nMann-Whitney U 检验：\n\n比较两个独立样本的中位数是否存在显著差异。\n\n适用于非正态分布数据或含有极端值的样本。\n\n示例：比较两种治疗方法的疗效（不同受试者组）。\n\nWilcoxon 符号秩检验：\n\n比较两个配对样本的中位数差异。\n\n适用于重复测量数据或实验设计中存在配对关系的场景。\n\n示例：同一批受试者在治疗前后血压的变化。\n\n\n\n\n\n\n秩和检验是非参数方法，对数据分布假设少，但效率可能低于参数方法（如t检验）在满足条件时的效果，如果满足参数检验的条件，应优先考虑使用参数检验的方法，否则会增加犯二类错误的概率。\n数据需要满足独立性假设，否则检验结果可能不准确。\n\nend.",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "非参数检验"
    ]
  },
  {
    "objectID": "Learn/Basic/10-non-parameter-test.html#秩和检验",
    "href": "Learn/Basic/10-non-parameter-test.html#秩和检验",
    "title": "非参数检验",
    "section": "",
    "text": "秩和检验（Rank-Sum Test）是一种非参数检验方法，用于比较两个独立样本的分布是否存在显著差异。它无需对数据分布作正态性假设，适用于数据偏离正态分布、样本量较小或数据为序数型变量的场景。\n常见的秩和检验包括：\n\nMann-Whitney U 检验（也称Wilcoxon秩和检验）：用于比较两个独立样本的中位数是否相等。\nWilcoxon 符号秩检验：用于两个配对样本的比较（类似配对t检验，但无需正态性假设）。\n\n\n\n\nMann-Whitney U 检验公式\n\n假设两组独立样本分别为 \\(X\\) 和 \\(Y\\)，样本量分别为 \\(n_1\\) 和 \\(n_2\\)。\n对两组样本合并并按大小排序，赋予秩次。计算两组的秩次和 \\(R_1\\) 和 \\(R_2\\)（分别为 $ X$ 和 \\(Y\\) 的秩次总和）。\n\n确定统计量T值：\n\n假设两组样本量 \\(n_1&lt;n_2\\)，一般情况下以样本量较小者\\(n_1\\)对应的秩和\\(T_1\\)为检验统计量\\(T\\)，当样本相等时可以选择任一组的秩和为\\(T\\)。1\n当两组中样本量较小者不低于10时，在\\(H_0\\)成立假设下，统计量\\(T\\)的抽样分布近似于正态分布，有\n\\[T\\approx N\\left(\\frac{n_1(n+1)}{2},\\frac{n_1 n_2(n+1)}{12} \\right)\\] 此时，Wilcoxon 秩和统计量在\\(H_0\\)下关于\\(\\mu=\\frac{n_1(n+1)}{2}\\)对称。\n如果没有或存在较少的“结”，将\\(T\\)标准化后为：\n\\[U=\\frac{T-\\frac{n_1(n+1)}{2}+C}{\\sqrt{\\frac{n_1 n_2(n+1)}{12}}}\\approx N(0,1)\\]\n其中，C为连续性校正系数，当\\(T&gt;\\frac{n(n+1)}{4}\\)时，\\(C=-0.5\\)，当\\(T&lt;\\frac{n(n+1)}{4}\\)时，\\(C=0.5\\)，当\\(T=\\frac{n(n+1)}{4}\\)时，\\(C=0\\)。\n若“结”的比例较多（&gt;25%），则用以下公式校正：\n\\[U_c=\\frac{T-\\frac{n_1(n+1)}{2}+C}{\\sqrt{\\frac{n_1 n_2}{12}[(n+1)-\\sum_\\limits{i=1}^{g}\\frac{t_i^3-t_i}{n(n-1)}]}}\\approx N(0,1)\\]\n\nWilcoxon 符号秩检验公式\n\n对配对样本 \\((X_i, Y_i)\\)，计算差值 \\(D_i = X_i - Y_i\\)，取非零差值的绝对值并排序（若差值为0则舍去不计，且减去相应的个数），赋予秩次 \\(R_i\\)。再根据差值的符号计算符号秩次和 \\(W\\)：\n\\[W = \\sum R_i \\cdot \\text{sign}(D_i)\\]\n检验统计量 \\(T\\) 是 \\(W\\) 的绝对值，依据表或正态分布计算显著性。\n正态近似法：\n当\\(n\\ge 30\\)时，有中心极限定理可知，当\\(H_0\\)成立时统计量\\(T\\)的抽样分布近似正态分布，有\n\\[T\\approx N \\left(\\frac{n(n+1)}{4},\\frac{n(n+1)(2n+1)}{24}\\right)\\] 其中，均数\\(\\mu=\\frac{n(n+1)}{4}\\)，方差\\(\\sigma^2=\\frac{n(n+1)(2n+1)}{24}\\)。 将T标准化后，近似服从标准正态分布，有\n\\[U=\\frac{T-\\frac{n(n+1)}{4}+C}{\\sqrt{\\frac{n(n+1)(2n+1)}{24}}}\\approx N(0,1)\\] 其中，n是差值不为0的对子数，C为连续性校正系数，当\\(T&gt;\\frac{n(n+1)}{4}\\)时，\\(C=-0.5\\)，当\\(T&lt;\\frac{n(n+1)}{4}\\)时，\\(C=0.5\\)，当\\(T=\\frac{n(n+1)}{4}\\)时，\\(C=0\\)。\n当N较大时，样本中可能存在较多的“结”，（如“结”所占比例大于25%），此时需要使用校正公式：\n\\[U=\\frac{T-\\frac{n(n+1)}{4}+C}{\\sqrt{\\frac{n(n+1)(2n+1)}{24}-\\frac{\\sum_\\limits{i=1}^g(t_i^3-t_i)}{48}}}\\approx N(0,1)\\] 其中，\\(t_i\\)为\\(i\\)个“结”中有相同秩次的个数，\\(g\\)是“结”的个数。\nWilcoxon符号秩检验的前提条件为数据是连续的且差值分布是对称的。\nnotice：秩和秩和的区别：秩是指全部观察值按某种顺序排列的位序，在一定程度上反映了等级的高低；而秩和则表示同组秩次之和，在一定程度上反映了等级的分布。2\n\n\n\n\nMann-Whitney U 检验：\n\n比较两个独立样本的中位数是否存在显著差异。\n\n适用于非正态分布数据或含有极端值的样本。\n\n示例：比较两种治疗方法的疗效（不同受试者组）。\n\nWilcoxon 符号秩检验：\n\n比较两个配对样本的中位数差异。\n\n适用于重复测量数据或实验设计中存在配对关系的场景。\n\n示例：同一批受试者在治疗前后血压的变化。\n\n\n\n\n\n\n秩和检验是非参数方法，对数据分布假设少，但效率可能低于参数方法（如t检验）在满足条件时的效果，如果满足参数检验的条件，应优先考虑使用参数检验的方法，否则会增加犯二类错误的概率。\n数据需要满足独立性假设，否则检验结果可能不准确。\n\nend.",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "非参数检验"
    ]
  },
  {
    "objectID": "Learn/Basic/10-non-parameter-test.html#footnotes",
    "href": "Learn/Basic/10-non-parameter-test.html#footnotes",
    "title": "非参数检验",
    "section": "脚注",
    "text": "脚注\n\n\n不是说一定要选择样本量较小者对应的秩和作为检验统计量，只是长期的使用习惯，造成了这一惯例。如果取较小的秩和计算后得到的\\(U&lt;u_{\\alpha/2}\\)，则表示拒绝\\(H_0\\)；相反，如果取较大的秩和计算后得到的\\(U&gt;u_{1-\\alpha/2}\\)，也会表示拒绝\\(H_0\\)，他们都表示检验统计量落在了拒绝域中。↩︎\n尽管非参数方法对总体分布形式未做要求，但如果我们知道总体的一些性质而不去利用，就会浪费许多有用的信息，最常见的就是分布的对称性，配对设计的 Wilcoxon 符号秩检验充分利用了差值分布对称性这一信息，这与尽可能地采用有效方法，利用尽可能多的信息进行统计分析的大原则相一致。↩︎",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "非参数检验"
    ]
  },
  {
    "objectID": "Learn/Basic/09-chi2-test.html",
    "href": "Learn/Basic/09-chi2-test.html",
    "title": "卡方检验",
    "section": "",
    "text": "资料特征\n数据特征\n\n完全随机设计\n\n配对设计\n随机区组\n\n\n\n\n\n\n单组\n两组\n多组\n\n\n\n\n分类资料\n无序分类资料\n二项分布直接计算概率法、正态近似法（Z检验）、率的正态近似\n独立四格表\\(\\chi^2\\)检验、Fisher确切概率法\nR×C交叉表\\(\\chi^2\\)检验、Fisher确切概率法\n配对四格表\\(\\chi^2\\)检验，配对R×R列联表\\(\\chi^2\\)检验\n/\n\n\n\n等级资料\nWilcoxon符合秩和检验\nwilcoxon秩和检验\nKruskal-Wallis H检验\nWilcoxon符合秩和检验\nFriedman M秩和检验\n\n\n\n\n\n\n\n\n\n\n\n\n\n方法\n内容\n\n\n\n\n确切概率法\n1. 适用情形：样本量较小或\\(\\pi_0\\)不靠近0.5时作单侧检验的情形。2. 计算公式：(1)最多有k例阳性的概率：\\(Pr(X\\le k)\\)(2)最少有k例阳性的概率：\\(Pr(X\\ge k)\\)\n\n\n正态近似法\n1. 适用情形：样本量较大时，\\(n\\pi,n(1-\\pi)\\)均大于5；2. 计算公式：分子为\\(p-\\pi_0\\)，分母为率的标准误\n\n\n\nnotice：上式中p为样本率，\\(\\pi_0\\)为给的总体率（常为理论值或标准值），n为样本含量。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n方法\n情形\n计算公式\n\n\n\n\n独立四格表卡方检验\n\\(n\\ge 40\\)且所有的\\(T\\ge 5\\)\\(n\\ge 40\\)且任一理论频数有\\(1\\le T&lt; 5\\)当\\(n&lt;40\\)，或任一一个格子理论频数\\(T&lt;1\\)时\n卡方基本公式、独立四格表专用公式同上、但是需要校正用四格表资料的Fisher确切概率法\n\n\n正态近似法\n\\(n_1p_1,n_1(1-p_1),n_2p_2,n_2(1-p_2)\\)均大于5\n分子为样本率之差，分母为样本率差的标准误\\(S_{p1-p2}\\)为两个样本率之差的标准误，\\(p_c=\\frac{x_1+x_2}{n_1+n_2}\\)为两样本的合并率\n\n\n校正样本率的正态近似法\n当\\(n_1p_1,n_1(1-p_1),n_2p_2,n_2(1-p_2)\\)不太大时\n同上，但是需要对样本率实施“分子+2、分母+4”的校正\n\n\n\nnotice：\n\n正态近似法与卡方检验结果是很接近的。在日常计算时，因为计算简便，故常用卡方检验公式。\n四格表的自由度为1。\n四格表实际频数变动时，若周边合计数保持不变，则理论频数将不会产生变化。\n用\\(n_R\\)和\\(n_C\\)和n分别表示行合计、列合计和总合计，则计算每格理论数的公式为：\\(T_{RC}=\\frac{n_R×n_C}{n}\\)。\n\\(\\chi^2\\)检验的基本公式：\\(\\chi^2=\\sum \\frac{(A-T)^2}{T}\\)。\n校正的\\(\\chi^2\\)检验的基本公式：\\(\\chi^2=\\sum \\frac{(|A-T|-0.5)^2}{T}\\)。\n\n\n\n\n\n\n\n\n\n\n\n\n方法\n情形\n计算公式\n\n\n\n\n配对四格表卡方检验\n当\\((b+c)\\ge 40\\)时当\\((b+c)&lt;40\\)时\n配对卡方检验专用公式校正配对卡方检验专用公式\n\n\n配对R×R交叉表数据的\\(\\chi^2\\)检验\nR（\\(R\\ge2\\)）\n\\(T=\\frac{k-1}{k}\\sum_{i=1}^{k}\\frac{(n_i-m_i)^2}{n_i+m_i-2A_{ii}}\\)\n\n\n\nnotice：\n\n配对\\(\\chi^2\\)检验的基本公式：\\(\\chi^2=\\sum \\frac{(A-T)^2}{T}=\\frac{(b-c)^2}{b+c}\\)。\n若b+c&lt;40,使用校正的配对\\(\\chi^2\\)检验的基本公式：\\(\\chi^2=\\sum \\frac{(|b-c|-1)^2}{b+c}\\)。\n\n\n\n\n\n\n\n\n建立假设检验，确定检验水准 \\(H_0\\):两变量之间相互独立 \\(H_1\\):两变量之间相互独立 \\(\\alpha=0.05\\)\n计算检验统计量 [^2=_{i,j} ]\n确定P值，做出推断\n关联系数的计算 [r=]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n类目\n内容\n\n\n\n\n假设检验\n\\(H_0\\)：各组总体率（或构成比）相同。\\(H_1\\)：各组总体率（或构成比）不同（不全相同）。\n\n\n计算公式\n卡方检验基本公式，自由度为：\\(v=(R-1)(C-1)\\)\n\n\n数据要求\n1. 应用条件：不能有理论频数小于1的格子，或者不能有1/5以上的理论频数大于等于1且小于5 2. 不能进行卡方检验时的解决办法：①增加样本量；②合并或删除理论频数比较小的行或列；③采用Fisher确切概率法\n\n\n卡方分割\n多个率或多个频率分布比较的卡方检验，当结论为拒绝\\(H_0\\)时，仅表示多组之间是有差别的。若需要明确研究是那两组之间存在差别，可做率的多重比较，将R×C表分割为若干个小的四格表进行检验，并且需要根据比较的次数合理地修正检验水准\\(\\alpha\\)，否则将人为地增大犯第一类错误的概率\n\n\n\nnotice:\n\n多个独立样本率的比较，根据R个独立样本的频率分布，是检验R个二项分布总体的概率是否相同，。假设对四个样本率进行比较，进行\\(\\chi^2\\)检验，则它的行数为4，列数为2，其自由度为\\(v=(R-1)×(C-1)=(4-1)(2-1)=3\\)。\n针对行列表资料的\\(\\chi^2\\)检验，若有\\(1/5\\)格子以上的理论频数小于5，即\\(1\\le T\\le5\\)时，应考虑增加样本量，或结合专业知识对行或列进行合并。",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "卡方检验"
    ]
  },
  {
    "objectID": "Learn/Basic/09-chi2-test.html#卡方检验",
    "href": "Learn/Basic/09-chi2-test.html#卡方检验",
    "title": "卡方检验",
    "section": "",
    "text": "资料特征\n数据特征\n\n完全随机设计\n\n配对设计\n随机区组\n\n\n\n\n\n\n单组\n两组\n多组\n\n\n\n\n分类资料\n无序分类资料\n二项分布直接计算概率法、正态近似法（Z检验）、率的正态近似\n独立四格表\\(\\chi^2\\)检验、Fisher确切概率法\nR×C交叉表\\(\\chi^2\\)检验、Fisher确切概率法\n配对四格表\\(\\chi^2\\)检验，配对R×R列联表\\(\\chi^2\\)检验\n/\n\n\n\n等级资料\nWilcoxon符合秩和检验\nwilcoxon秩和检验\nKruskal-Wallis H检验\nWilcoxon符合秩和检验\nFriedman M秩和检验\n\n\n\n\n\n\n\n\n\n\n\n\n\n方法\n内容\n\n\n\n\n确切概率法\n1. 适用情形：样本量较小或\\(\\pi_0\\)不靠近0.5时作单侧检验的情形。2. 计算公式：(1)最多有k例阳性的概率：\\(Pr(X\\le k)\\)(2)最少有k例阳性的概率：\\(Pr(X\\ge k)\\)\n\n\n正态近似法\n1. 适用情形：样本量较大时，\\(n\\pi,n(1-\\pi)\\)均大于5；2. 计算公式：分子为\\(p-\\pi_0\\)，分母为率的标准误\n\n\n\nnotice：上式中p为样本率，\\(\\pi_0\\)为给的总体率（常为理论值或标准值），n为样本含量。",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "卡方检验"
    ]
  },
  {
    "objectID": "Learn/Basic/09-chi2-test.html#率的比较",
    "href": "Learn/Basic/09-chi2-test.html#率的比较",
    "title": "卡方检验",
    "section": "",
    "text": "方法\n情形\n计算公式\n\n\n\n\n独立四格表卡方检验\n\\(n\\ge 40\\)且所有的\\(T\\ge 5\\)\\(n\\ge 40\\)且任一理论频数有\\(1\\le T&lt; 5\\)当\\(n&lt;40\\)，或任一一个格子理论频数\\(T&lt;1\\)时\n卡方基本公式、独立四格表专用公式同上、但是需要校正用四格表资料的Fisher确切概率法\n\n\n正态近似法\n\\(n_1p_1,n_1(1-p_1),n_2p_2,n_2(1-p_2)\\)均大于5\n分子为样本率之差，分母为样本率差的标准误\\(S_{p1-p2}\\)为两个样本率之差的标准误，\\(p_c=\\frac{x_1+x_2}{n_1+n_2}\\)为两样本的合并率\n\n\n校正样本率的正态近似法\n当\\(n_1p_1,n_1(1-p_1),n_2p_2,n_2(1-p_2)\\)不太大时\n同上，但是需要对样本率实施“分子+2、分母+4”的校正\n\n\n\nnotice：\n\n正态近似法与卡方检验结果是很接近的。在日常计算时，因为计算简便，故常用卡方检验公式。\n四格表的自由度为1。\n四格表实际频数变动时，若周边合计数保持不变，则理论频数将不会产生变化。\n用\\(n_R\\)和\\(n_C\\)和n分别表示行合计、列合计和总合计，则计算每格理论数的公式为：\\(T_{RC}=\\frac{n_R×n_C}{n}\\)。\n\\(\\chi^2\\)检验的基本公式：\\(\\chi^2=\\sum \\frac{(A-T)^2}{T}\\)。\n校正的\\(\\chi^2\\)检验的基本公式：\\(\\chi^2=\\sum \\frac{(|A-T|-0.5)^2}{T}\\)。\n\n\n\n\n\n\n\n\n\n\n\n\n方法\n情形\n计算公式\n\n\n\n\n配对四格表卡方检验\n当\\((b+c)\\ge 40\\)时当\\((b+c)&lt;40\\)时\n配对卡方检验专用公式校正配对卡方检验专用公式\n\n\n配对R×R交叉表数据的\\(\\chi^2\\)检验\nR（\\(R\\ge2\\)）\n\\(T=\\frac{k-1}{k}\\sum_{i=1}^{k}\\frac{(n_i-m_i)^2}{n_i+m_i-2A_{ii}}\\)\n\n\n\nnotice：\n\n配对\\(\\chi^2\\)检验的基本公式：\\(\\chi^2=\\sum \\frac{(A-T)^2}{T}=\\frac{(b-c)^2}{b+c}\\)。\n若b+c&lt;40,使用校正的配对\\(\\chi^2\\)检验的基本公式：\\(\\chi^2=\\sum \\frac{(|b-c|-1)^2}{b+c}\\)。",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "卡方检验"
    ]
  },
  {
    "objectID": "Learn/Basic/09-chi2-test.html#独立性检验",
    "href": "Learn/Basic/09-chi2-test.html#独立性检验",
    "title": "卡方检验",
    "section": "",
    "text": "建立假设检验，确定检验水准 \\(H_0\\):两变量之间相互独立 \\(H_1\\):两变量之间相互独立 \\(\\alpha=0.05\\)\n计算检验统计量 [^2=_{i,j} ]\n确定P值，做出推断\n关联系数的计算 [r=]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n类目\n内容\n\n\n\n\n假设检验\n\\(H_0\\)：各组总体率（或构成比）相同。\\(H_1\\)：各组总体率（或构成比）不同（不全相同）。\n\n\n计算公式\n卡方检验基本公式，自由度为：\\(v=(R-1)(C-1)\\)\n\n\n数据要求\n1. 应用条件：不能有理论频数小于1的格子，或者不能有1/5以上的理论频数大于等于1且小于5 2. 不能进行卡方检验时的解决办法：①增加样本量；②合并或删除理论频数比较小的行或列；③采用Fisher确切概率法\n\n\n卡方分割\n多个率或多个频率分布比较的卡方检验，当结论为拒绝\\(H_0\\)时，仅表示多组之间是有差别的。若需要明确研究是那两组之间存在差别，可做率的多重比较，将R×C表分割为若干个小的四格表进行检验，并且需要根据比较的次数合理地修正检验水准\\(\\alpha\\)，否则将人为地增大犯第一类错误的概率\n\n\n\nnotice:\n\n多个独立样本率的比较，根据R个独立样本的频率分布，是检验R个二项分布总体的概率是否相同，。假设对四个样本率进行比较，进行\\(\\chi^2\\)检验，则它的行数为4，列数为2，其自由度为\\(v=(R-1)×(C-1)=(4-1)(2-1)=3\\)。\n针对行列表资料的\\(\\chi^2\\)检验，若有\\(1/5\\)格子以上的理论频数小于5，即\\(1\\le T\\le5\\)时，应考虑增加样本量，或结合专业知识对行或列进行合并。",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "卡方检验"
    ]
  },
  {
    "objectID": "Learn/Basic/11-regression-correlation.html",
    "href": "Learn/Basic/11-regression-correlation.html",
    "title": "简单线性相关和回归",
    "section": "",
    "text": "two variables relationship\n\n\n\n\n\nThe basic process of straight-line regression analysis\n\n\n\n\n\n\n\n\n名称\n适用条件\n\n\n\nPearson直线相关系数\n双变量正态分布的资料\\(\\rightarrow\\)定量\\(\\rightarrow\\)类比t检验、方差分析\n\n\n列联系数\n非等级资料\\(\\rightarrow\\)分类\\(\\rightarrow\\)类比卡方检验\n\n\nSpearman秩相关系数\n不满足双变量正态分布、分布未知、等级资料\\(\\rightarrow\\)定量+分类\\(\\rightarrow\\)类比秩和检验",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "简单线性相关和回归"
    ]
  },
  {
    "objectID": "Learn/Basic/11-regression-correlation.html#两变量关系分析",
    "href": "Learn/Basic/11-regression-correlation.html#两变量关系分析",
    "title": "简单线性相关和回归",
    "section": "",
    "text": "two variables relationship",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "简单线性相关和回归"
    ]
  },
  {
    "objectID": "Learn/Basic/11-regression-correlation.html#常见相关系数",
    "href": "Learn/Basic/11-regression-correlation.html#常见相关系数",
    "title": "简单线性相关和回归",
    "section": "",
    "text": "The basic process of straight-line regression analysis\n\n\n\n\n\n\n\n\n名称\n适用条件\n\n\n\nPearson直线相关系数\n双变量正态分布的资料\\(\\rightarrow\\)定量\\(\\rightarrow\\)类比t检验、方差分析\n\n\n列联系数\n非等级资料\\(\\rightarrow\\)分类\\(\\rightarrow\\)类比卡方检验\n\n\nSpearman秩相关系数\n不满足双变量正态分布、分布未知、等级资料\\(\\rightarrow\\)定量+分类\\(\\rightarrow\\)类比秩和检验",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "简单线性相关和回归"
    ]
  },
  {
    "objectID": "Learn/Basic/11-regression-correlation.html#假设检验",
    "href": "Learn/Basic/11-regression-correlation.html#假设检验",
    "title": "简单线性相关和回归",
    "section": "\n2.1 假设检验",
    "text": "2.1 假设检验\n\n2.1.1 F检验\n\\(y_i\\)的总离均差平方和为：\n\\[SS_{yy}=\\sum_{i}(y_i-\\bar y)^2\\] 对其做分解，得到等式：\n\\[SS_{yy}=\\sum_{i}^{n}(\\hat y_i-\\bar y)^2+\\sum_{i}^{n}(y_i-\\hat y_i)^2\\] \\(\\sum_{i}^{n}(\\hat y_i-\\bar y)^2\\)为回归平方和（regression sum of squares），记为\\(SS_R\\)，表示回归估计值\\(\\hat y_i\\)与均数\\(\\bar y\\)的离差平方和，其公式为：\n\\[\n\\begin{align}\nSS_{yy} &= \\sum_{i=1}^{n}(\\hat y_i - \\bar y)^2 \\\\\n        &= \\sum_{i=1}^{n}[a + bx_i - (a + b\\bar x)]^2 \\\\\n        &= SS_{xx}b^2 \\\\\n        &= SS_{xy}b\n\\end{align}\n\\] 显然，回归平方和\\(SS_{R}\\)反映的是在y的总变异中由x与y的直线回归关系解释的那部分变异。\\(SS_R\\)值越大，说明回归直线的拟合效果就越好。\n\\(\\sum_{i}^{n}(y_i-\\hat y_i)^2\\)为残差平方和（residual sum of squares），记为\\(SS_E\\)，表示观测值\\(y_i\\)与回归估计值\\(\\hat y_i\\)的离差平方和，其公式为： \\[SS_E=\\sum_{i=1}^{n}(y_i-\\hat y_i)^2\\] \\(SS_E\\)反映了在总变异中扣除自变量x对因变量y的线性影响以后的其他因素（包括x对y的非线性影响和随机误差等）对y变异的影响，也就是在总平方和中无法用y和x线性回归关系解释的部分。\\(SS_E\\)值越小，说明回归直线的拟合效果就越好。\n对公式进行简化： \\[\\begin{align}\nSS_{yy}=&\\sum_{i}^{n}(\\hat y_i-\\bar y)^2+\\sum_{i}^{n}(y_i-\\hat y_i)^2\\\\\n=&SS_R+SS_E\n\\end{align}\\] 上述三个平方和，各有其相应的自由度\\(v\\)，并有如下关系： \\[v_{yy}=v_R+v_E\\\\\nv_{yy}=n-1,v_R=1,v_E=n-2\\]\n在\\(H_0\\)成立的条件下，有： \\[\\frac{SS_R}{\\sigma^2}\\sim \\chi^2(v_R),\\frac{SS_E}{\\sigma^2}\\sim \\chi^2(v_E)\\] 且\\(SS_R\\)和\\(SS_E\\)相互独立。\n检验统计量：\n\\[F=\\frac{SS_R/v_R}{SS_E/v_E}\\] 服从自由度\\(v_R=1,v_E=n-2\\)的F分布。如果y和x确实存在直线回归关系，那么回归所解释的变异\\(SS_R\\)应大于其他因素所解释的变异\\(SS_E\\)。由此可见，F检验正是建立在这个基础上的。\n对于给定的检验水准\\(\\alpha\\)， 如果\\(F&gt;F_{(v_R,v_E),1-\\alpha}\\)，则拒绝\\(H_0\\)，认为直线回归方程有统计学显著性；\n如果\\(F\\leq F_{(v_R,v_E),1-\\alpha}\\)，则不拒绝\\(H_0\\)，尚不能认为直线回归方程有统计学显著性。\n\n2.1.2 t检验法\n回归直线方程的稳定性程度取决于 \\(b\\) 的波动大小，即 \\(S_b\\) 的大小，这里的 \\(S_b\\) 为样本回归系数 \\(b\\) 的标准误的估计值。由于统计量 \\(b\\) 来自正态总体，故可从 \\(b\\) 的抽样分布出发构造 \\(t\\) 统计量对其进行假设检验。\n当 \\(H_0\\) ：\\(\\beta = 0\\) 成立时，检验统计量服从自由度 \\(v_E=n-2\\) 的 \\(t\\) 分布。\n\\[\nt=\\frac{b-0}{S_b}\\sim t(v_E)\n\\]\n其中：\n\\[\nS_b=\\frac{S_{yx}}{\\sqrt{SS_{xx}}}=\\sqrt{\\frac{S_{yx}/(n-2)}{SS_{xx}}}\n\\]\n\\(S_{yx}=\\sqrt{SS_E/(n-2)}\\) 为剩余标准差（residual standard deviation），是指扣除 \\(x\\) 对 \\(y\\) 的线性影响后，衡量观测值 \\(y\\) 对回归直线的平均离散程度，即回归直线 \\(\\hat y\\) 估计的精度。",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "简单线性相关和回归"
    ]
  },
  {
    "objectID": "Learn/Basic/11-regression-correlation.html#直线回归方程的区间估计",
    "href": "Learn/Basic/11-regression-correlation.html#直线回归方程的区间估计",
    "title": "简单线性相关和回归",
    "section": "\n2.2 直线回归方程的区间估计",
    "text": "2.2 直线回归方程的区间估计\n\n2.2.1 总体回归系数的置信区间\n\\[\nt = \\frac{b-\\beta}{S_b}\\sim t(v_E)\n\\]",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "简单线性相关和回归"
    ]
  },
  {
    "objectID": "Learn/Basic/11-regression-correlation.html#直线相关与直线回归的比较",
    "href": "Learn/Basic/11-regression-correlation.html#直线相关与直线回归的比较",
    "title": "简单线性相关和回归",
    "section": "\n2.3 直线相关与直线回归的比较",
    "text": "2.3 直线相关与直线回归的比较\n\n\n\n\n\n\n\n区别与联系\n类目\n内容\n\n\n\n区别\n资料要求\n1. 线性相关要求X,Y服从双变量正态分布，对这种资料进行回归分析称为\\(\\textrm{II}\\)型回归，即可以把X当自变量，也可以当因变量，反之亦然。2. 线性回归要求Y在给定X值时服从正态分布，X可以是精确测量和严格控制的变量，这时的回归称为型回归，即不可以把X当因变量，Y当自变量进行回归分析。\n\n\n\n\n应用\n1. 线性相关用来表达两个变量间的互依关系，两个变量的研究地位是相等的，谁做X，谁做Y都可以；2. 线性回归用来表达两个变量间的依存变化的数量关系，即一个变量（为因变量Y）如何依存于另一个变量（为自变量X）而变化，两个变量的研究地位是不相等的。\n\n\n\n意义\n1. 相关系数r说明具有线性关系的两个变量之间的密切程度和相关方向；2. 回归系数b表示X每变化一个单位所导致的Y的平均变化量。\n\n\n\nr和b的取值范围\nr没有单位，而b有单位（其单位是：Y的单位/X的单位），所以导致两者的取值范围不同；\\(-1 \\le r \\le 1\\),\\(-\\infty&lt;b&lt;+\\infty\\)\n\n\n\n\nr和b的计算公式不同\n\n\\(r=\\frac{l_{xy}}{\\sqrt{l_{xx}l_{yy}}}\\),\\(b=\\frac{SS_{xy}}{SS_{xx}}\\)\n\n\n\n联系\n符号\n对于既可以做相关又可作回归的同一组资料，计算出r与b的正负号相同\n\n\n\n假设检验\n对于同一组资料，相关系数和回归系数的假设检验等价。即有：\\(t_b=t_r\\)\n\n\n\n\n相互换算\n对于同一组资料，相关系数和回归系数可通过下式换算：\\(b=r\\frac{S_Y}{S_X}\\)，式中的\\(S_X,S_Y\\)分别是\\(X,Y\\)的标准差\n\n\n\n用回归解释相关\n又决定系数\\(R^2=\\frac{SS_{回}}{SS_{总}}\\in [0,1]\\)当总平方和的大小决定了相关的密切程度，回归平方和越接近总平方和，则\\(R^2\\)越接近1，相关的效果越好，说明回归效果越好，相关的密切程度也越高。",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "简单线性相关和回归"
    ]
  },
  {
    "objectID": "Learn/Basic/11-regression-correlation.html#数学定义",
    "href": "Learn/Basic/11-regression-correlation.html#数学定义",
    "title": "简单线性相关和回归",
    "section": "\n3.1 数学定义",
    "text": "3.1 数学定义\n均值向量：对于双元正态变量 \\((X, Y)\\)，均值向量为：\n\\[\\mu = \\begin{pmatrix}\n\\mu_X \\\\\n\\mu_Y\n\\end{pmatrix}\\]\n其中 \\(\\mu_X\\) 和 \\(\\mu_Y\\) 分别是随机变量 \\(X\\) 和 \\(Y\\) 的均值。 2. 协方差矩阵：协方差矩阵为：\n\\[\\Sigma = \\begin{pmatrix}\n\\sigma_X^2 & \\sigma_{XY} \\\\\n\\sigma_{XY} & \\sigma_Y^2\n\\end{pmatrix}\\]\n其中 \\(\\sigma_X^2\\) 和 \\(\\sigma_Y^2\\) 是 \\(X\\) 和 \\(Y\\) 的方差，\\(\\sigma_{XY}\\) 是它们之间的协方差。",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "简单线性相关和回归"
    ]
  },
  {
    "objectID": "Learn/Basic/11-regression-correlation.html#性质",
    "href": "Learn/Basic/11-regression-correlation.html#性质",
    "title": "简单线性相关和回归",
    "section": "\n3.2 性质",
    "text": "3.2 性质\n\n边缘分布：\\(X\\) 和 \\(Y\\) 的边缘分布也是正态分布。\n条件分布：给定 \\(X\\) 的值，\\(Y\\) 的条件分布也是正态分布。\n相关性：协方差矩阵的值可以用来判断 X 和 Y 之间的相关性。如果 \\(\\sigma_{XY} &gt; 0\\)，则两者正相关；如果 \\(\\sigma_{XY} &lt; 0\\)，则负相关。",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "简单线性相关和回归"
    ]
  },
  {
    "objectID": "Learn/Basic/11-regression-correlation.html#示例",
    "href": "Learn/Basic/11-regression-correlation.html#示例",
    "title": "简单线性相关和回归",
    "section": "\n3.3 示例",
    "text": "3.3 示例\n假设有一组数据描述学生的身高 \\(X\\) 和体重 \\(Y\\)，并且假设 \\((X, Y)\\) 服从双元正态分布：\n\n3.3.1 均值向量：\n\\[\\mu = \\begin{pmatrix}\n170 \\\\\n65\n\\end{pmatrix}\\]\n表示身高的均值为 170 厘米，体重的均值为 65 千克。 •\n\n3.3.2 协方差矩阵：\n\\[\\Sigma = \\begin{pmatrix}\n100 & 20 \\\\\n20 & 25\n\\end{pmatrix}\\]\n这里，身高的方差为 100，体重的方差为 25，协方差为 20，表示身高和体重之间存在正相关关系。\n在这个示例中，如果我们知道某个学生的身高为 180 厘米，我们可以利用条件分布来预测他的体重，这个体重的预测值也是正态分布。\n我们用一个图形来展示：\n\n## 安装和加载所需的包\n#install.packages(\"plotly\")\n#install.packages(\"mvtnorm\")\nlibrary(plotly)\nlibrary(mvtnorm)\nlibrary(webshot2)\n\n# 创建网格数据\nx &lt;- seq(150, 190, length.out = 100)\n#身高150-190，等距的100个值\ny &lt;- seq(50, 80, length.out = 100)\n#体重50-80，等距的100个值\ngrid &lt;- expand.grid(X = x, Y = y)\n#生成 x 和 y 的所有组合，用于构建一个网格数据框，以便计算多元正态分布的概率密度。\n\n# 设置均值和协方差矩阵\nmu &lt;- c(170, 65)\n#设置双元正态分布的均值向量，表示均值分别为身高 170 cm 和体重 65 kg\n\nsigma &lt;- matrix(c(100, 20, 20, 25), nrow = 2)\n#设置协方差矩阵，表示身高的方差为 100，体重的方差为 25，身高和体重之间的协方差为 20\n\n# 计算概率密度\nz &lt;- dmvnorm(as.matrix(grid), mean = mu, sigma = sigma)\n#计算每个网格点上双元正态分布的概率密度。\n\n# 将概率密度矩阵转换为适合绘图的形状\nz_matrix &lt;- matrix(z, nrow = 100, ncol = 100)\n\n# 绘制三维表面图\nplot_ly(x = x, y = y, z = z_matrix, type = \"surface\") %&gt;%\n  layout(title = list(text = \"双元正态分布的三维概率密度图\", y=0.95),\n         scene = list(xaxis = list(title = \"身高 (cm)\"),\n                      yaxis = list(title = \"体重 (kg)\"),\n                      zaxis = list(title = \"概率密度\")))\n\n\nBinary normal distribution\n\n\n注：上述图像在被转换为PDF文件时，会发生报错：Quarto 文档中包含了一些生成 HTML 输出的函数（比如交互式图表或其他 HTML 小部件），但你当前的目标输出格式是 PDF。由于 PDF 是静态格式，无法直接渲染 HTML 内容，Quarto 会报错并停止执行。\n解决方案，此章节不转换为PDF格式，或者：\n如果你仍想输出 PDF，但希望将 HTML 小部件作为静态截图嵌入，可以安装 R 的 webshot 或 webshot2 包。Quarto 会利用它们将 HTML 内容转换为图片。\n需要安装：\n\ninstall.packages(\"webshot2\")\n\n然后在这段程序的前部导入该包：library(webshot2)。\nend.",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "医学统计学基础",
      "简单线性相关和回归"
    ]
  },
  {
    "objectID": "Learn/Bayes/01-Bayes-PGM.html#灯泡机的简单概率图模型",
    "href": "Learn/Bayes/01-Bayes-PGM.html#灯泡机的简单概率图模型",
    "title": "贝叶斯与概率图模型（PGM）",
    "section": "",
    "text": "首先，为每一个节点定义取值：\n\nmachine_val &lt;- c(\"working\", \"broken\")\nlight_bulb_val &lt;- c(\"good\", \"bad\")\n\n为两个随机变量定义百分比数值：\n\nmachine_val &lt;- c(99,1)\nlight_bulb_val &lt;- c(99,1,60,40)\n\n使用 gRain 定义随机变量：\n\nlibrary(gRain)\nM &lt;- cptable(~machine, values = machine_prob,\n            levels = machine_val)\nL &lt;- cptable(~light_bulb | machine,\n            values = light_bulb_prob,\n            levels = light_bulb_val)\n\n这里的 cptable 表示条件概率表1：它是离散型随机变量概率分布的内存表示2。\n\n\nplist &lt;- compileCPT(list(M,L))\nplist\n\n输出结果如上，这里可以清楚地看到之前定义的概率分布\n2025.04.05 再次尝试复现程序，失败，暂时停止概率图R程序的复现工作。\nend.",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "贝叶斯与概率推理",
      "贝叶斯与概率图模型（PGM）"
    ]
  },
  {
    "objectID": "Learn/Bayes/01-Bayes-PGM.html#footnotes",
    "href": "Learn/Bayes/01-Bayes-PGM.html#footnotes",
    "title": "贝叶斯与概率图模型（PGM）",
    "section": "脚注",
    "text": "脚注\n\n条件概率表（Conditional Probability Table, CPT），是一种表格形式的数据结构，用来描述离散型随机变量之间的概率关系。通常用于表示一个变量（或一组变量）的概率分布，可能依赖于其他变量（条件变量）。↩︎\n“内存表示”指的是在计算机程序中，这种概率分布被组织和存储为一种数据结构（例如表格、数组或矩阵），以便程序可以高效地访问和操作这些概率值。具体来说，cptable 函数会根据你提供的参数（如 values 和 levels）生成一个对象，这个对象在内存中以某种形式存储了变量的概率分布。↩︎",
    "crumbs": [
      "Home",
      "医学统计学基础",
      "贝叶斯与概率推理",
      "贝叶斯与概率图模型（PGM）"
    ]
  },
  {
    "objectID": "Guide/Python/25-04-28-DID-test.html",
    "href": "Guide/Python/25-04-28-DID-test.html",
    "title": "How to Use the DID in Python",
    "section": "",
    "text": "双重差分回归 (DID) 用于评估一个事件的因果效应，其方法是比较事件发生的单元集合（处理组）与事件未发生的单元集合（控制组）。\nDID 背后的逻辑是，如果事件从未发生，处理组和控制组之间的差异应该随着时间的推移保持不变。\nDID 通过比较处理组和控制组在事件发生前后的差异来估计事件的因果效应。\nDID 法是一种无法随机分配样本情况下的替代方法，主要应用于区域行的策略评估问题。\n目标：获取相对同质的策略组和控制组，这个“相对”是指除策略影响外，策略组和控制组的结果变量随时间的变化存在一个基本固定的差异。\n对于相对同质的策略组和控制组，DID法通过第一次的差分消除这个基本固定的差异，通过第二次的差分消除时间趋势的影响，评估策略带来的实际效应。\n从DID 法的目标中可知，该方法面对的实验数据是面板数据（多个时间点的截面数据组成面板数据），即在策略干预时间点前，至少有两个时间点的数据。\n\\[\ny = \\alpha_0 +\\alpha_1g +\\alpha_2T + \\alpha_3gT + \\epsilon\n\\] \\(\\alpha_0\\)为常数项，\\(\\alpha_1\\)为处理组和控制组的差异，\\(\\alpha_2\\)为时间效应，\\(\\epsilon\\)为误差项。 \\(\\alpha_3\\)为交互项的系数，表示处理组和控制组在事件发生前后的差异。\n其中，\\(y\\)为结果变量，\\(g\\)为处理组和控制组的虚拟变量，\\(T\\)为时间虚拟变量，\\(gT\\)为交互项。 \\(\\alpha_3\\)为DID估计量，表示处理组和控制组在事件发生前后的差异。\nDID 模型的有效性检验\n为了保证该模型的有效性，在试验设计时需要满足平行趋势假设：在事件发生前，处理组和控制组的结果变量随时间的变化存在一个基本固定的差异。\n平行趋势，即策略组和控制组在干预前保持相同的变化趋势。\n3种常见的平行趋势的检验方法：\n\n画图法：画出处理组和控制组在事件发生前后的结果变量的变化趋势图，观察两组的变化趋势是否平行。\n统计检验法：使用t检验或F检验等统计方法，检验处理组和控制组在事件发生前的结果变量的差异是否显著。\n伪DID法：在事件发生前，随机选择一个时间点，将处理组和控制组的结果变量进行差分，检验差分后的结果变量是否显著。",
    "crumbs": [
      "Home",
      "统计软件",
      "Python",
      "How to Use the DID in Python"
    ]
  },
  {
    "objectID": "Guide/Python/25-04-28-DID-test.html#did双重差分回归",
    "href": "Guide/Python/25-04-28-DID-test.html#did双重差分回归",
    "title": "How to Use the DID in Python",
    "section": "",
    "text": "双重差分回归 (DID) 用于评估一个事件的因果效应，其方法是比较事件发生的单元集合（处理组）与事件未发生的单元集合（控制组）。\nDID 背后的逻辑是，如果事件从未发生，处理组和控制组之间的差异应该随着时间的推移保持不变。\nDID 通过比较处理组和控制组在事件发生前后的差异来估计事件的因果效应。\nDID 法是一种无法随机分配样本情况下的替代方法，主要应用于区域行的策略评估问题。\n目标：获取相对同质的策略组和控制组，这个“相对”是指除策略影响外，策略组和控制组的结果变量随时间的变化存在一个基本固定的差异。\n对于相对同质的策略组和控制组，DID法通过第一次的差分消除这个基本固定的差异，通过第二次的差分消除时间趋势的影响，评估策略带来的实际效应。\n从DID 法的目标中可知，该方法面对的实验数据是面板数据（多个时间点的截面数据组成面板数据），即在策略干预时间点前，至少有两个时间点的数据。\n\\[\ny = \\alpha_0 +\\alpha_1g +\\alpha_2T + \\alpha_3gT + \\epsilon\n\\] \\(\\alpha_0\\)为常数项，\\(\\alpha_1\\)为处理组和控制组的差异，\\(\\alpha_2\\)为时间效应，\\(\\epsilon\\)为误差项。 \\(\\alpha_3\\)为交互项的系数，表示处理组和控制组在事件发生前后的差异。\n其中，\\(y\\)为结果变量，\\(g\\)为处理组和控制组的虚拟变量，\\(T\\)为时间虚拟变量，\\(gT\\)为交互项。 \\(\\alpha_3\\)为DID估计量，表示处理组和控制组在事件发生前后的差异。\nDID 模型的有效性检验\n为了保证该模型的有效性，在试验设计时需要满足平行趋势假设：在事件发生前，处理组和控制组的结果变量随时间的变化存在一个基本固定的差异。\n平行趋势，即策略组和控制组在干预前保持相同的变化趋势。\n3种常见的平行趋势的检验方法：\n\n画图法：画出处理组和控制组在事件发生前后的结果变量的变化趋势图，观察两组的变化趋势是否平行。\n统计检验法：使用t检验或F检验等统计方法，检验处理组和控制组在事件发生前的结果变量的差异是否显著。\n伪DID法：在事件发生前，随机选择一个时间点，将处理组和控制组的结果变量进行差分，检验差分后的结果变量是否显著。",
    "crumbs": [
      "Home",
      "统计软件",
      "Python",
      "How to Use the DID in Python"
    ]
  },
  {
    "objectID": "Guide/Python/25-04-28-DID.html",
    "href": "Guide/Python/25-04-28-DID.html",
    "title": "DID 双重差分模型",
    "section": "",
    "text": "双重差分回归 (DID) 用于评估一个事件的因果效应，其方法是比较事件发生的单元集合（处理组）与事件未发生的单元集合（控制组）。\nDID 背后的逻辑是，如果事件从未发生，处理组和控制组之间的差异应该随着时间的推移保持不变。\nDID 通过比较处理组和控制组在事件发生前后的差异来估计事件的因果效应。\nDID 法是一种无法随机分配样本情况下的替代方法，主要应用于区域行的策略评估问题。\n目标：获取相对同质的策略组和控制组，这个“相对”是指除策略影响外，策略组和控制组的结果变量随时间的变化存在一个基本固定的差异。\n对于相对同质的策略组和控制组，DID法通过第一次的差分消除这个基本固定的差异，通过第二次的差分消除时间趋势的影响，评估策略带来的实际效应。\n从DID 法的目标中可知，该方法面对的实验数据是面板数据（多个时间点的截面数据组成面板数据），即在策略干预时间点前，至少有两个时间点的数据。\n\n\n\n\n\n\\[\ny = \\alpha_0 +\\alpha_1g +\\alpha_2T + \\alpha_3gT + \\epsilon\n\\]\n其中，\\(\\alpha_0\\)为常数项，\\(\\alpha_1\\)为处理组和控制组的差异，\\(\\alpha_2\\)为时间效应，\\(\\epsilon\\)为误差项。\n\\(y\\)为结果变量，\\(g\\)为处理组和控制组的虚拟变量，\\(T\\)为时间虚拟变量，\\(gT\\)为交互项。\n\\(\\alpha_3\\)为交互项的系数，也就是DID的估计量，当交互项 \\(gT\\) 与结果变量 \\(y\\) 显著相关时，\\(\\alpha_3\\) 为评估的实际的策略效应，表示处理组和控制组在事件发生前后的差异。\n\n\n\n\n\n\nDID模型示意图\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n组别\n干预前（T=0）\n干预后（T=1)\n差分（干预后非策略差异）\n\n\n\n\n策略组(g=1)\n\\(\\alpha_0+\\alpha_1\\)\n\\(\\alpha_0+\\alpha_1+\\alpha_2+\\alpha_3\\)\n\\(\\alpha_2+\\alpha_3\\)\n\n\n控制组(g=0)\n\\(\\alpha_0\\)（基准值）\n\\(\\alpha_0+\\alpha_2\\)\n\\(\\alpha_2\\)\n\n\n差分(组间差异)\n\\(\\alpha_1\\)\n\\(\\alpha_1+\\alpha_3\\)\n\\(\\alpha_3\\)（策略效应）\n\n\n\nDID模型的原理很清晰，在无法获取完全同质的策略组和控制组的情况下，替代地获取存在固定组间差异的试验数据以抵抗混杂的影响，最后通过回归系数的显著性检验来评估策略实施的净效应。但是，理论很简洁，现实很残酷，获取 @ref(DID-models) 所示的理想数据并不简单，为了保证DID模型可以有效地评估策略效应，需要一些必要的前提检验。下面介绍这些关于DID模型的有效性检验。\n\n\n\n\n为了保证该模型的有效性，在试验设计时需要满足平行趋势假设：在事件发生前，处理组和控制组的结果变量随时间的变化存在一个基本固定的差异。\n平行趋势，即策略组和控制组在干预前保持相同的变化趋势。\n3种常见的平行趋势的检验方法：\n\n画图法：画出处理组和控制组在事件发生前后的结果变量的变化趋势图，观察两组的变化趋势是否平行。\n统计检验法（差异性检验）：使用t检验或F检验等统计方法，检验处理组和控制组在事件发生前的结果变量的差异是否显著。\n伪DID法（交互项显著性检验）：在事件发生前，随机选择一个时间点，将处理组和控制组的结果变量进行差分，检验差分后的结果变量是否显著。\n\n\n\n\n数据来自 princeton 的 Oscar Torres-Reyna 教授构建的虚拟数据集。\n案例数据示例如下表所示：",
    "crumbs": [
      "Home",
      "统计软件使用历程",
      "Python",
      "DID 双重差分模型"
    ]
  },
  {
    "objectID": "Guide/Python/25-04-28-DID.html#did-定义与目标",
    "href": "Guide/Python/25-04-28-DID.html#did-定义与目标",
    "title": "DID 双重差分模型",
    "section": "",
    "text": "双重差分回归 (DID) 用于评估一个事件的因果效应，其方法是比较事件发生的单元集合（处理组）与事件未发生的单元集合（控制组）。\nDID 背后的逻辑是，如果事件从未发生，处理组和控制组之间的差异应该随着时间的推移保持不变。\nDID 通过比较处理组和控制组在事件发生前后的差异来估计事件的因果效应。\nDID 法是一种无法随机分配样本情况下的替代方法，主要应用于区域行的策略评估问题。\n目标：获取相对同质的策略组和控制组，这个“相对”是指除策略影响外，策略组和控制组的结果变量随时间的变化存在一个基本固定的差异。\n对于相对同质的策略组和控制组，DID法通过第一次的差分消除这个基本固定的差异，通过第二次的差分消除时间趋势的影响，评估策略带来的实际效应。\n从DID 法的目标中可知，该方法面对的实验数据是面板数据（多个时间点的截面数据组成面板数据），即在策略干预时间点前，至少有两个时间点的数据。",
    "crumbs": [
      "Home",
      "统计软件使用历程",
      "Python",
      "DID 双重差分模型"
    ]
  },
  {
    "objectID": "Guide/Python/25-04-28-DID.html#did-模型的原理",
    "href": "Guide/Python/25-04-28-DID.html#did-模型的原理",
    "title": "DID 双重差分模型",
    "section": "",
    "text": "\\[\ny = \\alpha_0 +\\alpha_1g +\\alpha_2T + \\alpha_3gT + \\epsilon\n\\]\n其中，\\(\\alpha_0\\)为常数项，\\(\\alpha_1\\)为处理组和控制组的差异，\\(\\alpha_2\\)为时间效应，\\(\\epsilon\\)为误差项。\n\\(y\\)为结果变量，\\(g\\)为处理组和控制组的虚拟变量，\\(T\\)为时间虚拟变量，\\(gT\\)为交互项。\n\\(\\alpha_3\\)为交互项的系数，也就是DID的估计量，当交互项 \\(gT\\) 与结果变量 \\(y\\) 显著相关时，\\(\\alpha_3\\) 为评估的实际的策略效应，表示处理组和控制组在事件发生前后的差异。\n\n\n\n\n\n\nDID模型示意图\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n组别\n干预前（T=0）\n干预后（T=1)\n差分（干预后非策略差异）\n\n\n\n\n策略组(g=1)\n\\(\\alpha_0+\\alpha_1\\)\n\\(\\alpha_0+\\alpha_1+\\alpha_2+\\alpha_3\\)\n\\(\\alpha_2+\\alpha_3\\)\n\n\n控制组(g=0)\n\\(\\alpha_0\\)（基准值）\n\\(\\alpha_0+\\alpha_2\\)\n\\(\\alpha_2\\)\n\n\n差分(组间差异)\n\\(\\alpha_1\\)\n\\(\\alpha_1+\\alpha_3\\)\n\\(\\alpha_3\\)（策略效应）\n\n\n\nDID模型的原理很清晰，在无法获取完全同质的策略组和控制组的情况下，替代地获取存在固定组间差异的试验数据以抵抗混杂的影响，最后通过回归系数的显著性检验来评估策略实施的净效应。但是，理论很简洁，现实很残酷，获取 @ref(DID-models) 所示的理想数据并不简单，为了保证DID模型可以有效地评估策略效应，需要一些必要的前提检验。下面介绍这些关于DID模型的有效性检验。",
    "crumbs": [
      "Home",
      "统计软件使用历程",
      "Python",
      "DID 双重差分模型"
    ]
  },
  {
    "objectID": "Guide/Python/25-04-28-DID.html#did-模型的有效性检验",
    "href": "Guide/Python/25-04-28-DID.html#did-模型的有效性检验",
    "title": "DID 双重差分模型",
    "section": "",
    "text": "为了保证该模型的有效性，在试验设计时需要满足平行趋势假设：在事件发生前，处理组和控制组的结果变量随时间的变化存在一个基本固定的差异。\n平行趋势，即策略组和控制组在干预前保持相同的变化趋势。\n3种常见的平行趋势的检验方法：\n\n画图法：画出处理组和控制组在事件发生前后的结果变量的变化趋势图，观察两组的变化趋势是否平行。\n统计检验法（差异性检验）：使用t检验或F检验等统计方法，检验处理组和控制组在事件发生前的结果变量的差异是否显著。\n伪DID法（交互项显著性检验）：在事件发生前，随机选择一个时间点，将处理组和控制组的结果变量进行差分，检验差分后的结果变量是否显著。",
    "crumbs": [
      "Home",
      "统计软件使用历程",
      "Python",
      "DID 双重差分模型"
    ]
  },
  {
    "objectID": "Guide/Python/25-04-28-DID.html#did-案例分析",
    "href": "Guide/Python/25-04-28-DID.html#did-案例分析",
    "title": "DID 双重差分模型",
    "section": "",
    "text": "数据来自 princeton 的 Oscar Torres-Reyna 教授构建的虚拟数据集。\n案例数据示例如下表所示：",
    "crumbs": [
      "Home",
      "统计软件使用历程",
      "Python",
      "DID 双重差分模型"
    ]
  },
  {
    "objectID": "Guide/Stata/25-04-29-Stata-PY.html",
    "href": "Guide/Stata/25-04-29-Stata-PY.html",
    "title": "Use Stata with Python",
    "section": "",
    "text": "在Stata官网冲浪的时候，看到他们推出了Python与Stata联合使用的功能，于是就想试试。\nStata是一个强大的统计分析软件，广泛应用于社会科学、经济学、医学等领域。它提供了丰富的统计分析功能和数据处理工具，适合进行复杂的数据分析和建模工作。\n在使用Stata的时候，我们可能会需要在Python中调用Stata的功能。PyStata就是一个可以让我们在Python中使用Stata的工具。它允许我们在Python中运行Stata命令，并且可以将结果返回到Python中进行进一步的分析和处理。\n\n\n\nStata 官网关于 pystata 的介绍\nPyStata 是 Stata17 中引入的一个新概念，它涵盖了所有 Stata 和 Python 的交互方式。\n事实上从 Stata16 开始，我们就可以在 Stata 中调用 Python 代码，并通过 Stata 函数接口（ sfi 模块）实现 Python 与 Stata 核心功能的交互；但 Stata17 通过允许我们通过导入一个新的 Python 包（pystata）从一个独立的 Python 环境中调用 Stata ，这大大扩展二者的交互功能，使我们可以在基于或支持 IPython 内核的环境中（例如：Jupyter Notebook 、Jupyter Lab 、Spyder 、PyCharm 、VScode 等）更加方便地调用 Stata 和 Mata。\n\n\n自 Stata17 之后，官方推出了一种 StataS与 Python 的全新交互方式，而 stata_kernel 是一个第三方项目。\n即通过在 Python 环境中直接安装 pystata 模块，便能在 Python 环境中直接调用 Stata17 的命令。而 stata_kernel 是通过在 Jupyter Notebook 中安装 stata_kernel 模块，来实现 Python 与 Stata 的交互。\n在使用Quarto制作本网站时，可以编译 .qmd 和 .ipynb 文件，生成 .html 和 .pdf 文件，就想是否可以 Quarto 中利用 .ipynb 文件来调用 Stata 然后编译成 .html 文件再在网站中展示出来。\n于是有了这篇笔记。\n步骤主要分为四部分： 1. 将 Stata 添加到系统环境变量中 2. 在 Python 中安装 PyStata 3. 在 Jupyter Notebook 中使用PyStata 4. 在 Quarto 中使用 PyStata\n\n\n\n\n\n请先安装好 Stata 17 或更高版本，且最好是无限制的版本，因为有很多网上的资源是破解的，可能会有一些限制。\nStata17/18/19 软件必须具备有效的许可证，否则无法调用\n拥有基于或支持 IPython 内核的 Python 环境（建议使用 Jupyter Lab 或 VScode）\nPython 3.7 或更高版本（建议使用 Anaconda 进行安装和管理）\n\n\n\n\n要使用 pystata 包的完整功能，需要安装以下 Python 包：\n\nNumPy 1.9 或更高版本\npandas 0.15 或更高版本\n\n如果您仅计划通过调用 stata 模块中的 run() 方法执行 Stata 命令，则无需安装 NumPy 和 pandas 包。\n然而，如果需要调用 stata 模块中用于在 Stata 和 Python 之间传递数据和结果的方法，则必须安装这些包。\n\nIPython 5.0 或更高版本\n\n如果您想使用魔法命令，则需要安装 IPython 包。\n\n\n\n\n\n\n\n\n找到 Stata 的安装目录，通常在 C:\\Program Files\\Stata18 或 C:\\Program Files (x86)\\Stata18。\n复制该目录的路径。\n右键点击“此电脑”或“计算机”，选择“属性”。\n点击“高级系统设置”。\n在“系统属性”窗口中，点击“环境变量”。\n在“系统变量”部分，找到名为“Path”的变量，选中它并点击“编辑”。\n在“编辑环境变量”窗口中，点击“新建”，然后粘贴 Stata 的安装目录路径。\n点击“确定”保存更改，关闭所有窗口。\n重新启动命令提示符或 PowerShell，以使更改生效。\n在命令提示符中输入 stata，如果 Stata 启动，则说明添加成功。\n\n\n\n\n\n打开命令提示符或 PowerShell。\n输入以下命令，将 C:\\Program Files\\Stata18 替换为 Stata 的安装目录：\n\nsetx PATH \"%PATH%;C:\\Program Files\\Stata17\"\n\n按下回车键执行命令。\n关闭命令提示符或 PowerShell。\n重新打开命令提示符或 PowerShell，以使更改生效。\n在命令提示符中输入 stata，如果 Stata 启动，则说明添加成功。\n\n\n\n\n这个办法也有一定的普及程度，但是可能不太好用，对于新手来说会有些难以理解。可以参考连玉君的珠联璧合：Jupyter Notebook 和 Stata 之融合。\n主要步骤如下：\n\n找到 Stata 的安装目录，通常在 C:\\Program Files\\Stata18 或 C:\\Program Files (x86)\\Stata18。\n在该目录下找到 StataMP.exe 或 StataSE.exe 文件。\n将该文件的路径复制下来。\n以管理员身份打开电脑的 Windows Powershell 。\n在 PS C:\\WINDOWS\\system32&gt; 后输入以下命令（将路径转到 Stata 安装目录下）：\n\n在 Windows PowerShell 执行 cd 命令，以进入 stata 程序安装的路径。cd 命令后接上步所获取的 stata 安装路径。根据个人电脑安装路径不同有所差异。路径请以英文引号包围，这样可以避免路径文件夹名称中包含空格导致无法顺利进入目标路径。\ncd \"C:\\Program Files\\Stata18\"\n实际效果应该如下：\nPS C:\\WINDOWS\\system32&gt; cd 'C:\\Program Files\\Stata18'\nPS C:\\Program Files\\Stata18&gt;\n\n输入以下命令来将 stata 添加到命令行注册表中：\n\n.\\StataMP-64.exe /Register\n需要注意的是： .\\StataMP-64.exe /Register 中的 .\\StataMP-64.exe 部分，根据个人电脑安装 Stata17+ 版本有所差异。我电脑安装的是 MP 版，所以为 .\\StataMP-64.exe。如果安装的是 SE 版，应该为 .\\StataSE-64.exe。\n这里实测效果不太好，不知道为什么，注册成功但是命令行输入 stata 还是无法打开 Stata。",
    "crumbs": [
      "Home",
      "统计软件",
      "Stata",
      "Use Stata with Python"
    ]
  },
  {
    "objectID": "Guide/Stata/25-04-29-Stata-PY.html#前言",
    "href": "Guide/Stata/25-04-29-Stata-PY.html#前言",
    "title": "Use Stata with Python",
    "section": "",
    "text": "在Stata官网冲浪的时候，看到他们推出了Python与Stata联合使用的功能，于是就想试试。\nStata是一个强大的统计分析软件，广泛应用于社会科学、经济学、医学等领域。它提供了丰富的统计分析功能和数据处理工具，适合进行复杂的数据分析和建模工作。\n在使用Stata的时候，我们可能会需要在Python中调用Stata的功能。PyStata就是一个可以让我们在Python中使用Stata的工具。它允许我们在Python中运行Stata命令，并且可以将结果返回到Python中进行进一步的分析和处理。",
    "crumbs": [
      "Home",
      "统计软件",
      "Stata",
      "Use Stata with Python"
    ]
  },
  {
    "objectID": "Guide/Stata/25-04-29-Stata-PY.html#关于pystata",
    "href": "Guide/Stata/25-04-29-Stata-PY.html#关于pystata",
    "title": "Use Stata with Python",
    "section": "",
    "text": "Stata 官网关于 pystata 的介绍\nPyStata 是 Stata17 中引入的一个新概念，它涵盖了所有 Stata 和 Python 的交互方式。\n事实上从 Stata16 开始，我们就可以在 Stata 中调用 Python 代码，并通过 Stata 函数接口（ sfi 模块）实现 Python 与 Stata 核心功能的交互；但 Stata17 通过允许我们通过导入一个新的 Python 包（pystata）从一个独立的 Python 环境中调用 Stata ，这大大扩展二者的交互功能，使我们可以在基于或支持 IPython 内核的环境中（例如：Jupyter Notebook 、Jupyter Lab 、Spyder 、PyCharm 、VScode 等）更加方便地调用 Stata 和 Mata。\n\n\n自 Stata17 之后，官方推出了一种 StataS与 Python 的全新交互方式，而 stata_kernel 是一个第三方项目。\n即通过在 Python 环境中直接安装 pystata 模块，便能在 Python 环境中直接调用 Stata17 的命令。而 stata_kernel 是通过在 Jupyter Notebook 中安装 stata_kernel 模块，来实现 Python 与 Stata 的交互。\n在使用Quarto制作本网站时，可以编译 .qmd 和 .ipynb 文件，生成 .html 和 .pdf 文件，就想是否可以 Quarto 中利用 .ipynb 文件来调用 Stata 然后编译成 .html 文件再在网站中展示出来。\n于是有了这篇笔记。\n步骤主要分为四部分： 1. 将 Stata 添加到系统环境变量中 2. 在 Python 中安装 PyStata 3. 在 Jupyter Notebook 中使用PyStata 4. 在 Quarto 中使用 PyStata",
    "crumbs": [
      "Home",
      "统计软件",
      "Stata",
      "Use Stata with Python"
    ]
  },
  {
    "objectID": "Guide/Stata/25-04-29-Stata-PY.html#前置要求",
    "href": "Guide/Stata/25-04-29-Stata-PY.html#前置要求",
    "title": "Use Stata with Python",
    "section": "",
    "text": "请先安装好 Stata 17 或更高版本，且最好是无限制的版本，因为有很多网上的资源是破解的，可能会有一些限制。\nStata17/18/19 软件必须具备有效的许可证，否则无法调用\n拥有基于或支持 IPython 内核的 Python 环境（建议使用 Jupyter Lab 或 VScode）\nPython 3.7 或更高版本（建议使用 Anaconda 进行安装和管理）",
    "crumbs": [
      "Home",
      "统计软件",
      "Stata",
      "Use Stata with Python"
    ]
  },
  {
    "objectID": "Guide/Stata/25-04-29-Stata-PY.html#依赖项",
    "href": "Guide/Stata/25-04-29-Stata-PY.html#依赖项",
    "title": "Use Stata with Python",
    "section": "",
    "text": "要使用 pystata 包的完整功能，需要安装以下 Python 包：\n\nNumPy 1.9 或更高版本\npandas 0.15 或更高版本\n\n如果您仅计划通过调用 stata 模块中的 run() 方法执行 Stata 命令，则无需安装 NumPy 和 pandas 包。\n然而，如果需要调用 stata 模块中用于在 Stata 和 Python 之间传递数据和结果的方法，则必须安装这些包。\n\nIPython 5.0 或更高版本\n\n如果您想使用魔法命令，则需要安装 IPython 包。",
    "crumbs": [
      "Home",
      "统计软件",
      "Stata",
      "Use Stata with Python"
    ]
  },
  {
    "objectID": "Guide/Stata/25-04-29-Stata-PY.html#stata-添加到系统环境变量中",
    "href": "Guide/Stata/25-04-29-Stata-PY.html#stata-添加到系统环境变量中",
    "title": "Use Stata with Python",
    "section": "",
    "text": "找到 Stata 的安装目录，通常在 C:\\Program Files\\Stata18 或 C:\\Program Files (x86)\\Stata18。\n复制该目录的路径。\n右键点击“此电脑”或“计算机”，选择“属性”。\n点击“高级系统设置”。\n在“系统属性”窗口中，点击“环境变量”。\n在“系统变量”部分，找到名为“Path”的变量，选中它并点击“编辑”。\n在“编辑环境变量”窗口中，点击“新建”，然后粘贴 Stata 的安装目录路径。\n点击“确定”保存更改，关闭所有窗口。\n重新启动命令提示符或 PowerShell，以使更改生效。\n在命令提示符中输入 stata，如果 Stata 启动，则说明添加成功。\n\n\n\n\n\n打开命令提示符或 PowerShell。\n输入以下命令，将 C:\\Program Files\\Stata18 替换为 Stata 的安装目录：\n\nsetx PATH \"%PATH%;C:\\Program Files\\Stata17\"\n\n按下回车键执行命令。\n关闭命令提示符或 PowerShell。\n重新打开命令提示符或 PowerShell，以使更改生效。\n在命令提示符中输入 stata，如果 Stata 启动，则说明添加成功。\n\n\n\n\n这个办法也有一定的普及程度，但是可能不太好用，对于新手来说会有些难以理解。可以参考连玉君的珠联璧合：Jupyter Notebook 和 Stata 之融合。\n主要步骤如下：\n\n找到 Stata 的安装目录，通常在 C:\\Program Files\\Stata18 或 C:\\Program Files (x86)\\Stata18。\n在该目录下找到 StataMP.exe 或 StataSE.exe 文件。\n将该文件的路径复制下来。\n以管理员身份打开电脑的 Windows Powershell 。\n在 PS C:\\WINDOWS\\system32&gt; 后输入以下命令（将路径转到 Stata 安装目录下）：\n\n在 Windows PowerShell 执行 cd 命令，以进入 stata 程序安装的路径。cd 命令后接上步所获取的 stata 安装路径。根据个人电脑安装路径不同有所差异。路径请以英文引号包围，这样可以避免路径文件夹名称中包含空格导致无法顺利进入目标路径。\ncd \"C:\\Program Files\\Stata18\"\n实际效果应该如下：\nPS C:\\WINDOWS\\system32&gt; cd 'C:\\Program Files\\Stata18'\nPS C:\\Program Files\\Stata18&gt;\n\n输入以下命令来将 stata 添加到命令行注册表中：\n\n.\\StataMP-64.exe /Register\n需要注意的是： .\\StataMP-64.exe /Register 中的 .\\StataMP-64.exe 部分，根据个人电脑安装 Stata17+ 版本有所差异。我电脑安装的是 MP 版，所以为 .\\StataMP-64.exe。如果安装的是 SE 版，应该为 .\\StataSE-64.exe。\n这里实测效果不太好，不知道为什么，注册成功但是命令行输入 stata 还是无法打开 Stata。",
    "crumbs": [
      "Home",
      "统计软件",
      "Stata",
      "Use Stata with Python"
    ]
  },
  {
    "objectID": "Guide/Stata/25-04-29-Stata-PY.html#方法一使用-pip-配置-pystata",
    "href": "Guide/Stata/25-04-29-Stata-PY.html#方法一使用-pip-配置-pystata",
    "title": "Use Stata with Python",
    "section": "2.1 方法一：使用 pip 配置 pystata",
    "text": "2.1 方法一：使用 pip 配置 pystata\nPyStata 可以通过 pip 安装。Windows 可以使用以下命令进行安装：\npip install --upgrade --user stata_setup\nmacOS 或 Unix 系统可以使用以下命令进行安装：\n$ pip install --upgrade --user stata_setup\n\n2.1.1 配置 Stata\n假设你的 Stata 安装在 STATA_SYSDIR 目录下，并且使用的是 Stata/MP 版本。你可以在 Python 环境中按如下方式配置 Stata：\n如果 Stata 配置正确，stata_setup.config() 将返回如下的启动画面，其中包含 Stata 的徽标和初始化消息。\n\n\n代码\nimport stata_setup\nstata_setup.config('C:\\Program Files\\Stata18', 'mp')\n\n\n\n  ___  ____  ____  ____  ____ ®\n /__    /   ____/   /   ____/      18.0\n___/   /   /___/   /   /___/       MP—Parallel Edition\n\n Statistics and Data Science       Copyright 1985-2023 StataCorp LLC\n                                   StataCorp\n                                   4905 Lakeway Drive\n                                   College Station, Texas 77845 USA\n                                   800-STATA-PC        https://www.stata.com\n                                   979-696-4600        stata@stata.com\n\nStata license: Unlimited-user 2-core network, expiring  8 Apr 2026\nSerial number: 501809376090\n  Licensed to: ausa\n               NJU\n\nNotes:\n      1. Unicode is supported; see help unicode_advice.\n      2. More than 2 billion observations are allowed; see help obs_advice.\n      3. Maximum number of variables is set to 5,000 but can be increased;\n          see help set_maxvar.\n\n\n如果你不想看到初始化的信息，可以使用如下命令将其隐藏：\nstata_setup.config('YOUR_STATA_SYSDIR', 'mp', splash=False)",
    "crumbs": [
      "Home",
      "统计软件",
      "Stata",
      "Use Stata with Python"
    ]
  },
  {
    "objectID": "Guide/Stata/25-04-29-Stata-PY.html#方法二将-pystata-添加到-sys.path",
    "href": "Guide/Stata/25-04-29-Stata-PY.html#方法二将-pystata-添加到-sys.path",
    "title": "Use Stata with Python",
    "section": "2.2 方法二：将 pystata 添加到 sys.path",
    "text": "2.2 方法二：将 pystata 添加到 sys.path\n找到 pystata 包的最直接方法是将 pystata 子目录的位置添加到 Python 的模块搜索路径中。在你的 Python 环境中，你可以输入\nimport sys\nsys.path.append('STATA_SYSDIR/utilities')\nfrom pystata import config\nconfig.init('mp')\n如果配置正确，config.init() 应该返回无错误，并显示同上面一样的的启动画面，其中包含 Stata 的徽标和初始化消息。如果您想隐藏这些消息，可以将 splash 参数设置为 False。\n更多的安装和配置信息可以访问：pystata",
    "crumbs": [
      "Home",
      "统计软件",
      "Stata",
      "Use Stata with Python"
    ]
  }
]